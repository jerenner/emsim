{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import training as tr\n",
    "import emnet\n",
    "import emsim_utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import cv2\n",
    "\n",
    "from unet import UNet\n",
    "import scipy.optimize as optimize\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write events to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datfile = \"/home/jrenner/local/data/electronsim/pixelated_tracks_K2_5um_front_3M_100keV.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a new dataset.\n",
    "df = emsim_utils.read_electron_data(datfile,nevts=200005)\n",
    "df.to_pickle(\"EM_5um_front_3M_100keV.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random multi-electron events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset for events from 0 to 198917\n"
     ]
    }
   ],
   "source": [
    "dset = tr.EMDataset(\"dataframes/EM_5um_front_3M_100keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=False,add_shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameset  = tr.EMFrameDataset(dset,frame_size=20,nelec_mean=2,nelec_sigma=0.1,noise_mean=683,noise_sigma=11.2,m_line=-2.0,b_line=30.0, lside = 0)\n",
    "#frameset = tr.EMFrameDataset(dset,frame_size=4855,nelec_mean=103713,nelec_sigma=0.5,noise_mean=683,noise_sigma=11.2)\n",
    "#frameset = tr.EMFrameDataset(dset,frame_size=100,nelec_mean=88,nelec_sigma=2,noise_mean=0,noise_sigma=20)\n",
    "#frameset = tr.EMFrameDataset(dset,frame_size=100,nelec_mean=10,nelec_sigma=1,noise_mean=0,noise_sigma=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate many frames and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(fit_img, th = 0.5, pct_rng = 0.2, nbins_hdist = 100):\n",
    "    \n",
    "    A = fit_img/np.max(fit_img)\n",
    "    nrows = A.shape[0]\n",
    "    ncols = A.shape[1]\n",
    "    ncts = np.sum(A[A >= th])\n",
    "    nzeros = np.sum(1-A[A < th])\n",
    "    wcts = 1.0 #nzeros/ncts\n",
    "    indices = np.indices((nrows,ncols))\n",
    "    irows = indices[0]\n",
    "    icols = indices[1]\n",
    "    print(\"nzeros = {}, ncts = {}, wcts = {}\".format(nzeros,ncts,wcts))\n",
    "\n",
    "    def count_loss(x):\n",
    "        m,b = x\n",
    "\n",
    "        # The loss L is:\n",
    "        #\n",
    "        # (number of 0s in the dark region) - wcts*(number of 1s in the dark region)\n",
    "        # + wcts*(number of 1s in the light region) - (number of 0s in the dark region)\n",
    "        # \n",
    "        # where wcts is the count weight, determined such that the number of counts multiplied by wcts is equal to\n",
    "        # the number of zeros.\n",
    "        L = 0\n",
    "        L1 = np.sum(1-A[(irows < m*icols + b) & (A < th)])\n",
    "        L2 = np.sum(A[(irows < m*icols + b) & (A >= th)])\n",
    "        L3 = np.sum(A[(irows >= m*icols + b) & (A >= th)])\n",
    "        L4 = np.sum(1-A[(irows >= m*icols + b) & (A < th)])\n",
    "\n",
    "        L = L1 - wcts*L2 + wcts*L3 - L4\n",
    "        #print(\"Loss is:\",-L,\"with L1 =\",L1,\"L2 =\",L2,\"L3 =\",L3,\"L4 =\",L4)\n",
    "        return -L\n",
    "    \n",
    "    initial_guess = [-3*nrows/ncols,nrows]\n",
    "    result = optimize.minimize(count_loss,initial_guess,method='Nelder-Mead',tol=1e-6)\n",
    "    m,b = result.x\n",
    "    Lmin = result.fun\n",
    "    print(\"m = \",m,\"b = \",b,\"Lmin=\",Lmin)\n",
    "    \n",
    "    # Get the loss over a range of the parameters.\n",
    "    mrng = np.arange(m-pct_rng*m, m+pct_rng*m, 2*pct_rng*m/1000)\n",
    "    Lrng_m = np.array([count_loss([mval,b])/Lmin for mval in mrng])\n",
    "    brng = np.arange(b-pct_rng*b, b+pct_rng*b, 2*pct_rng*b/1000)\n",
    "    Lrng_b = np.array([count_loss([m,bval])/Lmin for bval in brng])\n",
    "    \n",
    "    # Get the histogram of mean value vs. distance.\n",
    "    dist = (m*icols - irows + b) / (m**2 + 1)                          # compute distance to line for each point\n",
    "    hw, bb = np.histogram(dist.flatten(),weights=A.flatten(),bins=nbins_hdist)  # weighted histogram\n",
    "    hh, bb = np.histogram(dist.flatten(),bins=nbins_hdist)                      # unweighted (for normalization)\n",
    "    hh[hh = 0] = 0.1\n",
    "    hfinal = hw / hh                                                   # normalize the histogram\n",
    "    bcenters = (bb[1:] + bb[:-1]) / 2                                  # determine the bin centers\n",
    "    \n",
    "    return m,b,Lmin,mrng,Lrng_m,brng,Lrng_b,hfinal,bcenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some number of events and count them.\n",
    "th_unet = 0.9\n",
    "th_classical = 825\n",
    "evts = np.arange(0,10000)\n",
    "l_frames, l_labels, l_ct_unet, l_ct_classical = [], [], [], []\n",
    "for evt in evts:\n",
    "    frame,label = frameset[evt]\n",
    "    label = label[0]\n",
    "    \n",
    "    # Send through the model.\n",
    "    data = torch.tensor(frame).float().unsqueeze(0).unsqueeze(1).cuda()\n",
    "    output_score = model(data)\n",
    "    \n",
    "    # Compute the predicted pixel values.\n",
    "    prob = np.array(sigmoid(output_score).cpu().detach().numpy()).squeeze()\n",
    "    ct_unet = (prob > th_unet)\n",
    "    \n",
    "    # Count with a single threshold.\n",
    "    ct_classical = (frame > th_classical)\n",
    "    \n",
    "    l_frames.append(frame)\n",
    "    l_labels.append(label)\n",
    "    l_ct_unet.append(ct_unet)\n",
    "    l_ct_classical.append(ct_classical)\n",
    "    \n",
    "    if((evt-evts[0]) % (len(evts)/100) == 0):\n",
    "            print(\"{}% done\".format(int((evt-evts[0]) / (len(evts)/100))))\n",
    "            \n",
    "l_frames = np.array(l_frames)\n",
    "l_labels = np.array(l_labels)\n",
    "l_ct_unet = np.array(l_ct_unet)\n",
    "l_ct_classical = np.array(l_ct_classical)\n",
    "\n",
    "# Create a summed frame, label, and count arrays.\n",
    "frame = np.sum(l_frames,axis=0)\n",
    "label = np.sum(l_labels,axis=0)\n",
    "ct_unet = np.sum(l_ct_unet,axis=0)\n",
    "ct_classical = np.sum(l_ct_classical,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_th = 0.994\n",
    "ct_th = 0.2\n",
    "m_frame,b_frame,Lmin_frame,mrng_frame,Lrng_m_frame,brng_frame,Lrng_b_frame,hdist_frame,bcenters_frame = fit_line(frame,th=raw_th)\n",
    "m_label,b_label,Lmin_label,mrng_label,Lrng_m_label,brng_label,Lrng_b_label,hdist_label,bcenters_label = fit_line(label,th=ct_th)\n",
    "m_unet,b_unet,Lmin_unet,mrng_unet,Lrng_m_unet,brng_unet,Lrng_b_unet,hdist_unet,bcenters_unet = fit_line(ct_unet,th=ct_th)\n",
    "m_classical,b_classical,Lmin_classical,mrng_classical,Lrng_m_classical,brng_classical,Lrng_b_classical,hdist_classical,bcenters_classical = fit_line(ct_classical,th=ct_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#frame,label = frameset[0]\n",
    "logscale = False\n",
    "nrows = frame.shape[0]\n",
    "ncols = frame.shape[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(12.0)\n",
    "fig.set_figwidth(12.0)\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "if(logscale):\n",
    "    plt.imshow(np.log(frame))\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"log(counts)\")\n",
    "    plt.title(\"Raw frame (log counts, threshold = {})\\nm = {:.2f}, b = {:.2f}\".format(raw_th,m_label,b_label))\n",
    "else:\n",
    "    plt.imshow(frame/np.max(frame))\n",
    "    cbar = plt.colorbar()\n",
    "    plt.title(\"Raw frame (threshold = {})\\nm = {:.2f}, b = {:.2f}\".format(raw_th,m_label,b_label))\n",
    "xfit = np.arange(0,ncols-1,0.1)\n",
    "yfit = m_frame*xfit + b_frame\n",
    "plt.plot(xfit[(yfit > 0) & (yfit < nrows-1)],yfit[(yfit > 0) & (yfit < nrows-1)],color='red',linewidth=2)\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "plt.imshow(label/np.max(label))\n",
    "plt.title(\"Truth (threshold = {})\\nm = {:.2f}, b = {:.2f}\".format(ct_th,m_label,b_label))\n",
    "plt.colorbar()\n",
    "xfit = np.arange(0,ncols-1,0.1)\n",
    "yfit = m_label*xfit + b_label\n",
    "plt.plot(xfit[(yfit > 0) & (yfit < nrows-1)],yfit[(yfit > 0) & (yfit < nrows-1)],color='red',linewidth=2)\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "plt.imshow(ct_unet/np.max(ct_unet))\n",
    "plt.title(\"UNet counts (threshold = {})\\nm = {:.2f}, b = {:.2f}\".format(ct_th,m_unet,b_unet))\n",
    "plt.colorbar()\n",
    "xfit = np.arange(0,ncols-1,0.1)\n",
    "yfit = m_unet*xfit + b_unet\n",
    "plt.plot(xfit[(yfit > 0) & (yfit < nrows-1)],yfit[(yfit > 0) & (yfit < nrows-1)],color='red',linewidth=2)\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "plt.imshow(ct_classical/np.max(ct_classical))\n",
    "plt.title(\"Classical counts (threshold = {})\\nm = {:.2f}, b = {:.2f}\".format(ct_th,m_classical,b_classical))\n",
    "plt.colorbar()\n",
    "xfit = np.arange(0,ncols-1,0.1)\n",
    "yfit = m_classical*xfit + b_classical\n",
    "plt.plot(xfit[(yfit > 0) & (yfit < nrows-1)],yfit[(yfit > 0) & (yfit < nrows-1)],color='red',linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(4.0)\n",
    "fig.set_figwidth(12.0)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "#plt.plot(bcenters_frame,hdist_frame,color='black',label='frame')\n",
    "plt.plot(bcenters_label,hdist_label,'.-',color='green',label='true')\n",
    "plt.plot(bcenters_unet,hdist_unet,'.-',color='blue',label='UNet')\n",
    "plt.plot(bcenters_classical,hdist_classical,'.-',color='red',label='classical')\n",
    "plt.xlim([-5,5])\n",
    "plt.xlabel(\"Distance from line (pixels)\")\n",
    "plt.ylabel(\"Mean number of normalized counts\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(4.0)\n",
    "fig.set_figwidth(12.0)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "plt.plot(mrng_frame/m_frame,Lrng_m_frame,color='black',label='frame')\n",
    "plt.plot(mrng_label/m_label,Lrng_m_label,color='green',label='true')\n",
    "plt.plot(mrng_unet/m_unet,Lrng_m_unet,color='blue',label='UNet')\n",
    "plt.plot(mrng_classical/m_classical,Lrng_m_classical,color='red',label='classical')\n",
    "plt.xlabel(\"Parameter m/m$_0$\")\n",
    "plt.ylabel(\"Relative loss L/L(m$_0$)\")\n",
    "plt.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.plot(brng_frame/b_frame,Lrng_b_frame,color='black',label='frame')\n",
    "plt.plot(brng_label/b_label,Lrng_b_label,color='green',label='true')\n",
    "plt.plot(brng_unet/b_unet,Lrng_b_unet,color='blue',label='UNet')\n",
    "plt.plot(brng_classical/b_classical,Lrng_b_classical,color='red',label='classical')\n",
    "plt.xlabel(\"Parameter b/b$_0$\")\n",
    "plt.ylabel(\"Relative loss L/L(b$_0$)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"evt_arrays.npz\",evt_arrays=l_evt_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examine a large generated frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(label[0,0:50,0:50])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sim = frame.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.hist(img_sim[(img_sim < 400)],bins=50)\n",
    "plt.hist(img_sim,bins=50)\n",
    "plt.xlabel(\"Pixel values\")\n",
    "plt.ylabel(\"Counts/bin\")\n",
    "plt.yscale(\"log\")\n",
    "print(\"Total pixels:\",len(img_sim))\n",
    "#plt.xlim([0,500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"frame_4855x4855_11occ.npz\",frame=frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a network (multi-electron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset for events from 0 to 198917\n"
     ]
    }
   ],
   "source": [
    "modeldir = '/home/jrenner/local/jerenner/emsim/models'\n",
    "lrate       = 1e-4   # Learning rate to use in the training.\n",
    "load_model  = True   # Load an existing model\n",
    "tr.augment  = False  # Enable/disable data augmentation\n",
    "epoch_start = 0      # Number of initial epoch\n",
    "epoch_end   = 2000    # Number of final epoch\n",
    "model_load_checkpoint = \"{}/model_frames_20x20_noise683_2e_bcsloss_front_100kev_89_withline.pt\".format(modeldir)\n",
    "\n",
    "# Create the dataset.\n",
    "# 576x576: 2927 +/- 71\n",
    "# 100x100: 88 +/- 2\n",
    "# 50x50: 22 +/- 0.5\n",
    "#dset = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=False,add_shift=0)\n",
    "\n",
    "# \"Real-data-like\" dataset: occupancy 11, noise_mean=683, noise_sigma=11.2\n",
    "dset = tr.EMDataset(\"dataframes/EM_5um_front_3M_100keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=False,add_shift=0)\n",
    "#dataset_train   = tr.EMFrameDataset(dset,frame_size=50,nelec_mean=11,nelec_sigma=0.5,noise_mean=683,noise_sigma=11.2)\n",
    "dataset_train = tr.EMFrameDataset(dset,frame_size=20,nelec_mean=2,nelec_sigma=0.1,noise_mean=683,noise_sigma=11.2,m_line=-2.0,b_line=30.0)\n",
    "\n",
    "# Create the loaders.\n",
    "train_loader = DataLoader(dataset_train, batch_size=50, shuffle=False, collate_fn=tr.my_collate_unet, num_workers=8)\n",
    "\n",
    "# Define the model.\n",
    "model = UNet(n_channels=1, n_classes=1)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lrate, weight_decay=1e-8, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if model.n_classes > 1 else 'max', patience=2)\n",
    "\n",
    "# Load the model from file.\n",
    "if(load_model):\n",
    "    model.load_state_dict(torch.load(model_load_checkpoint))\n",
    "    #model.load_state_dict(torch.load(model_load_checkpoint,map_location=torch.device('cpu')))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrenner/miniconda3/envs/tf2/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.001207\t score_max: 5.028306\t score_min: -25.362034; Accuracy 0.992\n",
      "Train Epoch: 0 [50/1000 (5%)]\tLoss: 0.001300\t score_max: 5.029306\t score_min: -26.824331; Accuracy 0.994\n",
      "Train Epoch: 0 [100/1000 (10%)]\tLoss: 0.000785\t score_max: 5.029420\t score_min: -28.461962; Accuracy 0.997\n",
      "Train Epoch: 0 [150/1000 (15%)]\tLoss: 0.001119\t score_max: 5.029015\t score_min: -27.895882; Accuracy 0.996\n",
      "Train Epoch: 0 [200/1000 (20%)]\tLoss: 0.001008\t score_max: 5.028013\t score_min: -26.641562; Accuracy 0.993\n",
      "Train Epoch: 0 [250/1000 (25%)]\tLoss: 0.000610\t score_max: 5.027302\t score_min: -25.351765; Accuracy 0.995\n",
      "Train Epoch: 0 [300/1000 (30%)]\tLoss: 0.000839\t score_max: 5.026938\t score_min: -27.388641; Accuracy 0.995\n",
      "Train Epoch: 0 [350/1000 (35%)]\tLoss: 0.000734\t score_max: 5.026937\t score_min: -27.644152; Accuracy 0.995\n",
      "Train Epoch: 0 [400/1000 (40%)]\tLoss: 0.000920\t score_max: 5.027208\t score_min: -27.375883; Accuracy 0.995\n",
      "Train Epoch: 0 [450/1000 (45%)]\tLoss: 0.000785\t score_max: 5.027723\t score_min: -29.245283; Accuracy 0.996\n",
      "Train Epoch: 0 [500/1000 (50%)]\tLoss: 0.000854\t score_max: 5.028504\t score_min: -26.279060; Accuracy 0.995\n",
      "Train Epoch: 0 [550/1000 (55%)]\tLoss: 0.000652\t score_max: 5.029525\t score_min: -24.700626; Accuracy 0.996\n",
      "Train Epoch: 0 [600/1000 (60%)]\tLoss: 0.001187\t score_max: 5.030706\t score_min: -27.046053; Accuracy 0.995\n",
      "Train Epoch: 0 [650/1000 (65%)]\tLoss: 0.000645\t score_max: 5.031928\t score_min: -28.318800; Accuracy 0.996\n",
      "Train Epoch: 0 [700/1000 (70%)]\tLoss: 0.000894\t score_max: 5.032815\t score_min: -28.092598; Accuracy 0.995\n",
      "Train Epoch: 0 [750/1000 (75%)]\tLoss: 0.000581\t score_max: 5.033301\t score_min: -27.644604; Accuracy 0.994\n",
      "Train Epoch: 0 [800/1000 (80%)]\tLoss: 0.000617\t score_max: 5.033701\t score_min: -27.529917; Accuracy 0.995\n",
      "Train Epoch: 0 [850/1000 (85%)]\tLoss: 0.000672\t score_max: 5.033935\t score_min: -32.193279; Accuracy 0.996\n",
      "Train Epoch: 0 [900/1000 (90%)]\tLoss: 0.000979\t score_max: 5.033893\t score_min: -27.944252; Accuracy 0.995\n",
      "Train Epoch: 0 [950/1000 (95%)]\tLoss: 0.000770\t score_max: 5.033704\t score_min: -27.422684; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.000858059196616523 ACCURACY: 0.9949374765157699\n",
      "Epoch:  1\n",
      "Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.000461\t score_max: 5.033416\t score_min: -29.066139; Accuracy 0.996\n",
      "Train Epoch: 1 [50/1000 (5%)]\tLoss: 0.000633\t score_max: 5.033058\t score_min: -29.281536; Accuracy 0.995\n",
      "Train Epoch: 1 [100/1000 (10%)]\tLoss: 0.000906\t score_max: 5.032809\t score_min: -27.678537; Accuracy 0.992\n",
      "Train Epoch: 1 [150/1000 (15%)]\tLoss: 0.000382\t score_max: 5.032878\t score_min: -27.306126; Accuracy 0.996\n",
      "Train Epoch: 1 [200/1000 (20%)]\tLoss: 0.000508\t score_max: 5.033086\t score_min: -27.819307; Accuracy 0.995\n",
      "Train Epoch: 1 [250/1000 (25%)]\tLoss: 0.001022\t score_max: 5.033371\t score_min: -28.019920; Accuracy 0.993\n",
      "Train Epoch: 1 [300/1000 (30%)]\tLoss: 0.001043\t score_max: 5.033909\t score_min: -28.813366; Accuracy 0.994\n",
      "Train Epoch: 1 [350/1000 (35%)]\tLoss: 0.000823\t score_max: 5.034728\t score_min: -29.774088; Accuracy 0.996\n",
      "Train Epoch: 1 [400/1000 (40%)]\tLoss: 0.000677\t score_max: 5.035742\t score_min: -29.134439; Accuracy 0.994\n",
      "Train Epoch: 1 [450/1000 (45%)]\tLoss: 0.000560\t score_max: 5.036622\t score_min: -29.925953; Accuracy 0.994\n",
      "Train Epoch: 1 [500/1000 (50%)]\tLoss: 0.000634\t score_max: 5.037386\t score_min: -29.902544; Accuracy 0.996\n",
      "Train Epoch: 1 [550/1000 (55%)]\tLoss: 0.000546\t score_max: 5.037989\t score_min: -28.954691; Accuracy 0.993\n",
      "Train Epoch: 1 [600/1000 (60%)]\tLoss: 0.000666\t score_max: 5.038505\t score_min: -29.663090; Accuracy 0.995\n",
      "Train Epoch: 1 [650/1000 (65%)]\tLoss: 0.000710\t score_max: 5.038883\t score_min: -29.908218; Accuracy 0.995\n",
      "Train Epoch: 1 [700/1000 (70%)]\tLoss: 0.000681\t score_max: 5.039379\t score_min: -31.079952; Accuracy 0.995\n",
      "Train Epoch: 1 [750/1000 (75%)]\tLoss: 0.000572\t score_max: 5.039758\t score_min: -29.013981; Accuracy 0.992\n",
      "Train Epoch: 1 [800/1000 (80%)]\tLoss: 0.000800\t score_max: 5.040213\t score_min: -30.154726; Accuracy 0.996\n",
      "Train Epoch: 1 [850/1000 (85%)]\tLoss: 0.000567\t score_max: 5.040562\t score_min: -28.726627; Accuracy 0.994\n",
      "Train Epoch: 1 [900/1000 (90%)]\tLoss: 0.000351\t score_max: 5.040802\t score_min: -33.383385; Accuracy 0.996\n",
      "Train Epoch: 1 [950/1000 (95%)]\tLoss: 0.000561\t score_max: 5.041080\t score_min: -32.167233; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0006552196311531589 ACCURACY: 0.994687482714653\n",
      "Epoch:  2\n",
      "Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.000287\t score_max: 5.041403\t score_min: -33.361557; Accuracy 0.997\n",
      "Train Epoch: 2 [50/1000 (5%)]\tLoss: 0.000815\t score_max: 5.041737\t score_min: -29.402542; Accuracy 0.994\n",
      "Train Epoch: 2 [100/1000 (10%)]\tLoss: 0.000327\t score_max: 5.042044\t score_min: -34.043690; Accuracy 0.997\n",
      "Train Epoch: 2 [150/1000 (15%)]\tLoss: 0.000191\t score_max: 5.042388\t score_min: -33.330250; Accuracy 0.998\n",
      "Train Epoch: 2 [200/1000 (20%)]\tLoss: 0.000781\t score_max: 5.042685\t score_min: -31.619143; Accuracy 0.993\n",
      "Train Epoch: 2 [250/1000 (25%)]\tLoss: 0.000254\t score_max: 5.043137\t score_min: -32.376999; Accuracy 0.997\n",
      "Train Epoch: 2 [300/1000 (30%)]\tLoss: 0.000642\t score_max: 5.043598\t score_min: -31.340679; Accuracy 0.995\n",
      "Train Epoch: 2 [350/1000 (35%)]\tLoss: 0.000750\t score_max: 5.044093\t score_min: -32.210007; Accuracy 0.996\n",
      "Train Epoch: 2 [400/1000 (40%)]\tLoss: 0.000447\t score_max: 5.044432\t score_min: -34.856110; Accuracy 0.996\n",
      "Train Epoch: 2 [450/1000 (45%)]\tLoss: 0.000760\t score_max: 5.044645\t score_min: -29.945627; Accuracy 0.994\n",
      "Train Epoch: 2 [500/1000 (50%)]\tLoss: 0.000349\t score_max: 5.044906\t score_min: -32.449043; Accuracy 0.996\n",
      "Train Epoch: 2 [550/1000 (55%)]\tLoss: 0.000596\t score_max: 5.045108\t score_min: -32.651527; Accuracy 0.995\n",
      "Train Epoch: 2 [600/1000 (60%)]\tLoss: 0.000551\t score_max: 5.045294\t score_min: -30.578360; Accuracy 0.993\n",
      "Train Epoch: 2 [650/1000 (65%)]\tLoss: 0.000394\t score_max: 5.045584\t score_min: -30.719114; Accuracy 0.994\n",
      "Train Epoch: 2 [700/1000 (70%)]\tLoss: 0.000422\t score_max: 5.045929\t score_min: -29.660946; Accuracy 0.993\n",
      "Train Epoch: 2 [750/1000 (75%)]\tLoss: 0.000235\t score_max: 5.046261\t score_min: -33.415382; Accuracy 0.997\n",
      "Train Epoch: 2 [800/1000 (80%)]\tLoss: 0.000266\t score_max: 5.046484\t score_min: -34.542850; Accuracy 0.996\n",
      "Train Epoch: 2 [850/1000 (85%)]\tLoss: 0.000582\t score_max: 5.046713\t score_min: -29.429121; Accuracy 0.994\n",
      "Train Epoch: 2 [900/1000 (90%)]\tLoss: 0.000461\t score_max: 5.047030\t score_min: -31.641455; Accuracy 0.994\n",
      "Train Epoch: 2 [950/1000 (95%)]\tLoss: 0.000244\t score_max: 5.047339\t score_min: -34.295074; Accuracy 0.998\n",
      "---EPOCH AVG TRAIN LOSS: 0.00046778394462307913 ACCURACY: 0.9954199731349945\n",
      "Epoch:  3\n",
      "Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.000415\t score_max: 5.047638\t score_min: -33.872585; Accuracy 0.996\n",
      "Train Epoch: 3 [50/1000 (5%)]\tLoss: 0.000629\t score_max: 5.047995\t score_min: -31.147493; Accuracy 0.995\n",
      "Train Epoch: 3 [100/1000 (10%)]\tLoss: 0.000700\t score_max: 5.048391\t score_min: -31.437502; Accuracy 0.995\n",
      "Train Epoch: 3 [150/1000 (15%)]\tLoss: 0.000535\t score_max: 5.048746\t score_min: -32.322655; Accuracy 0.996\n",
      "Train Epoch: 3 [200/1000 (20%)]\tLoss: 0.000262\t score_max: 5.049133\t score_min: -32.822380; Accuracy 0.996\n",
      "Train Epoch: 3 [250/1000 (25%)]\tLoss: 0.000260\t score_max: 5.049452\t score_min: -31.876642; Accuracy 0.996\n",
      "Train Epoch: 3 [300/1000 (30%)]\tLoss: 0.000460\t score_max: 5.049715\t score_min: -32.364433; Accuracy 0.994\n",
      "Train Epoch: 3 [350/1000 (35%)]\tLoss: 0.000918\t score_max: 5.050012\t score_min: -31.095951; Accuracy 0.992\n",
      "Train Epoch: 3 [400/1000 (40%)]\tLoss: 0.000790\t score_max: 5.050555\t score_min: -32.543331; Accuracy 0.992\n",
      "Train Epoch: 3 [450/1000 (45%)]\tLoss: 0.000229\t score_max: 5.051169\t score_min: -33.005474; Accuracy 0.996\n",
      "Train Epoch: 3 [500/1000 (50%)]\tLoss: 0.000415\t score_max: 5.051740\t score_min: -34.338406; Accuracy 0.995\n",
      "Train Epoch: 3 [550/1000 (55%)]\tLoss: 0.000776\t score_max: 5.052257\t score_min: -32.700558; Accuracy 0.994\n",
      "Train Epoch: 3 [600/1000 (60%)]\tLoss: 0.000264\t score_max: 5.052605\t score_min: -36.151981; Accuracy 0.997\n",
      "Train Epoch: 3 [650/1000 (65%)]\tLoss: 0.000543\t score_max: 5.052863\t score_min: -33.907890; Accuracy 0.995\n",
      "Train Epoch: 3 [700/1000 (70%)]\tLoss: 0.000747\t score_max: 5.052999\t score_min: -31.476454; Accuracy 0.995\n",
      "Train Epoch: 3 [750/1000 (75%)]\tLoss: 0.000782\t score_max: 5.053230\t score_min: -35.177528; Accuracy 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [800/1000 (80%)]\tLoss: 0.000663\t score_max: 5.053388\t score_min: -32.544308; Accuracy 0.993\n",
      "Train Epoch: 3 [850/1000 (85%)]\tLoss: 0.000283\t score_max: 5.053575\t score_min: -34.286663; Accuracy 0.996\n",
      "Train Epoch: 3 [900/1000 (90%)]\tLoss: 0.000482\t score_max: 5.053817\t score_min: -32.560051; Accuracy 0.994\n",
      "Train Epoch: 3 [950/1000 (95%)]\tLoss: 0.000261\t score_max: 5.054166\t score_min: -36.426434; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.0005207625996263232 ACCURACY: 0.995007473230362\n",
      "Epoch:  4\n",
      "Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.000837\t score_max: 5.054474\t score_min: -30.555470; Accuracy 0.992\n",
      "Train Epoch: 4 [50/1000 (5%)]\tLoss: 0.000288\t score_max: 5.054994\t score_min: -34.470612; Accuracy 0.996\n",
      "Train Epoch: 4 [100/1000 (10%)]\tLoss: 0.000340\t score_max: 5.055526\t score_min: -32.212456; Accuracy 0.993\n",
      "Train Epoch: 4 [150/1000 (15%)]\tLoss: 0.000614\t score_max: 5.056039\t score_min: -33.460197; Accuracy 0.993\n",
      "Train Epoch: 4 [200/1000 (20%)]\tLoss: 0.000561\t score_max: 5.056429\t score_min: -32.257469; Accuracy 0.995\n",
      "Train Epoch: 4 [250/1000 (25%)]\tLoss: 0.000328\t score_max: 5.056802\t score_min: -37.713245; Accuracy 0.998\n",
      "Train Epoch: 4 [300/1000 (30%)]\tLoss: 0.000452\t score_max: 5.057171\t score_min: -33.326569; Accuracy 0.996\n",
      "Train Epoch: 4 [350/1000 (35%)]\tLoss: 0.000525\t score_max: 5.057440\t score_min: -32.664459; Accuracy 0.995\n",
      "Train Epoch: 4 [400/1000 (40%)]\tLoss: 0.000479\t score_max: 5.057561\t score_min: -37.262264; Accuracy 0.993\n",
      "Train Epoch: 4 [450/1000 (45%)]\tLoss: 0.000301\t score_max: 5.057795\t score_min: -34.703300; Accuracy 0.996\n",
      "Train Epoch: 4 [500/1000 (50%)]\tLoss: 0.000578\t score_max: 5.057994\t score_min: -34.013748; Accuracy 0.993\n",
      "Train Epoch: 4 [550/1000 (55%)]\tLoss: 0.000452\t score_max: 5.058388\t score_min: -34.096981; Accuracy 0.996\n",
      "Train Epoch: 4 [600/1000 (60%)]\tLoss: 0.000394\t score_max: 5.058753\t score_min: -33.109367; Accuracy 0.994\n",
      "Train Epoch: 4 [650/1000 (65%)]\tLoss: 0.000441\t score_max: 5.059095\t score_min: -34.975899; Accuracy 0.993\n",
      "Train Epoch: 4 [700/1000 (70%)]\tLoss: 0.000409\t score_max: 5.059482\t score_min: -33.118515; Accuracy 0.994\n",
      "Train Epoch: 4 [750/1000 (75%)]\tLoss: 0.000604\t score_max: 5.059783\t score_min: -32.676693; Accuracy 0.994\n",
      "Train Epoch: 4 [800/1000 (80%)]\tLoss: 0.000452\t score_max: 5.059987\t score_min: -36.894104; Accuracy 0.996\n",
      "Train Epoch: 4 [850/1000 (85%)]\tLoss: 0.000484\t score_max: 5.060172\t score_min: -33.083954; Accuracy 0.994\n",
      "Train Epoch: 4 [900/1000 (90%)]\tLoss: 0.000417\t score_max: 5.060335\t score_min: -36.555290; Accuracy 0.996\n",
      "Train Epoch: 4 [950/1000 (95%)]\tLoss: 0.000235\t score_max: 5.060628\t score_min: -36.306374; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004596007813233882 ACCURACY: 0.9946099728345871\n",
      "Epoch:  5\n",
      "Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.000528\t score_max: 5.060940\t score_min: -36.857670; Accuracy 0.995\n",
      "Train Epoch: 5 [50/1000 (5%)]\tLoss: 0.000429\t score_max: 5.061326\t score_min: -31.068024; Accuracy 0.991\n",
      "Train Epoch: 5 [100/1000 (10%)]\tLoss: 0.000184\t score_max: 5.061825\t score_min: -38.561790; Accuracy 0.997\n",
      "Train Epoch: 5 [150/1000 (15%)]\tLoss: 0.000450\t score_max: 5.062333\t score_min: -32.035236; Accuracy 0.993\n",
      "Train Epoch: 5 [200/1000 (20%)]\tLoss: 0.000595\t score_max: 5.062835\t score_min: -36.666935; Accuracy 0.995\n",
      "Train Epoch: 5 [250/1000 (25%)]\tLoss: 0.000530\t score_max: 5.063211\t score_min: -33.702644; Accuracy 0.994\n",
      "Train Epoch: 5 [300/1000 (30%)]\tLoss: 0.000383\t score_max: 5.063474\t score_min: -31.706991; Accuracy 0.994\n",
      "Train Epoch: 5 [350/1000 (35%)]\tLoss: 0.000355\t score_max: 5.063741\t score_min: -36.731697; Accuracy 0.996\n",
      "Train Epoch: 5 [400/1000 (40%)]\tLoss: 0.000200\t score_max: 5.063919\t score_min: -36.952602; Accuracy 0.995\n",
      "Train Epoch: 5 [450/1000 (45%)]\tLoss: 0.000385\t score_max: 5.064047\t score_min: -32.955647; Accuracy 0.994\n",
      "Train Epoch: 5 [500/1000 (50%)]\tLoss: 0.000517\t score_max: 5.064297\t score_min: -33.555157; Accuracy 0.994\n",
      "Train Epoch: 5 [550/1000 (55%)]\tLoss: 0.000525\t score_max: 5.064660\t score_min: -33.360619; Accuracy 0.993\n",
      "Train Epoch: 5 [600/1000 (60%)]\tLoss: 0.000408\t score_max: 5.065069\t score_min: -35.899960; Accuracy 0.996\n",
      "Train Epoch: 5 [650/1000 (65%)]\tLoss: 0.000360\t score_max: 5.065540\t score_min: -33.949371; Accuracy 0.995\n",
      "Train Epoch: 5 [700/1000 (70%)]\tLoss: 0.000751\t score_max: 5.066043\t score_min: -36.516445; Accuracy 0.994\n",
      "Train Epoch: 5 [750/1000 (75%)]\tLoss: 0.001086\t score_max: 5.066524\t score_min: -33.927097; Accuracy 0.993\n",
      "Train Epoch: 5 [800/1000 (80%)]\tLoss: 0.000650\t score_max: 5.067272\t score_min: -38.935261; Accuracy 0.996\n",
      "Train Epoch: 5 [850/1000 (85%)]\tLoss: 0.000491\t score_max: 5.068085\t score_min: -34.016319; Accuracy 0.994\n",
      "Train Epoch: 5 [900/1000 (90%)]\tLoss: 0.001115\t score_max: 5.068808\t score_min: -32.772137; Accuracy 0.991\n",
      "Train Epoch: 5 [950/1000 (95%)]\tLoss: 0.000639\t score_max: 5.069749\t score_min: -35.856007; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0005290872177283745 ACCURACY: 0.994279968738556\n",
      "Epoch:  6\n",
      "Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.000901\t score_max: 5.070513\t score_min: -34.471230; Accuracy 0.995\n",
      "Train Epoch: 6 [50/1000 (5%)]\tLoss: 0.000457\t score_max: 5.071084\t score_min: -37.904121; Accuracy 0.996\n",
      "Train Epoch: 6 [100/1000 (10%)]\tLoss: 0.000719\t score_max: 5.071474\t score_min: -30.794222; Accuracy 0.993\n",
      "Train Epoch: 6 [150/1000 (15%)]\tLoss: 0.000428\t score_max: 5.071616\t score_min: -36.288013; Accuracy 0.991\n",
      "Train Epoch: 6 [200/1000 (20%)]\tLoss: 0.000663\t score_max: 5.071702\t score_min: -35.119858; Accuracy 0.995\n",
      "Train Epoch: 6 [250/1000 (25%)]\tLoss: 0.000527\t score_max: 5.071646\t score_min: -35.757996; Accuracy 0.996\n",
      "Train Epoch: 6 [300/1000 (30%)]\tLoss: 0.000588\t score_max: 5.071508\t score_min: -34.476345; Accuracy 0.994\n",
      "Train Epoch: 6 [350/1000 (35%)]\tLoss: 0.000175\t score_max: 5.071507\t score_min: -39.201050; Accuracy 0.996\n",
      "Train Epoch: 6 [400/1000 (40%)]\tLoss: 0.000803\t score_max: 5.071564\t score_min: -34.954708; Accuracy 0.993\n",
      "Train Epoch: 6 [450/1000 (45%)]\tLoss: 0.000225\t score_max: 5.071723\t score_min: -39.480007; Accuracy 0.996\n",
      "Train Epoch: 6 [500/1000 (50%)]\tLoss: 0.000717\t score_max: 5.071915\t score_min: -33.136581; Accuracy 0.992\n",
      "Train Epoch: 6 [550/1000 (55%)]\tLoss: 0.000553\t score_max: 5.072325\t score_min: -36.840034; Accuracy 0.997\n",
      "Train Epoch: 6 [600/1000 (60%)]\tLoss: 0.000421\t score_max: 5.072661\t score_min: -36.222919; Accuracy 0.996\n",
      "Train Epoch: 6 [650/1000 (65%)]\tLoss: 0.000381\t score_max: 5.073083\t score_min: -39.475731; Accuracy 0.997\n",
      "Train Epoch: 6 [700/1000 (70%)]\tLoss: 0.000559\t score_max: 5.073565\t score_min: -37.894554; Accuracy 0.994\n",
      "Train Epoch: 6 [750/1000 (75%)]\tLoss: 0.000286\t score_max: 5.074114\t score_min: -37.964409; Accuracy 0.997\n",
      "Train Epoch: 6 [800/1000 (80%)]\tLoss: 0.001050\t score_max: 5.074680\t score_min: -33.335598; Accuracy 0.992\n",
      "Train Epoch: 6 [850/1000 (85%)]\tLoss: 0.000364\t score_max: 5.075271\t score_min: -33.888214; Accuracy 0.992\n",
      "Train Epoch: 6 [900/1000 (90%)]\tLoss: 0.000729\t score_max: 5.075883\t score_min: -33.185398; Accuracy 0.992\n",
      "Train Epoch: 6 [950/1000 (95%)]\tLoss: 0.000307\t score_max: 5.076407\t score_min: -37.364780; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.0005426892603281885 ACCURACY: 0.9945349752902984\n",
      "Epoch:  7\n",
      "Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.000538\t score_max: 5.076828\t score_min: -35.043621; Accuracy 0.993\n",
      "Train Epoch: 7 [50/1000 (5%)]\tLoss: 0.000374\t score_max: 5.077198\t score_min: -36.741016; Accuracy 0.994\n",
      "Train Epoch: 7 [100/1000 (10%)]\tLoss: 0.000690\t score_max: 5.077470\t score_min: -38.656181; Accuracy 0.996\n",
      "Train Epoch: 7 [150/1000 (15%)]\tLoss: 0.000367\t score_max: 5.077522\t score_min: -33.448956; Accuracy 0.995\n",
      "Train Epoch: 7 [200/1000 (20%)]\tLoss: 0.000378\t score_max: 5.077510\t score_min: -38.885189; Accuracy 0.996\n",
      "Train Epoch: 7 [250/1000 (25%)]\tLoss: 0.000393\t score_max: 5.077478\t score_min: -38.469147; Accuracy 0.996\n",
      "Train Epoch: 7 [300/1000 (30%)]\tLoss: 0.000327\t score_max: 5.077497\t score_min: -36.265251; Accuracy 0.995\n",
      "Train Epoch: 7 [350/1000 (35%)]\tLoss: 0.000188\t score_max: 5.077509\t score_min: -36.937099; Accuracy 0.996\n",
      "Train Epoch: 7 [400/1000 (40%)]\tLoss: 0.000325\t score_max: 5.077517\t score_min: -37.527641; Accuracy 0.995\n",
      "Train Epoch: 7 [450/1000 (45%)]\tLoss: 0.000382\t score_max: 5.077600\t score_min: -38.856956; Accuracy 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [500/1000 (50%)]\tLoss: 0.000493\t score_max: 5.077816\t score_min: -36.098362; Accuracy 0.996\n",
      "Train Epoch: 7 [550/1000 (55%)]\tLoss: 0.000565\t score_max: 5.078137\t score_min: -36.178638; Accuracy 0.995\n",
      "Train Epoch: 7 [600/1000 (60%)]\tLoss: 0.000554\t score_max: 5.078421\t score_min: -33.638596; Accuracy 0.992\n",
      "Train Epoch: 7 [650/1000 (65%)]\tLoss: 0.000492\t score_max: 5.078781\t score_min: -33.580627; Accuracy 0.995\n",
      "Train Epoch: 7 [700/1000 (70%)]\tLoss: 0.000458\t score_max: 5.079170\t score_min: -38.131027; Accuracy 0.996\n",
      "Train Epoch: 7 [750/1000 (75%)]\tLoss: 0.000576\t score_max: 5.079634\t score_min: -36.827057; Accuracy 0.996\n",
      "Train Epoch: 7 [800/1000 (80%)]\tLoss: 0.000266\t score_max: 5.079936\t score_min: -37.322361; Accuracy 0.995\n",
      "Train Epoch: 7 [850/1000 (85%)]\tLoss: 0.000360\t score_max: 5.080308\t score_min: -41.123829; Accuracy 0.995\n",
      "Train Epoch: 7 [900/1000 (90%)]\tLoss: 0.000405\t score_max: 5.080571\t score_min: -37.904858; Accuracy 0.995\n",
      "Train Epoch: 7 [950/1000 (95%)]\tLoss: 0.000452\t score_max: 5.080815\t score_min: -37.215580; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00042917612372548317 ACCURACY: 0.995142474770546\n",
      "Epoch:  8\n",
      "Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.000494\t score_max: 5.081056\t score_min: -31.682625; Accuracy 0.993\n",
      "Train Epoch: 8 [50/1000 (5%)]\tLoss: 0.000560\t score_max: 5.081433\t score_min: -37.301678; Accuracy 0.995\n",
      "Train Epoch: 8 [100/1000 (10%)]\tLoss: 0.000746\t score_max: 5.081790\t score_min: -33.918003; Accuracy 0.993\n",
      "Train Epoch: 8 [150/1000 (15%)]\tLoss: 0.000259\t score_max: 5.082252\t score_min: -37.240524; Accuracy 0.995\n",
      "Train Epoch: 8 [200/1000 (20%)]\tLoss: 0.000391\t score_max: 5.082633\t score_min: -36.758770; Accuracy 0.993\n",
      "Train Epoch: 8 [250/1000 (25%)]\tLoss: 0.000312\t score_max: 5.082929\t score_min: -40.396118; Accuracy 0.994\n",
      "Train Epoch: 8 [300/1000 (30%)]\tLoss: 0.000170\t score_max: 5.083159\t score_min: -40.131813; Accuracy 0.996\n",
      "Train Epoch: 8 [350/1000 (35%)]\tLoss: 0.000374\t score_max: 5.083376\t score_min: -39.747131; Accuracy 0.997\n",
      "Train Epoch: 8 [400/1000 (40%)]\tLoss: 0.000550\t score_max: 5.083538\t score_min: -38.593773; Accuracy 0.996\n",
      "Train Epoch: 8 [450/1000 (45%)]\tLoss: 0.000443\t score_max: 5.083845\t score_min: -38.546059; Accuracy 0.995\n",
      "Train Epoch: 8 [500/1000 (50%)]\tLoss: 0.000556\t score_max: 5.084023\t score_min: -38.161774; Accuracy 0.995\n",
      "Train Epoch: 8 [550/1000 (55%)]\tLoss: 0.000490\t score_max: 5.084231\t score_min: -34.358040; Accuracy 0.994\n",
      "Train Epoch: 8 [600/1000 (60%)]\tLoss: 0.000317\t score_max: 5.084305\t score_min: -38.665192; Accuracy 0.996\n",
      "Train Epoch: 8 [650/1000 (65%)]\tLoss: 0.000353\t score_max: 5.084462\t score_min: -37.905197; Accuracy 0.996\n",
      "Train Epoch: 8 [700/1000 (70%)]\tLoss: 0.000760\t score_max: 5.084789\t score_min: -35.290962; Accuracy 0.996\n",
      "Train Epoch: 8 [750/1000 (75%)]\tLoss: 0.000430\t score_max: 5.085180\t score_min: -37.480331; Accuracy 0.996\n",
      "Train Epoch: 8 [800/1000 (80%)]\tLoss: 0.000376\t score_max: 5.085612\t score_min: -35.742489; Accuracy 0.994\n",
      "Train Epoch: 8 [850/1000 (85%)]\tLoss: 0.000416\t score_max: 5.085983\t score_min: -38.919777; Accuracy 0.995\n",
      "Train Epoch: 8 [900/1000 (90%)]\tLoss: 0.000814\t score_max: 5.086378\t score_min: -39.412586; Accuracy 0.995\n",
      "Train Epoch: 8 [950/1000 (95%)]\tLoss: 0.000320\t score_max: 5.086510\t score_min: -41.818066; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004565385774185415 ACCURACY: 0.9949174731969833\n",
      "Epoch:  9\n",
      "Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.000333\t score_max: 5.086656\t score_min: -36.155624; Accuracy 0.993\n",
      "Train Epoch: 9 [50/1000 (5%)]\tLoss: 0.000411\t score_max: 5.086825\t score_min: -35.046383; Accuracy 0.995\n",
      "Train Epoch: 9 [100/1000 (10%)]\tLoss: 0.000690\t score_max: 5.086992\t score_min: -36.797699; Accuracy 0.995\n",
      "Train Epoch: 9 [150/1000 (15%)]\tLoss: 0.000378\t score_max: 5.087060\t score_min: -40.063648; Accuracy 0.995\n",
      "Train Epoch: 9 [200/1000 (20%)]\tLoss: 0.000433\t score_max: 5.087085\t score_min: -37.431538; Accuracy 0.993\n",
      "Train Epoch: 9 [250/1000 (25%)]\tLoss: 0.000154\t score_max: 5.087206\t score_min: -38.743408; Accuracy 0.997\n",
      "Train Epoch: 9 [300/1000 (30%)]\tLoss: 0.000582\t score_max: 5.087333\t score_min: -35.664619; Accuracy 0.994\n",
      "Train Epoch: 9 [350/1000 (35%)]\tLoss: 0.000260\t score_max: 5.087621\t score_min: -38.311943; Accuracy 0.994\n",
      "Train Epoch: 9 [400/1000 (40%)]\tLoss: 0.000530\t score_max: 5.087897\t score_min: -35.641830; Accuracy 0.996\n",
      "Train Epoch: 9 [450/1000 (45%)]\tLoss: 0.000445\t score_max: 5.088379\t score_min: -36.334991; Accuracy 0.995\n",
      "Train Epoch: 9 [500/1000 (50%)]\tLoss: 0.000689\t score_max: 5.088810\t score_min: -32.486427; Accuracy 0.992\n",
      "Train Epoch: 9 [550/1000 (55%)]\tLoss: 0.000379\t score_max: 5.089381\t score_min: -38.920567; Accuracy 0.993\n",
      "Train Epoch: 9 [600/1000 (60%)]\tLoss: 0.000478\t score_max: 5.089926\t score_min: -38.598400; Accuracy 0.994\n",
      "Train Epoch: 9 [650/1000 (65%)]\tLoss: 0.000321\t score_max: 5.090403\t score_min: -38.394447; Accuracy 0.994\n",
      "Train Epoch: 9 [700/1000 (70%)]\tLoss: 0.000520\t score_max: 5.090930\t score_min: -39.321709; Accuracy 0.995\n",
      "Train Epoch: 9 [750/1000 (75%)]\tLoss: 0.000581\t score_max: 5.091310\t score_min: -39.058586; Accuracy 0.995\n",
      "Train Epoch: 9 [800/1000 (80%)]\tLoss: 0.000234\t score_max: 5.091639\t score_min: -37.465691; Accuracy 0.994\n",
      "Train Epoch: 9 [850/1000 (85%)]\tLoss: 0.000303\t score_max: 5.091934\t score_min: -40.667282; Accuracy 0.997\n",
      "Train Epoch: 9 [900/1000 (90%)]\tLoss: 0.000328\t score_max: 5.092175\t score_min: -38.616356; Accuracy 0.994\n",
      "Train Epoch: 9 [950/1000 (95%)]\tLoss: 0.000223\t score_max: 5.092391\t score_min: -39.677303; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041370925973751584 ACCURACY: 0.9946274787187577\n",
      "Epoch:  10\n",
      "Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.000658\t score_max: 5.092617\t score_min: -34.902248; Accuracy 0.995\n",
      "Train Epoch: 10 [50/1000 (5%)]\tLoss: 0.000432\t score_max: 5.092666\t score_min: -41.817322; Accuracy 0.995\n",
      "Train Epoch: 10 [100/1000 (10%)]\tLoss: 0.000462\t score_max: 5.092680\t score_min: -40.698112; Accuracy 0.996\n",
      "Train Epoch: 10 [150/1000 (15%)]\tLoss: 0.000260\t score_max: 5.092776\t score_min: -37.136395; Accuracy 0.995\n",
      "Train Epoch: 10 [200/1000 (20%)]\tLoss: 0.000890\t score_max: 5.092865\t score_min: -34.411198; Accuracy 0.992\n",
      "Train Epoch: 10 [250/1000 (25%)]\tLoss: 0.000390\t score_max: 5.093042\t score_min: -39.986687; Accuracy 0.995\n",
      "Train Epoch: 10 [300/1000 (30%)]\tLoss: 0.000326\t score_max: 5.093275\t score_min: -36.709290; Accuracy 0.994\n",
      "Train Epoch: 10 [350/1000 (35%)]\tLoss: 0.000659\t score_max: 5.093598\t score_min: -37.557102; Accuracy 0.994\n",
      "Train Epoch: 10 [400/1000 (40%)]\tLoss: 0.000243\t score_max: 5.093950\t score_min: -39.633621; Accuracy 0.996\n",
      "Train Epoch: 10 [450/1000 (45%)]\tLoss: 0.000599\t score_max: 5.094257\t score_min: -37.253017; Accuracy 0.994\n",
      "Train Epoch: 10 [500/1000 (50%)]\tLoss: 0.000355\t score_max: 5.094758\t score_min: -36.690266; Accuracy 0.994\n",
      "Train Epoch: 10 [550/1000 (55%)]\tLoss: 0.000862\t score_max: 5.095292\t score_min: -34.765472; Accuracy 0.992\n",
      "Train Epoch: 10 [600/1000 (60%)]\tLoss: 0.001064\t score_max: 5.095889\t score_min: -31.078236; Accuracy 0.993\n",
      "Train Epoch: 10 [650/1000 (65%)]\tLoss: 0.000396\t score_max: 5.096639\t score_min: -41.167839; Accuracy 0.995\n",
      "Train Epoch: 10 [700/1000 (70%)]\tLoss: 0.000402\t score_max: 5.097239\t score_min: -38.038025; Accuracy 0.994\n",
      "Train Epoch: 10 [750/1000 (75%)]\tLoss: 0.000518\t score_max: 5.097694\t score_min: -42.029495; Accuracy 0.996\n",
      "Train Epoch: 10 [800/1000 (80%)]\tLoss: 0.000386\t score_max: 5.098203\t score_min: -35.879307; Accuracy 0.994\n",
      "Train Epoch: 10 [850/1000 (85%)]\tLoss: 0.000352\t score_max: 5.098691\t score_min: -40.251633; Accuracy 0.993\n",
      "Train Epoch: 10 [900/1000 (90%)]\tLoss: 0.000400\t score_max: 5.099100\t score_min: -37.221107; Accuracy 0.995\n",
      "Train Epoch: 10 [950/1000 (95%)]\tLoss: 0.000538\t score_max: 5.099458\t score_min: -36.790417; Accuracy 0.991\n",
      "---EPOCH AVG TRAIN LOSS: 0.0005096576380310581 ACCURACY: 0.9940899789333344\n",
      "Epoch:  11\n",
      "Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.000201\t score_max: 5.099853\t score_min: -40.618240; Accuracy 0.994\n",
      "Train Epoch: 11 [50/1000 (5%)]\tLoss: 0.000553\t score_max: 5.100204\t score_min: -37.430061; Accuracy 0.994\n",
      "Train Epoch: 11 [100/1000 (10%)]\tLoss: 0.000230\t score_max: 5.100624\t score_min: -40.869690; Accuracy 0.996\n",
      "Train Epoch: 11 [150/1000 (15%)]\tLoss: 0.000197\t score_max: 5.100941\t score_min: -42.788326; Accuracy 0.997\n",
      "Train Epoch: 11 [200/1000 (20%)]\tLoss: 0.000330\t score_max: 5.101193\t score_min: -40.079395; Accuracy 0.996\n",
      "Train Epoch: 11 [250/1000 (25%)]\tLoss: 0.000172\t score_max: 5.101394\t score_min: -40.979511; Accuracy 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [300/1000 (30%)]\tLoss: 0.000410\t score_max: 5.101601\t score_min: -37.886024; Accuracy 0.994\n",
      "Train Epoch: 11 [350/1000 (35%)]\tLoss: 0.000419\t score_max: 5.101736\t score_min: -36.599136; Accuracy 0.995\n",
      "Train Epoch: 11 [400/1000 (40%)]\tLoss: 0.000459\t score_max: 5.101788\t score_min: -39.505611; Accuracy 0.994\n",
      "Train Epoch: 11 [450/1000 (45%)]\tLoss: 0.000366\t score_max: 5.101768\t score_min: -39.490364; Accuracy 0.996\n",
      "Train Epoch: 11 [500/1000 (50%)]\tLoss: 0.000358\t score_max: 5.101866\t score_min: -41.539890; Accuracy 0.996\n",
      "Train Epoch: 11 [550/1000 (55%)]\tLoss: 0.000394\t score_max: 5.102068\t score_min: -43.302406; Accuracy 0.997\n",
      "Train Epoch: 11 [600/1000 (60%)]\tLoss: 0.000404\t score_max: 5.102402\t score_min: -43.054356; Accuracy 0.996\n",
      "Train Epoch: 11 [650/1000 (65%)]\tLoss: 0.000349\t score_max: 5.102857\t score_min: -39.930416; Accuracy 0.995\n",
      "Train Epoch: 11 [700/1000 (70%)]\tLoss: 0.000616\t score_max: 5.103263\t score_min: -37.571205; Accuracy 0.993\n",
      "Train Epoch: 11 [750/1000 (75%)]\tLoss: 0.000290\t score_max: 5.103808\t score_min: -40.482655; Accuracy 0.996\n",
      "Train Epoch: 11 [800/1000 (80%)]\tLoss: 0.000636\t score_max: 5.104345\t score_min: -37.991692; Accuracy 0.994\n",
      "Train Epoch: 11 [850/1000 (85%)]\tLoss: 0.000414\t score_max: 5.104835\t score_min: -40.760742; Accuracy 0.995\n",
      "Train Epoch: 11 [900/1000 (90%)]\tLoss: 0.000653\t score_max: 5.105321\t score_min: -39.243931; Accuracy 0.993\n",
      "Train Epoch: 11 [950/1000 (95%)]\tLoss: 0.000444\t score_max: 5.105940\t score_min: -38.056908; Accuracy 0.993\n",
      "---EPOCH AVG TRAIN LOSS: 0.00039474649747717194 ACCURACY: 0.9950499713420868\n",
      "Epoch:  12\n",
      "Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.000496\t score_max: 5.106533\t score_min: -39.958447; Accuracy 0.992\n",
      "Train Epoch: 12 [50/1000 (5%)]\tLoss: 0.000800\t score_max: 5.107157\t score_min: -40.160400; Accuracy 0.991\n",
      "Train Epoch: 12 [100/1000 (10%)]\tLoss: 0.000447\t score_max: 5.107701\t score_min: -40.000320; Accuracy 0.994\n",
      "Train Epoch: 12 [150/1000 (15%)]\tLoss: 0.000498\t score_max: 5.108086\t score_min: -38.520527; Accuracy 0.994\n",
      "Train Epoch: 12 [200/1000 (20%)]\tLoss: 0.000595\t score_max: 5.108269\t score_min: -37.274361; Accuracy 0.994\n",
      "Train Epoch: 12 [250/1000 (25%)]\tLoss: 0.000573\t score_max: 5.108282\t score_min: -32.746925; Accuracy 0.991\n",
      "Train Epoch: 12 [300/1000 (30%)]\tLoss: 0.000669\t score_max: 5.108407\t score_min: -39.706001; Accuracy 0.995\n",
      "Train Epoch: 12 [350/1000 (35%)]\tLoss: 0.000642\t score_max: 5.108327\t score_min: -39.494556; Accuracy 0.995\n",
      "Train Epoch: 12 [400/1000 (40%)]\tLoss: 0.000631\t score_max: 5.108113\t score_min: -39.947540; Accuracy 0.995\n",
      "Train Epoch: 12 [450/1000 (45%)]\tLoss: 0.000390\t score_max: 5.107834\t score_min: -36.210690; Accuracy 0.995\n",
      "Train Epoch: 12 [500/1000 (50%)]\tLoss: 0.000327\t score_max: 5.107697\t score_min: -39.281284; Accuracy 0.997\n",
      "Train Epoch: 12 [550/1000 (55%)]\tLoss: 0.000400\t score_max: 5.107639\t score_min: -42.000290; Accuracy 0.996\n",
      "Train Epoch: 12 [600/1000 (60%)]\tLoss: 0.000815\t score_max: 5.107749\t score_min: -41.759556; Accuracy 0.995\n",
      "Train Epoch: 12 [650/1000 (65%)]\tLoss: 0.000693\t score_max: 5.108081\t score_min: -37.407372; Accuracy 0.993\n",
      "Train Epoch: 12 [700/1000 (70%)]\tLoss: 0.001021\t score_max: 5.108497\t score_min: -40.718140; Accuracy 0.993\n",
      "Train Epoch: 12 [750/1000 (75%)]\tLoss: 0.000549\t score_max: 5.109164\t score_min: -40.781170; Accuracy 0.995\n",
      "Train Epoch: 12 [800/1000 (80%)]\tLoss: 0.000421\t score_max: 5.109869\t score_min: -38.545086; Accuracy 0.995\n",
      "Train Epoch: 12 [850/1000 (85%)]\tLoss: 0.000347\t score_max: 5.110528\t score_min: -42.325302; Accuracy 0.994\n",
      "Train Epoch: 12 [900/1000 (90%)]\tLoss: 0.000459\t score_max: 5.111129\t score_min: -39.521832; Accuracy 0.994\n",
      "Train Epoch: 12 [950/1000 (95%)]\tLoss: 0.000193\t score_max: 5.111692\t score_min: -44.382172; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0005482798158482182 ACCURACY: 0.9942899733781815\n",
      "Epoch:  13\n",
      "Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.000182\t score_max: 5.112239\t score_min: -42.541695; Accuracy 0.997\n",
      "Train Epoch: 13 [50/1000 (5%)]\tLoss: 0.000662\t score_max: 5.112766\t score_min: -36.504669; Accuracy 0.990\n",
      "Train Epoch: 13 [100/1000 (10%)]\tLoss: 0.000526\t score_max: 5.113295\t score_min: -40.174587; Accuracy 0.994\n",
      "Train Epoch: 13 [150/1000 (15%)]\tLoss: 0.000723\t score_max: 5.113662\t score_min: -37.871353; Accuracy 0.992\n",
      "Train Epoch: 13 [200/1000 (20%)]\tLoss: 0.000390\t score_max: 5.113945\t score_min: -41.373604; Accuracy 0.994\n",
      "Train Epoch: 13 [250/1000 (25%)]\tLoss: 0.000484\t score_max: 5.114132\t score_min: -40.155811; Accuracy 0.995\n",
      "Train Epoch: 13 [300/1000 (30%)]\tLoss: 0.000628\t score_max: 5.114220\t score_min: -38.957855; Accuracy 0.994\n",
      "Train Epoch: 13 [350/1000 (35%)]\tLoss: 0.000252\t score_max: 5.114274\t score_min: -39.509617; Accuracy 0.995\n",
      "Train Epoch: 13 [400/1000 (40%)]\tLoss: 0.000180\t score_max: 5.114311\t score_min: -38.008430; Accuracy 0.995\n",
      "Train Epoch: 13 [450/1000 (45%)]\tLoss: 0.000840\t score_max: 5.114382\t score_min: -33.614971; Accuracy 0.992\n",
      "Train Epoch: 13 [500/1000 (50%)]\tLoss: 0.000430\t score_max: 5.114635\t score_min: -35.171623; Accuracy 0.995\n",
      "Train Epoch: 13 [550/1000 (55%)]\tLoss: 0.000263\t score_max: 5.114868\t score_min: -46.019276; Accuracy 0.997\n",
      "Train Epoch: 13 [600/1000 (60%)]\tLoss: 0.000310\t score_max: 5.115176\t score_min: -45.954002; Accuracy 0.996\n",
      "Train Epoch: 13 [650/1000 (65%)]\tLoss: 0.000176\t score_max: 5.115505\t score_min: -41.755749; Accuracy 0.996\n",
      "Train Epoch: 13 [700/1000 (70%)]\tLoss: 0.000502\t score_max: 5.115795\t score_min: -40.471756; Accuracy 0.994\n",
      "Train Epoch: 13 [750/1000 (75%)]\tLoss: 0.000658\t score_max: 5.116133\t score_min: -42.400200; Accuracy 0.994\n",
      "Train Epoch: 13 [800/1000 (80%)]\tLoss: 0.000708\t score_max: 5.116696\t score_min: -38.630642; Accuracy 0.991\n",
      "Train Epoch: 13 [850/1000 (85%)]\tLoss: 0.000646\t score_max: 5.117127\t score_min: -40.951542; Accuracy 0.993\n",
      "Train Epoch: 13 [900/1000 (90%)]\tLoss: 0.000483\t score_max: 5.117503\t score_min: -36.213299; Accuracy 0.992\n",
      "Train Epoch: 13 [950/1000 (95%)]\tLoss: 0.000405\t score_max: 5.117945\t score_min: -40.652283; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.00047241789579857143 ACCURACY: 0.9943499743938446\n",
      "Epoch:  14\n",
      "Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.000292\t score_max: 5.118267\t score_min: -38.389580; Accuracy 0.995\n",
      "Train Epoch: 14 [50/1000 (5%)]\tLoss: 0.000470\t score_max: 5.118524\t score_min: -40.473099; Accuracy 0.995\n",
      "Train Epoch: 14 [100/1000 (10%)]\tLoss: 0.000658\t score_max: 5.118663\t score_min: -36.811813; Accuracy 0.993\n",
      "Train Epoch: 14 [150/1000 (15%)]\tLoss: 0.000203\t score_max: 5.118778\t score_min: -41.882034; Accuracy 0.997\n",
      "Train Epoch: 14 [200/1000 (20%)]\tLoss: 0.000177\t score_max: 5.118857\t score_min: -44.967503; Accuracy 0.996\n",
      "Train Epoch: 14 [250/1000 (25%)]\tLoss: 0.000321\t score_max: 5.118915\t score_min: -43.485161; Accuracy 0.996\n",
      "Train Epoch: 14 [300/1000 (30%)]\tLoss: 0.000396\t score_max: 5.118974\t score_min: -37.760578; Accuracy 0.994\n",
      "Train Epoch: 14 [350/1000 (35%)]\tLoss: 0.000230\t score_max: 5.119121\t score_min: -40.647499; Accuracy 0.994\n",
      "Train Epoch: 14 [400/1000 (40%)]\tLoss: 0.000332\t score_max: 5.119270\t score_min: -37.996304; Accuracy 0.995\n",
      "Train Epoch: 14 [450/1000 (45%)]\tLoss: 0.000518\t score_max: 5.119340\t score_min: -41.818951; Accuracy 0.997\n",
      "Train Epoch: 14 [500/1000 (50%)]\tLoss: 0.000510\t score_max: 5.119538\t score_min: -43.874466; Accuracy 0.996\n",
      "Train Epoch: 14 [550/1000 (55%)]\tLoss: 0.000289\t score_max: 5.119833\t score_min: -42.224731; Accuracy 0.996\n",
      "Train Epoch: 14 [600/1000 (60%)]\tLoss: 0.000751\t score_max: 5.120138\t score_min: -37.036655; Accuracy 0.994\n",
      "Train Epoch: 14 [650/1000 (65%)]\tLoss: 0.000865\t score_max: 5.120569\t score_min: -41.090286; Accuracy 0.993\n",
      "Train Epoch: 14 [700/1000 (70%)]\tLoss: 0.000297\t score_max: 5.121023\t score_min: -42.040871; Accuracy 0.995\n",
      "Train Epoch: 14 [750/1000 (75%)]\tLoss: 0.000430\t score_max: 5.121380\t score_min: -41.138348; Accuracy 0.993\n",
      "Train Epoch: 14 [800/1000 (80%)]\tLoss: 0.000751\t score_max: 5.121747\t score_min: -39.388027; Accuracy 0.992\n",
      "Train Epoch: 14 [850/1000 (85%)]\tLoss: 0.000407\t score_max: 5.122165\t score_min: -36.403179; Accuracy 0.992\n",
      "Train Epoch: 14 [900/1000 (90%)]\tLoss: 0.000361\t score_max: 5.122605\t score_min: -43.931175; Accuracy 0.997\n",
      "Train Epoch: 14 [950/1000 (95%)]\tLoss: 0.000333\t score_max: 5.122952\t score_min: -39.449875; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00042956328979926184 ACCURACY: 0.994819974899292\n",
      "Epoch:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.000667\t score_max: 5.123291\t score_min: -37.497112; Accuracy 0.993\n",
      "Train Epoch: 15 [50/1000 (5%)]\tLoss: 0.000659\t score_max: 5.123585\t score_min: -41.835796; Accuracy 0.995\n",
      "Train Epoch: 15 [100/1000 (10%)]\tLoss: 0.000408\t score_max: 5.123632\t score_min: -39.637974; Accuracy 0.995\n",
      "Train Epoch: 15 [150/1000 (15%)]\tLoss: 0.000229\t score_max: 5.123764\t score_min: -45.318626; Accuracy 0.997\n",
      "Train Epoch: 15 [200/1000 (20%)]\tLoss: 0.000374\t score_max: 5.123889\t score_min: -37.238453; Accuracy 0.994\n",
      "Train Epoch: 15 [250/1000 (25%)]\tLoss: 0.000547\t score_max: 5.124061\t score_min: -44.499298; Accuracy 0.996\n",
      "Train Epoch: 15 [300/1000 (30%)]\tLoss: 0.000387\t score_max: 5.124194\t score_min: -41.030243; Accuracy 0.995\n",
      "Train Epoch: 15 [350/1000 (35%)]\tLoss: 0.000386\t score_max: 5.124288\t score_min: -33.050453; Accuracy 0.994\n",
      "Train Epoch: 15 [400/1000 (40%)]\tLoss: 0.000179\t score_max: 5.124539\t score_min: -42.022049; Accuracy 0.995\n",
      "Train Epoch: 15 [450/1000 (45%)]\tLoss: 0.000329\t score_max: 5.124802\t score_min: -39.174515; Accuracy 0.994\n",
      "Train Epoch: 15 [500/1000 (50%)]\tLoss: 0.000542\t score_max: 5.124993\t score_min: -39.015469; Accuracy 0.995\n",
      "Train Epoch: 15 [550/1000 (55%)]\tLoss: 0.000679\t score_max: 5.125227\t score_min: -39.327034; Accuracy 0.995\n",
      "Train Epoch: 15 [600/1000 (60%)]\tLoss: 0.000376\t score_max: 5.125310\t score_min: -38.156166; Accuracy 0.995\n",
      "Train Epoch: 15 [650/1000 (65%)]\tLoss: 0.000240\t score_max: 5.125290\t score_min: -43.817295; Accuracy 0.996\n",
      "Train Epoch: 15 [700/1000 (70%)]\tLoss: 0.000155\t score_max: 5.125271\t score_min: -45.185841; Accuracy 0.995\n",
      "Train Epoch: 15 [750/1000 (75%)]\tLoss: 0.000396\t score_max: 5.125269\t score_min: -37.818428; Accuracy 0.993\n",
      "Train Epoch: 15 [800/1000 (80%)]\tLoss: 0.000377\t score_max: 5.125380\t score_min: -37.915176; Accuracy 0.995\n",
      "Train Epoch: 15 [850/1000 (85%)]\tLoss: 0.000381\t score_max: 5.125601\t score_min: -37.320210; Accuracy 0.995\n",
      "Train Epoch: 15 [900/1000 (90%)]\tLoss: 0.000379\t score_max: 5.125748\t score_min: -42.729328; Accuracy 0.995\n",
      "Train Epoch: 15 [950/1000 (95%)]\tLoss: 0.000474\t score_max: 5.126008\t score_min: -41.912525; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00040816732434905133 ACCURACY: 0.9949174672365189\n",
      "Epoch:  16\n",
      "Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.000333\t score_max: 5.126413\t score_min: -45.855537; Accuracy 0.996\n",
      "Train Epoch: 16 [50/1000 (5%)]\tLoss: 0.000337\t score_max: 5.126816\t score_min: -39.035641; Accuracy 0.995\n",
      "Train Epoch: 16 [100/1000 (10%)]\tLoss: 0.000510\t score_max: 5.127278\t score_min: -46.217724; Accuracy 0.997\n",
      "Train Epoch: 16 [150/1000 (15%)]\tLoss: 0.000362\t score_max: 5.127816\t score_min: -39.351173; Accuracy 0.993\n",
      "Train Epoch: 16 [200/1000 (20%)]\tLoss: 0.000401\t score_max: 5.128419\t score_min: -45.360214; Accuracy 0.997\n",
      "Train Epoch: 16 [250/1000 (25%)]\tLoss: 0.000345\t score_max: 5.128934\t score_min: -37.448376; Accuracy 0.995\n",
      "Train Epoch: 16 [300/1000 (30%)]\tLoss: 0.000204\t score_max: 5.129317\t score_min: -45.867126; Accuracy 0.997\n",
      "Train Epoch: 16 [350/1000 (35%)]\tLoss: 0.000349\t score_max: 5.129622\t score_min: -39.124630; Accuracy 0.994\n",
      "Train Epoch: 16 [400/1000 (40%)]\tLoss: 0.000181\t score_max: 5.129876\t score_min: -40.248573; Accuracy 0.996\n",
      "Train Epoch: 16 [450/1000 (45%)]\tLoss: 0.000335\t score_max: 5.130097\t score_min: -39.482849; Accuracy 0.994\n",
      "Train Epoch: 16 [500/1000 (50%)]\tLoss: 0.000426\t score_max: 5.130267\t score_min: -40.392212; Accuracy 0.995\n",
      "Train Epoch: 16 [550/1000 (55%)]\tLoss: 0.000230\t score_max: 5.130327\t score_min: -40.124619; Accuracy 0.994\n",
      "Train Epoch: 16 [600/1000 (60%)]\tLoss: 0.000550\t score_max: 5.130418\t score_min: -37.444836; Accuracy 0.994\n",
      "Train Epoch: 16 [650/1000 (65%)]\tLoss: 0.000550\t score_max: 5.130414\t score_min: -41.335438; Accuracy 0.995\n",
      "Train Epoch: 16 [700/1000 (70%)]\tLoss: 0.000683\t score_max: 5.130434\t score_min: -38.846901; Accuracy 0.992\n",
      "Train Epoch: 16 [750/1000 (75%)]\tLoss: 0.000290\t score_max: 5.130664\t score_min: -43.170490; Accuracy 0.994\n",
      "Train Epoch: 16 [800/1000 (80%)]\tLoss: 0.000184\t score_max: 5.130912\t score_min: -40.619877; Accuracy 0.995\n",
      "Train Epoch: 16 [850/1000 (85%)]\tLoss: 0.000404\t score_max: 5.131125\t score_min: -45.401390; Accuracy 0.997\n",
      "Train Epoch: 16 [900/1000 (90%)]\tLoss: 0.000484\t score_max: 5.131443\t score_min: -39.479237; Accuracy 0.993\n",
      "Train Epoch: 16 [950/1000 (95%)]\tLoss: 0.001239\t score_max: 5.131639\t score_min: -37.673412; Accuracy 0.992\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041970712118200026 ACCURACY: 0.9947874695062637\n",
      "Epoch:  17\n",
      "Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.000201\t score_max: 5.132051\t score_min: -44.756889; Accuracy 0.996\n",
      "Train Epoch: 17 [50/1000 (5%)]\tLoss: 0.000091\t score_max: 5.132506\t score_min: -45.456253; Accuracy 0.998\n",
      "Train Epoch: 17 [100/1000 (10%)]\tLoss: 0.000525\t score_max: 5.132949\t score_min: -43.226685; Accuracy 0.992\n",
      "Train Epoch: 17 [150/1000 (15%)]\tLoss: 0.000536\t score_max: 5.133407\t score_min: -39.524464; Accuracy 0.995\n",
      "Train Epoch: 17 [200/1000 (20%)]\tLoss: 0.000539\t score_max: 5.133882\t score_min: -44.494289; Accuracy 0.995\n",
      "Train Epoch: 17 [250/1000 (25%)]\tLoss: 0.000763\t score_max: 5.134140\t score_min: -40.389446; Accuracy 0.993\n",
      "Train Epoch: 17 [300/1000 (30%)]\tLoss: 0.000659\t score_max: 5.134272\t score_min: -33.127769; Accuracy 0.993\n",
      "Train Epoch: 17 [350/1000 (35%)]\tLoss: 0.000512\t score_max: 5.134482\t score_min: -40.514614; Accuracy 0.994\n",
      "Train Epoch: 17 [400/1000 (40%)]\tLoss: 0.000297\t score_max: 5.134657\t score_min: -44.667770; Accuracy 0.995\n",
      "Train Epoch: 17 [450/1000 (45%)]\tLoss: 0.000374\t score_max: 5.134757\t score_min: -47.904160; Accuracy 0.996\n",
      "Train Epoch: 17 [500/1000 (50%)]\tLoss: 0.000771\t score_max: 5.134929\t score_min: -45.311142; Accuracy 0.994\n",
      "Train Epoch: 17 [550/1000 (55%)]\tLoss: 0.000451\t score_max: 5.135265\t score_min: -38.472595; Accuracy 0.993\n",
      "Train Epoch: 17 [600/1000 (60%)]\tLoss: 0.000255\t score_max: 5.135686\t score_min: -43.719631; Accuracy 0.996\n",
      "Train Epoch: 17 [650/1000 (65%)]\tLoss: 0.000449\t score_max: 5.136042\t score_min: -40.681541; Accuracy 0.996\n",
      "Train Epoch: 17 [700/1000 (70%)]\tLoss: 0.000525\t score_max: 5.136318\t score_min: -41.978870; Accuracy 0.994\n",
      "Train Epoch: 17 [750/1000 (75%)]\tLoss: 0.000273\t score_max: 5.136714\t score_min: -47.175655; Accuracy 0.996\n",
      "Train Epoch: 17 [800/1000 (80%)]\tLoss: 0.000379\t score_max: 5.137072\t score_min: -44.601791; Accuracy 0.996\n",
      "Train Epoch: 17 [850/1000 (85%)]\tLoss: 0.000376\t score_max: 5.137481\t score_min: -42.332813; Accuracy 0.994\n",
      "Train Epoch: 17 [900/1000 (90%)]\tLoss: 0.000337\t score_max: 5.137860\t score_min: -44.001335; Accuracy 0.995\n",
      "Train Epoch: 17 [950/1000 (95%)]\tLoss: 0.000452\t score_max: 5.138260\t score_min: -42.472672; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00043831641742144713 ACCURACY: 0.9948574811220169\n",
      "Epoch:  18\n",
      "Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.000313\t score_max: 5.138628\t score_min: -39.964352; Accuracy 0.993\n",
      "Train Epoch: 18 [50/1000 (5%)]\tLoss: 0.000355\t score_max: 5.138947\t score_min: -46.853058; Accuracy 0.995\n",
      "Train Epoch: 18 [100/1000 (10%)]\tLoss: 0.000538\t score_max: 5.139186\t score_min: -41.616222; Accuracy 0.994\n",
      "Train Epoch: 18 [150/1000 (15%)]\tLoss: 0.000840\t score_max: 5.139490\t score_min: -35.931999; Accuracy 0.993\n",
      "Train Epoch: 18 [200/1000 (20%)]\tLoss: 0.000356\t score_max: 5.139851\t score_min: -38.139408; Accuracy 0.993\n",
      "Train Epoch: 18 [250/1000 (25%)]\tLoss: 0.000263\t score_max: 5.140127\t score_min: -42.516327; Accuracy 0.996\n",
      "Train Epoch: 18 [300/1000 (30%)]\tLoss: 0.000378\t score_max: 5.140372\t score_min: -44.391064; Accuracy 0.997\n",
      "Train Epoch: 18 [350/1000 (35%)]\tLoss: 0.000335\t score_max: 5.140481\t score_min: -38.082222; Accuracy 0.994\n",
      "Train Epoch: 18 [400/1000 (40%)]\tLoss: 0.000477\t score_max: 5.140555\t score_min: -35.518360; Accuracy 0.993\n",
      "Train Epoch: 18 [450/1000 (45%)]\tLoss: 0.000510\t score_max: 5.140786\t score_min: -37.742401; Accuracy 0.994\n",
      "Train Epoch: 18 [500/1000 (50%)]\tLoss: 0.000267\t score_max: 5.140996\t score_min: -48.456207; Accuracy 0.998\n",
      "Train Epoch: 18 [550/1000 (55%)]\tLoss: 0.000374\t score_max: 5.141287\t score_min: -42.364952; Accuracy 0.996\n",
      "Train Epoch: 18 [600/1000 (60%)]\tLoss: 0.000957\t score_max: 5.141683\t score_min: -42.586742; Accuracy 0.994\n",
      "Train Epoch: 18 [650/1000 (65%)]\tLoss: 0.000394\t score_max: 5.142278\t score_min: -44.105392; Accuracy 0.996\n",
      "Train Epoch: 18 [700/1000 (70%)]\tLoss: 0.000427\t score_max: 5.142927\t score_min: -43.242363; Accuracy 0.995\n",
      "Train Epoch: 18 [750/1000 (75%)]\tLoss: 0.000244\t score_max: 5.143512\t score_min: -41.463852; Accuracy 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [800/1000 (80%)]\tLoss: 0.000525\t score_max: 5.144016\t score_min: -36.906841; Accuracy 0.995\n",
      "Train Epoch: 18 [850/1000 (85%)]\tLoss: 0.000380\t score_max: 5.144485\t score_min: -45.406277; Accuracy 0.995\n",
      "Train Epoch: 18 [900/1000 (90%)]\tLoss: 0.000440\t score_max: 5.144991\t score_min: -43.314991; Accuracy 0.995\n",
      "Train Epoch: 18 [950/1000 (95%)]\tLoss: 0.000389\t score_max: 5.145405\t score_min: -44.125477; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00043800699058920144 ACCURACY: 0.994929975271225\n",
      "Epoch:  19\n",
      "Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.000347\t score_max: 5.145844\t score_min: -42.460930; Accuracy 0.995\n",
      "Train Epoch: 19 [50/1000 (5%)]\tLoss: 0.000452\t score_max: 5.146309\t score_min: -41.845699; Accuracy 0.995\n",
      "Train Epoch: 19 [100/1000 (10%)]\tLoss: 0.000279\t score_max: 5.146629\t score_min: -44.603458; Accuracy 0.996\n",
      "Train Epoch: 19 [150/1000 (15%)]\tLoss: 0.000281\t score_max: 5.146858\t score_min: -45.904751; Accuracy 0.997\n",
      "Train Epoch: 19 [200/1000 (20%)]\tLoss: 0.000492\t score_max: 5.147024\t score_min: -38.918140; Accuracy 0.993\n",
      "Train Epoch: 19 [250/1000 (25%)]\tLoss: 0.000174\t score_max: 5.147121\t score_min: -44.221539; Accuracy 0.996\n",
      "Train Epoch: 19 [300/1000 (30%)]\tLoss: 0.000288\t score_max: 5.147157\t score_min: -44.386906; Accuracy 0.995\n",
      "Train Epoch: 19 [350/1000 (35%)]\tLoss: 0.000484\t score_max: 5.147250\t score_min: -42.533958; Accuracy 0.996\n",
      "Train Epoch: 19 [400/1000 (40%)]\tLoss: 0.000242\t score_max: 5.147259\t score_min: -41.265656; Accuracy 0.994\n",
      "Train Epoch: 19 [450/1000 (45%)]\tLoss: 0.000363\t score_max: 5.147342\t score_min: -39.881653; Accuracy 0.996\n",
      "Train Epoch: 19 [500/1000 (50%)]\tLoss: 0.000525\t score_max: 5.147310\t score_min: -42.514610; Accuracy 0.995\n",
      "Train Epoch: 19 [550/1000 (55%)]\tLoss: 0.000465\t score_max: 5.147531\t score_min: -41.732643; Accuracy 0.995\n",
      "Train Epoch: 19 [600/1000 (60%)]\tLoss: 0.000593\t score_max: 5.147739\t score_min: -44.833336; Accuracy 0.996\n",
      "Train Epoch: 19 [650/1000 (65%)]\tLoss: 0.000565\t score_max: 5.148035\t score_min: -39.788628; Accuracy 0.993\n",
      "Train Epoch: 19 [700/1000 (70%)]\tLoss: 0.000349\t score_max: 5.148429\t score_min: -41.909668; Accuracy 0.994\n",
      "Train Epoch: 19 [750/1000 (75%)]\tLoss: 0.000846\t score_max: 5.148845\t score_min: -38.066486; Accuracy 0.995\n",
      "Train Epoch: 19 [800/1000 (80%)]\tLoss: 0.000346\t score_max: 5.149313\t score_min: -38.070465; Accuracy 0.995\n",
      "Train Epoch: 19 [850/1000 (85%)]\tLoss: 0.000593\t score_max: 5.149654\t score_min: -37.879707; Accuracy 0.994\n",
      "Train Epoch: 19 [900/1000 (90%)]\tLoss: 0.000125\t score_max: 5.149932\t score_min: -37.701504; Accuracy 0.993\n",
      "Train Epoch: 19 [950/1000 (95%)]\tLoss: 0.000366\t score_max: 5.150209\t score_min: -44.363796; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00040867157149477863 ACCURACY: 0.9950274735689163\n",
      "Epoch:  20\n",
      "Train Epoch: 20 [0/1000 (0%)]\tLoss: 0.000466\t score_max: 5.150520\t score_min: -41.313221; Accuracy 0.995\n",
      "Train Epoch: 20 [50/1000 (5%)]\tLoss: 0.000335\t score_max: 5.150704\t score_min: -43.160564; Accuracy 0.995\n",
      "Train Epoch: 20 [100/1000 (10%)]\tLoss: 0.000579\t score_max: 5.150879\t score_min: -42.117268; Accuracy 0.994\n",
      "Train Epoch: 20 [150/1000 (15%)]\tLoss: 0.000249\t score_max: 5.151188\t score_min: -48.105282; Accuracy 0.996\n",
      "Train Epoch: 20 [200/1000 (20%)]\tLoss: 0.000179\t score_max: 5.151530\t score_min: -40.978374; Accuracy 0.995\n",
      "Train Epoch: 20 [250/1000 (25%)]\tLoss: 0.000475\t score_max: 5.151890\t score_min: -37.918446; Accuracy 0.994\n",
      "Train Epoch: 20 [300/1000 (30%)]\tLoss: 0.000381\t score_max: 5.152228\t score_min: -42.904144; Accuracy 0.995\n",
      "Train Epoch: 20 [350/1000 (35%)]\tLoss: 0.000403\t score_max: 5.152572\t score_min: -42.105953; Accuracy 0.996\n",
      "Train Epoch: 20 [400/1000 (40%)]\tLoss: 0.000521\t score_max: 5.152806\t score_min: -36.542828; Accuracy 0.992\n",
      "Train Epoch: 20 [450/1000 (45%)]\tLoss: 0.000377\t score_max: 5.153169\t score_min: -37.276939; Accuracy 0.992\n",
      "Train Epoch: 20 [500/1000 (50%)]\tLoss: 0.000433\t score_max: 5.153537\t score_min: -42.318729; Accuracy 0.994\n",
      "Train Epoch: 20 [550/1000 (55%)]\tLoss: 0.000426\t score_max: 5.153795\t score_min: -43.986782; Accuracy 0.995\n",
      "Train Epoch: 20 [600/1000 (60%)]\tLoss: 0.000439\t score_max: 5.153934\t score_min: -40.111130; Accuracy 0.994\n",
      "Train Epoch: 20 [650/1000 (65%)]\tLoss: 0.000440\t score_max: 5.154130\t score_min: -42.201641; Accuracy 0.996\n",
      "Train Epoch: 20 [700/1000 (70%)]\tLoss: 0.000337\t score_max: 5.154204\t score_min: -45.183937; Accuracy 0.997\n",
      "Train Epoch: 20 [750/1000 (75%)]\tLoss: 0.000255\t score_max: 5.154271\t score_min: -43.449852; Accuracy 0.997\n",
      "Train Epoch: 20 [800/1000 (80%)]\tLoss: 0.000538\t score_max: 5.154340\t score_min: -37.945091; Accuracy 0.993\n",
      "Train Epoch: 20 [850/1000 (85%)]\tLoss: 0.000264\t score_max: 5.154525\t score_min: -42.692978; Accuracy 0.994\n",
      "Train Epoch: 20 [900/1000 (90%)]\tLoss: 0.000685\t score_max: 5.154731\t score_min: -38.630543; Accuracy 0.993\n",
      "Train Epoch: 20 [950/1000 (95%)]\tLoss: 0.000329\t score_max: 5.155211\t score_min: -40.624409; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.000405553183372831 ACCURACY: 0.9945874750614166\n",
      "Epoch:  21\n",
      "Train Epoch: 21 [0/1000 (0%)]\tLoss: 0.000218\t score_max: 5.155619\t score_min: -40.393074; Accuracy 0.996\n",
      "Train Epoch: 21 [50/1000 (5%)]\tLoss: 0.000546\t score_max: 5.155940\t score_min: -36.978203; Accuracy 0.993\n",
      "Train Epoch: 21 [100/1000 (10%)]\tLoss: 0.000370\t score_max: 5.156385\t score_min: -44.301910; Accuracy 0.995\n",
      "Train Epoch: 21 [150/1000 (15%)]\tLoss: 0.000354\t score_max: 5.156806\t score_min: -39.948761; Accuracy 0.993\n",
      "Train Epoch: 21 [200/1000 (20%)]\tLoss: 0.000519\t score_max: 5.157245\t score_min: -44.492207; Accuracy 0.995\n",
      "Train Epoch: 21 [250/1000 (25%)]\tLoss: 0.000432\t score_max: 5.157702\t score_min: -41.374588; Accuracy 0.993\n",
      "Train Epoch: 21 [300/1000 (30%)]\tLoss: 0.000308\t score_max: 5.158079\t score_min: -45.627800; Accuracy 0.997\n",
      "Train Epoch: 21 [350/1000 (35%)]\tLoss: 0.000477\t score_max: 5.158451\t score_min: -39.264301; Accuracy 0.995\n",
      "Train Epoch: 21 [400/1000 (40%)]\tLoss: 0.000295\t score_max: 5.158822\t score_min: -45.627850; Accuracy 0.995\n",
      "Train Epoch: 21 [450/1000 (45%)]\tLoss: 0.000574\t score_max: 5.159156\t score_min: -42.864975; Accuracy 0.996\n",
      "Train Epoch: 21 [500/1000 (50%)]\tLoss: 0.000422\t score_max: 5.159361\t score_min: -39.670364; Accuracy 0.991\n",
      "Train Epoch: 21 [550/1000 (55%)]\tLoss: 0.000403\t score_max: 5.159665\t score_min: -41.497791; Accuracy 0.995\n",
      "Train Epoch: 21 [600/1000 (60%)]\tLoss: 0.000603\t score_max: 5.159912\t score_min: -40.756248; Accuracy 0.994\n",
      "Train Epoch: 21 [650/1000 (65%)]\tLoss: 0.000383\t score_max: 5.160207\t score_min: -38.438198; Accuracy 0.993\n",
      "Train Epoch: 21 [700/1000 (70%)]\tLoss: 0.000408\t score_max: 5.160524\t score_min: -41.458366; Accuracy 0.994\n",
      "Train Epoch: 21 [750/1000 (75%)]\tLoss: 0.000340\t score_max: 5.160785\t score_min: -43.849121; Accuracy 0.995\n",
      "Train Epoch: 21 [800/1000 (80%)]\tLoss: 0.000282\t score_max: 5.161055\t score_min: -45.811398; Accuracy 0.995\n",
      "Train Epoch: 21 [850/1000 (85%)]\tLoss: 0.000339\t score_max: 5.161311\t score_min: -52.933258; Accuracy 0.995\n",
      "Train Epoch: 21 [900/1000 (90%)]\tLoss: 0.000388\t score_max: 5.161656\t score_min: -44.844322; Accuracy 0.996\n",
      "Train Epoch: 21 [950/1000 (95%)]\tLoss: 0.000556\t score_max: 5.162043\t score_min: -44.116985; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041093419640674255 ACCURACY: 0.9944974780082703\n",
      "Epoch:  22\n",
      "Train Epoch: 22 [0/1000 (0%)]\tLoss: 0.000215\t score_max: 5.162473\t score_min: -43.438656; Accuracy 0.994\n",
      "Train Epoch: 22 [50/1000 (5%)]\tLoss: 0.000317\t score_max: 5.162979\t score_min: -41.425205; Accuracy 0.992\n",
      "Train Epoch: 22 [100/1000 (10%)]\tLoss: 0.000379\t score_max: 5.163485\t score_min: -45.385471; Accuracy 0.994\n",
      "Train Epoch: 22 [150/1000 (15%)]\tLoss: 0.000193\t score_max: 5.163939\t score_min: -43.378185; Accuracy 0.995\n",
      "Train Epoch: 22 [200/1000 (20%)]\tLoss: 0.000484\t score_max: 5.164331\t score_min: -42.410217; Accuracy 0.992\n",
      "Train Epoch: 22 [250/1000 (25%)]\tLoss: 0.000478\t score_max: 5.164670\t score_min: -37.082058; Accuracy 0.993\n",
      "Train Epoch: 22 [300/1000 (30%)]\tLoss: 0.000369\t score_max: 5.165000\t score_min: -44.826717; Accuracy 0.994\n",
      "Train Epoch: 22 [350/1000 (35%)]\tLoss: 0.000319\t score_max: 5.165256\t score_min: -41.476543; Accuracy 0.992\n",
      "Train Epoch: 22 [400/1000 (40%)]\tLoss: 0.000347\t score_max: 5.165561\t score_min: -44.500557; Accuracy 0.993\n",
      "Train Epoch: 22 [450/1000 (45%)]\tLoss: 0.000351\t score_max: 5.165858\t score_min: -41.731712; Accuracy 0.995\n",
      "Train Epoch: 22 [500/1000 (50%)]\tLoss: 0.000500\t score_max: 5.166053\t score_min: -43.505032; Accuracy 0.993\n",
      "Train Epoch: 22 [550/1000 (55%)]\tLoss: 0.000245\t score_max: 5.166431\t score_min: -38.504364; Accuracy 0.995\n",
      "Train Epoch: 22 [600/1000 (60%)]\tLoss: 0.000510\t score_max: 5.166847\t score_min: -40.741673; Accuracy 0.993\n",
      "Train Epoch: 22 [650/1000 (65%)]\tLoss: 0.000557\t score_max: 5.167232\t score_min: -45.209072; Accuracy 0.996\n",
      "Train Epoch: 22 [700/1000 (70%)]\tLoss: 0.000575\t score_max: 5.167596\t score_min: -40.044838; Accuracy 0.995\n",
      "Train Epoch: 22 [750/1000 (75%)]\tLoss: 0.000292\t score_max: 5.167794\t score_min: -40.693069; Accuracy 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [800/1000 (80%)]\tLoss: 0.000316\t score_max: 5.167981\t score_min: -43.221043; Accuracy 0.995\n",
      "Train Epoch: 22 [850/1000 (85%)]\tLoss: 0.000366\t score_max: 5.168072\t score_min: -43.703804; Accuracy 0.994\n",
      "Train Epoch: 22 [900/1000 (90%)]\tLoss: 0.000195\t score_max: 5.168270\t score_min: -48.417908; Accuracy 0.997\n",
      "Train Epoch: 22 [950/1000 (95%)]\tLoss: 0.000289\t score_max: 5.168478\t score_min: -43.181198; Accuracy 0.993\n",
      "---EPOCH AVG TRAIN LOSS: 0.00036492713625193576 ACCURACY: 0.9939699769020081\n",
      "Epoch:  23\n",
      "Train Epoch: 23 [0/1000 (0%)]\tLoss: 0.000471\t score_max: 5.168759\t score_min: -41.219635; Accuracy 0.993\n",
      "Train Epoch: 23 [50/1000 (5%)]\tLoss: 0.000224\t score_max: 5.169182\t score_min: -39.632957; Accuracy 0.993\n",
      "Train Epoch: 23 [100/1000 (10%)]\tLoss: 0.000358\t score_max: 5.169531\t score_min: -43.542717; Accuracy 0.996\n",
      "Train Epoch: 23 [150/1000 (15%)]\tLoss: 0.000217\t score_max: 5.169827\t score_min: -45.934868; Accuracy 0.996\n",
      "Train Epoch: 23 [200/1000 (20%)]\tLoss: 0.000309\t score_max: 5.170159\t score_min: -46.773190; Accuracy 0.996\n",
      "Train Epoch: 23 [250/1000 (25%)]\tLoss: 0.000429\t score_max: 5.170503\t score_min: -46.142262; Accuracy 0.994\n",
      "Train Epoch: 23 [300/1000 (30%)]\tLoss: 0.000607\t score_max: 5.171048\t score_min: -43.137066; Accuracy 0.996\n",
      "Train Epoch: 23 [350/1000 (35%)]\tLoss: 0.000376\t score_max: 5.171475\t score_min: -39.919216; Accuracy 0.994\n",
      "Train Epoch: 23 [400/1000 (40%)]\tLoss: 0.000322\t score_max: 5.171793\t score_min: -42.256580; Accuracy 0.993\n",
      "Train Epoch: 23 [450/1000 (45%)]\tLoss: 0.000351\t score_max: 5.172212\t score_min: -42.798584; Accuracy 0.995\n",
      "Train Epoch: 23 [500/1000 (50%)]\tLoss: 0.000402\t score_max: 5.172540\t score_min: -45.128937; Accuracy 0.994\n",
      "Train Epoch: 23 [550/1000 (55%)]\tLoss: 0.000511\t score_max: 5.172823\t score_min: -46.836006; Accuracy 0.995\n",
      "Train Epoch: 23 [600/1000 (60%)]\tLoss: 0.000088\t score_max: 5.172996\t score_min: -49.329674; Accuracy 0.997\n",
      "Train Epoch: 23 [650/1000 (65%)]\tLoss: 0.000397\t score_max: 5.173156\t score_min: -42.302132; Accuracy 0.992\n",
      "Train Epoch: 23 [700/1000 (70%)]\tLoss: 0.001007\t score_max: 5.173288\t score_min: -42.380920; Accuracy 0.992\n",
      "Train Epoch: 23 [750/1000 (75%)]\tLoss: 0.000651\t score_max: 5.173678\t score_min: -44.590073; Accuracy 0.995\n",
      "Train Epoch: 23 [800/1000 (80%)]\tLoss: 0.000548\t score_max: 5.173852\t score_min: -42.651825; Accuracy 0.994\n",
      "Train Epoch: 23 [850/1000 (85%)]\tLoss: 0.000220\t score_max: 5.174212\t score_min: -53.690464; Accuracy 0.997\n",
      "Train Epoch: 23 [900/1000 (90%)]\tLoss: 0.000287\t score_max: 5.174547\t score_min: -47.379917; Accuracy 0.995\n",
      "Train Epoch: 23 [950/1000 (95%)]\tLoss: 0.000241\t score_max: 5.174811\t score_min: -44.578278; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00040092926974466536 ACCURACY: 0.9945524752140045\n",
      "Epoch:  24\n",
      "Train Epoch: 24 [0/1000 (0%)]\tLoss: 0.000215\t score_max: 5.175162\t score_min: -47.415878; Accuracy 0.996\n",
      "Train Epoch: 24 [50/1000 (5%)]\tLoss: 0.000400\t score_max: 5.175513\t score_min: -42.271236; Accuracy 0.993\n",
      "Train Epoch: 24 [100/1000 (10%)]\tLoss: 0.000259\t score_max: 5.175943\t score_min: -47.836021; Accuracy 0.996\n",
      "Train Epoch: 24 [150/1000 (15%)]\tLoss: 0.000175\t score_max: 5.176317\t score_min: -45.376625; Accuracy 0.996\n",
      "Train Epoch: 24 [200/1000 (20%)]\tLoss: 0.000371\t score_max: 5.176696\t score_min: -42.265572; Accuracy 0.994\n",
      "Train Epoch: 24 [250/1000 (25%)]\tLoss: 0.000270\t score_max: 5.177098\t score_min: -43.338188; Accuracy 0.995\n",
      "Train Epoch: 24 [300/1000 (30%)]\tLoss: 0.000274\t score_max: 5.177515\t score_min: -47.113949; Accuracy 0.996\n",
      "Train Epoch: 24 [350/1000 (35%)]\tLoss: 0.000297\t score_max: 5.177920\t score_min: -49.195717; Accuracy 0.996\n",
      "Train Epoch: 24 [400/1000 (40%)]\tLoss: 0.000170\t score_max: 5.178316\t score_min: -47.665054; Accuracy 0.996\n",
      "Train Epoch: 24 [450/1000 (45%)]\tLoss: 0.000235\t score_max: 5.178704\t score_min: -40.647312; Accuracy 0.995\n",
      "Train Epoch: 24 [500/1000 (50%)]\tLoss: 0.000285\t score_max: 5.179034\t score_min: -39.316597; Accuracy 0.996\n",
      "Train Epoch: 24 [550/1000 (55%)]\tLoss: 0.000144\t score_max: 5.179231\t score_min: -50.282860; Accuracy 0.997\n",
      "Train Epoch: 24 [600/1000 (60%)]\tLoss: 0.000624\t score_max: 5.179439\t score_min: -40.681877; Accuracy 0.994\n",
      "Train Epoch: 24 [650/1000 (65%)]\tLoss: 0.000750\t score_max: 5.179583\t score_min: -43.931000; Accuracy 0.993\n",
      "Train Epoch: 24 [700/1000 (70%)]\tLoss: 0.000373\t score_max: 5.179801\t score_min: -42.932137; Accuracy 0.992\n",
      "Train Epoch: 24 [750/1000 (75%)]\tLoss: 0.000305\t score_max: 5.180126\t score_min: -40.022469; Accuracy 0.994\n",
      "Train Epoch: 24 [800/1000 (80%)]\tLoss: 0.000279\t score_max: 5.180401\t score_min: -44.937912; Accuracy 0.995\n",
      "Train Epoch: 24 [850/1000 (85%)]\tLoss: 0.000550\t score_max: 5.180674\t score_min: -43.791122; Accuracy 0.994\n",
      "Train Epoch: 24 [900/1000 (90%)]\tLoss: 0.000295\t score_max: 5.180900\t score_min: -44.671135; Accuracy 0.995\n",
      "Train Epoch: 24 [950/1000 (95%)]\tLoss: 0.000310\t score_max: 5.181193\t score_min: -41.444523; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00032896205520955847 ACCURACY: 0.9948249757289886\n",
      "Epoch:  25\n",
      "Train Epoch: 25 [0/1000 (0%)]\tLoss: 0.000228\t score_max: 5.181479\t score_min: -47.578960; Accuracy 0.996\n",
      "Train Epoch: 25 [50/1000 (5%)]\tLoss: 0.000363\t score_max: 5.181746\t score_min: -45.745220; Accuracy 0.994\n",
      "Train Epoch: 25 [100/1000 (10%)]\tLoss: 0.000269\t score_max: 5.181994\t score_min: -45.220737; Accuracy 0.995\n",
      "Train Epoch: 25 [150/1000 (15%)]\tLoss: 0.000352\t score_max: 5.182323\t score_min: -41.747028; Accuracy 0.995\n",
      "Train Epoch: 25 [200/1000 (20%)]\tLoss: 0.000182\t score_max: 5.182590\t score_min: -47.177235; Accuracy 0.995\n",
      "Train Epoch: 25 [250/1000 (25%)]\tLoss: 0.000748\t score_max: 5.182861\t score_min: -40.671818; Accuracy 0.994\n",
      "Train Epoch: 25 [300/1000 (30%)]\tLoss: 0.000406\t score_max: 5.183392\t score_min: -47.716499; Accuracy 0.995\n",
      "Train Epoch: 25 [350/1000 (35%)]\tLoss: 0.000489\t score_max: 5.183860\t score_min: -44.571766; Accuracy 0.996\n",
      "Train Epoch: 25 [400/1000 (40%)]\tLoss: 0.000497\t score_max: 5.184163\t score_min: -46.287262; Accuracy 0.994\n",
      "Train Epoch: 25 [450/1000 (45%)]\tLoss: 0.000217\t score_max: 5.184536\t score_min: -49.915993; Accuracy 0.996\n",
      "Train Epoch: 25 [500/1000 (50%)]\tLoss: 0.000153\t score_max: 5.184864\t score_min: -47.677311; Accuracy 0.997\n",
      "Train Epoch: 25 [550/1000 (55%)]\tLoss: 0.000373\t score_max: 5.185111\t score_min: -39.416569; Accuracy 0.993\n",
      "Train Epoch: 25 [600/1000 (60%)]\tLoss: 0.000373\t score_max: 5.185501\t score_min: -47.824062; Accuracy 0.996\n",
      "Train Epoch: 25 [650/1000 (65%)]\tLoss: 0.000227\t score_max: 5.185855\t score_min: -48.974831; Accuracy 0.996\n",
      "Train Epoch: 25 [700/1000 (70%)]\tLoss: 0.000332\t score_max: 5.186255\t score_min: -48.271027; Accuracy 0.996\n",
      "Train Epoch: 25 [750/1000 (75%)]\tLoss: 0.000425\t score_max: 5.186701\t score_min: -38.621170; Accuracy 0.992\n",
      "Train Epoch: 25 [800/1000 (80%)]\tLoss: 0.000186\t score_max: 5.187091\t score_min: -42.591309; Accuracy 0.996\n",
      "Train Epoch: 25 [850/1000 (85%)]\tLoss: 0.000465\t score_max: 5.187420\t score_min: -45.437958; Accuracy 0.995\n",
      "Train Epoch: 25 [900/1000 (90%)]\tLoss: 0.000382\t score_max: 5.187647\t score_min: -40.459946; Accuracy 0.993\n",
      "Train Epoch: 25 [950/1000 (95%)]\tLoss: 0.000916\t score_max: 5.187891\t score_min: -39.373985; Accuracy 0.991\n",
      "---EPOCH AVG TRAIN LOSS: 0.000379080131824594 ACCURACY: 0.9948249757289886\n",
      "Epoch:  26\n",
      "Train Epoch: 26 [0/1000 (0%)]\tLoss: 0.000442\t score_max: 5.188500\t score_min: -43.436253; Accuracy 0.994\n",
      "Train Epoch: 26 [50/1000 (5%)]\tLoss: 0.000362\t score_max: 5.189051\t score_min: -45.115128; Accuracy 0.993\n",
      "Train Epoch: 26 [100/1000 (10%)]\tLoss: 0.000274\t score_max: 5.189588\t score_min: -48.270531; Accuracy 0.996\n",
      "Train Epoch: 26 [150/1000 (15%)]\tLoss: 0.000184\t score_max: 5.190036\t score_min: -46.379051; Accuracy 0.996\n",
      "Train Epoch: 26 [200/1000 (20%)]\tLoss: 0.000477\t score_max: 5.190416\t score_min: -39.230091; Accuracy 0.993\n",
      "Train Epoch: 26 [250/1000 (25%)]\tLoss: 0.000523\t score_max: 5.190768\t score_min: -47.075863; Accuracy 0.996\n",
      "Train Epoch: 26 [300/1000 (30%)]\tLoss: 0.000415\t score_max: 5.190984\t score_min: -44.435738; Accuracy 0.994\n",
      "Train Epoch: 26 [350/1000 (35%)]\tLoss: 0.000413\t score_max: 5.191078\t score_min: -45.985695; Accuracy 0.994\n",
      "Train Epoch: 26 [400/1000 (40%)]\tLoss: 0.000432\t score_max: 5.191061\t score_min: -43.494225; Accuracy 0.992\n",
      "Train Epoch: 26 [450/1000 (45%)]\tLoss: 0.000425\t score_max: 5.191173\t score_min: -47.958393; Accuracy 0.995\n",
      "Train Epoch: 26 [500/1000 (50%)]\tLoss: 0.000675\t score_max: 5.191432\t score_min: -45.517559; Accuracy 0.994\n",
      "Train Epoch: 26 [550/1000 (55%)]\tLoss: 0.000311\t score_max: 5.191844\t score_min: -43.846989; Accuracy 0.995\n",
      "Train Epoch: 26 [600/1000 (60%)]\tLoss: 0.000526\t score_max: 5.192148\t score_min: -43.026031; Accuracy 0.995\n",
      "Train Epoch: 26 [650/1000 (65%)]\tLoss: 0.000354\t score_max: 5.192529\t score_min: -48.867146; Accuracy 0.996\n",
      "Train Epoch: 26 [700/1000 (70%)]\tLoss: 0.000770\t score_max: 5.192939\t score_min: -41.272324; Accuracy 0.992\n",
      "Train Epoch: 26 [750/1000 (75%)]\tLoss: 0.000463\t score_max: 5.193542\t score_min: -48.273132; Accuracy 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [800/1000 (80%)]\tLoss: 0.000262\t score_max: 5.194111\t score_min: -48.637417; Accuracy 0.994\n",
      "Train Epoch: 26 [850/1000 (85%)]\tLoss: 0.000244\t score_max: 5.194605\t score_min: -47.842384; Accuracy 0.995\n",
      "Train Epoch: 26 [900/1000 (90%)]\tLoss: 0.000290\t score_max: 5.195031\t score_min: -46.278152; Accuracy 0.994\n",
      "Train Epoch: 26 [950/1000 (95%)]\tLoss: 0.000478\t score_max: 5.195375\t score_min: -40.829124; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041612302302382884 ACCURACY: 0.9944574773311615\n",
      "Epoch:  27\n",
      "Train Epoch: 27 [0/1000 (0%)]\tLoss: 0.000518\t score_max: 5.195709\t score_min: -44.249195; Accuracy 0.995\n",
      "Train Epoch: 27 [50/1000 (5%)]\tLoss: 0.000550\t score_max: 5.195959\t score_min: -45.351471; Accuracy 0.996\n",
      "Train Epoch: 27 [100/1000 (10%)]\tLoss: 0.000564\t score_max: 5.196095\t score_min: -43.653873; Accuracy 0.993\n",
      "Train Epoch: 27 [150/1000 (15%)]\tLoss: 0.000257\t score_max: 5.196142\t score_min: -47.452484; Accuracy 0.998\n",
      "Train Epoch: 27 [200/1000 (20%)]\tLoss: 0.000578\t score_max: 5.196203\t score_min: -43.864792; Accuracy 0.994\n",
      "Train Epoch: 27 [250/1000 (25%)]\tLoss: 0.000662\t score_max: 5.196363\t score_min: -45.348572; Accuracy 0.994\n",
      "Train Epoch: 27 [300/1000 (30%)]\tLoss: 0.000482\t score_max: 5.196550\t score_min: -39.885071; Accuracy 0.993\n",
      "Train Epoch: 27 [350/1000 (35%)]\tLoss: 0.000262\t score_max: 5.196758\t score_min: -41.195522; Accuracy 0.994\n",
      "Train Epoch: 27 [400/1000 (40%)]\tLoss: 0.000520\t score_max: 5.196997\t score_min: -39.570274; Accuracy 0.993\n",
      "Train Epoch: 27 [450/1000 (45%)]\tLoss: 0.000550\t score_max: 5.197343\t score_min: -46.157410; Accuracy 0.995\n",
      "Train Epoch: 27 [500/1000 (50%)]\tLoss: 0.000359\t score_max: 5.197848\t score_min: -42.875977; Accuracy 0.994\n",
      "Train Epoch: 27 [550/1000 (55%)]\tLoss: 0.000311\t score_max: 5.198384\t score_min: -48.509480; Accuracy 0.995\n",
      "Train Epoch: 27 [600/1000 (60%)]\tLoss: 0.000572\t score_max: 5.198885\t score_min: -41.365414; Accuracy 0.991\n",
      "Train Epoch: 27 [650/1000 (65%)]\tLoss: 0.000095\t score_max: 5.199502\t score_min: -46.659611; Accuracy 0.997\n",
      "Train Epoch: 27 [700/1000 (70%)]\tLoss: 0.000457\t score_max: 5.200078\t score_min: -44.887363; Accuracy 0.996\n",
      "Train Epoch: 27 [750/1000 (75%)]\tLoss: 0.000350\t score_max: 5.200457\t score_min: -45.433781; Accuracy 0.996\n",
      "Train Epoch: 27 [800/1000 (80%)]\tLoss: 0.000206\t score_max: 5.200817\t score_min: -48.764778; Accuracy 0.996\n",
      "Train Epoch: 27 [850/1000 (85%)]\tLoss: 0.000360\t score_max: 5.201193\t score_min: -43.643166; Accuracy 0.993\n",
      "Train Epoch: 27 [900/1000 (90%)]\tLoss: 0.000406\t score_max: 5.201426\t score_min: -46.435566; Accuracy 0.996\n",
      "Train Epoch: 27 [950/1000 (95%)]\tLoss: 0.000572\t score_max: 5.201498\t score_min: -41.151314; Accuracy 0.993\n",
      "---EPOCH AVG TRAIN LOSS: 0.00043156311257916966 ACCURACY: 0.9946174770593643\n",
      "Epoch:  28\n",
      "Train Epoch: 28 [0/1000 (0%)]\tLoss: 0.000371\t score_max: 5.201373\t score_min: -40.795403; Accuracy 0.994\n",
      "Train Epoch: 28 [50/1000 (5%)]\tLoss: 0.000258\t score_max: 5.201198\t score_min: -41.064247; Accuracy 0.996\n",
      "Train Epoch: 28 [100/1000 (10%)]\tLoss: 0.000300\t score_max: 5.200963\t score_min: -47.986118; Accuracy 0.995\n",
      "Train Epoch: 28 [150/1000 (15%)]\tLoss: 0.000684\t score_max: 5.200914\t score_min: -49.317719; Accuracy 0.996\n",
      "Train Epoch: 28 [200/1000 (20%)]\tLoss: 0.000350\t score_max: 5.201059\t score_min: -49.734444; Accuracy 0.996\n",
      "Train Epoch: 28 [250/1000 (25%)]\tLoss: 0.000225\t score_max: 5.201232\t score_min: -49.775669; Accuracy 0.995\n",
      "Train Epoch: 28 [300/1000 (30%)]\tLoss: 0.000633\t score_max: 5.201463\t score_min: -39.088909; Accuracy 0.994\n",
      "Train Epoch: 28 [350/1000 (35%)]\tLoss: 0.000951\t score_max: 5.201847\t score_min: -44.635151; Accuracy 0.995\n",
      "Train Epoch: 28 [400/1000 (40%)]\tLoss: 0.000361\t score_max: 5.202260\t score_min: -51.850903; Accuracy 0.996\n",
      "Train Epoch: 28 [450/1000 (45%)]\tLoss: 0.000319\t score_max: 5.202693\t score_min: -47.729218; Accuracy 0.996\n",
      "Train Epoch: 28 [500/1000 (50%)]\tLoss: 0.000181\t score_max: 5.203089\t score_min: -46.419834; Accuracy 0.995\n",
      "Train Epoch: 28 [550/1000 (55%)]\tLoss: 0.000219\t score_max: 5.203434\t score_min: -45.193352; Accuracy 0.995\n",
      "Train Epoch: 28 [600/1000 (60%)]\tLoss: 0.000095\t score_max: 5.203801\t score_min: -50.529419; Accuracy 0.996\n",
      "Train Epoch: 28 [650/1000 (65%)]\tLoss: 0.000340\t score_max: 5.204126\t score_min: -47.783154; Accuracy 0.995\n",
      "Train Epoch: 28 [700/1000 (70%)]\tLoss: 0.000469\t score_max: 5.204413\t score_min: -48.105598; Accuracy 0.995\n",
      "Train Epoch: 28 [750/1000 (75%)]\tLoss: 0.000478\t score_max: 5.204607\t score_min: -44.259396; Accuracy 0.995\n",
      "Train Epoch: 28 [800/1000 (80%)]\tLoss: 0.000435\t score_max: 5.204638\t score_min: -38.398521; Accuracy 0.992\n",
      "Train Epoch: 28 [850/1000 (85%)]\tLoss: 0.000307\t score_max: 5.204781\t score_min: -46.032436; Accuracy 0.994\n",
      "Train Epoch: 28 [900/1000 (90%)]\tLoss: 0.000236\t score_max: 5.204919\t score_min: -45.016735; Accuracy 0.996\n",
      "Train Epoch: 28 [950/1000 (95%)]\tLoss: 0.000246\t score_max: 5.204979\t score_min: -44.320492; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003728754938492784 ACCURACY: 0.9951349765062332\n",
      "Epoch:  29\n",
      "Train Epoch: 29 [0/1000 (0%)]\tLoss: 0.000207\t score_max: 5.205148\t score_min: -42.460697; Accuracy 0.995\n",
      "Train Epoch: 29 [50/1000 (5%)]\tLoss: 0.000348\t score_max: 5.205348\t score_min: -43.085472; Accuracy 0.995\n",
      "Train Epoch: 29 [100/1000 (10%)]\tLoss: 0.000542\t score_max: 5.205580\t score_min: -44.073318; Accuracy 0.993\n",
      "Train Epoch: 29 [150/1000 (15%)]\tLoss: 0.000648\t score_max: 5.205968\t score_min: -44.115646; Accuracy 0.994\n",
      "Train Epoch: 29 [200/1000 (20%)]\tLoss: 0.000299\t score_max: 5.206523\t score_min: -48.576260; Accuracy 0.996\n",
      "Train Epoch: 29 [250/1000 (25%)]\tLoss: 0.000366\t score_max: 5.207151\t score_min: -42.688240; Accuracy 0.995\n",
      "Train Epoch: 29 [300/1000 (30%)]\tLoss: 0.000621\t score_max: 5.207708\t score_min: -48.269207; Accuracy 0.994\n",
      "Train Epoch: 29 [350/1000 (35%)]\tLoss: 0.000593\t score_max: 5.208288\t score_min: -41.046207; Accuracy 0.993\n",
      "Train Epoch: 29 [400/1000 (40%)]\tLoss: 0.000613\t score_max: 5.208965\t score_min: -38.920170; Accuracy 0.992\n",
      "Train Epoch: 29 [450/1000 (45%)]\tLoss: 0.000768\t score_max: 5.209623\t score_min: -43.207375; Accuracy 0.995\n",
      "Train Epoch: 29 [500/1000 (50%)]\tLoss: 0.000649\t score_max: 5.209988\t score_min: -42.380112; Accuracy 0.995\n",
      "Train Epoch: 29 [550/1000 (55%)]\tLoss: 0.000287\t score_max: 5.210116\t score_min: -44.755615; Accuracy 0.995\n",
      "Train Epoch: 29 [600/1000 (60%)]\tLoss: 0.000213\t score_max: 5.210225\t score_min: -47.749294; Accuracy 0.997\n",
      "Train Epoch: 29 [650/1000 (65%)]\tLoss: 0.000514\t score_max: 5.210295\t score_min: -45.199856; Accuracy 0.993\n",
      "Train Epoch: 29 [700/1000 (70%)]\tLoss: 0.000266\t score_max: 5.210302\t score_min: -48.478958; Accuracy 0.996\n",
      "Train Epoch: 29 [750/1000 (75%)]\tLoss: 0.000319\t score_max: 5.210248\t score_min: -42.151714; Accuracy 0.995\n",
      "Train Epoch: 29 [800/1000 (80%)]\tLoss: 0.000251\t score_max: 5.210164\t score_min: -45.851715; Accuracy 0.995\n",
      "Train Epoch: 29 [850/1000 (85%)]\tLoss: 0.000086\t score_max: 5.210139\t score_min: -50.444042; Accuracy 0.998\n",
      "Train Epoch: 29 [900/1000 (90%)]\tLoss: 0.000346\t score_max: 5.210142\t score_min: -48.825233; Accuracy 0.997\n",
      "Train Epoch: 29 [950/1000 (95%)]\tLoss: 0.000312\t score_max: 5.210192\t score_min: -41.870972; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004124927283555735 ACCURACY: 0.9947774738073349\n",
      "Epoch:  30\n",
      "Train Epoch: 30 [0/1000 (0%)]\tLoss: 0.000208\t score_max: 5.210337\t score_min: -47.163727; Accuracy 0.996\n",
      "Train Epoch: 30 [50/1000 (5%)]\tLoss: 0.000195\t score_max: 5.210543\t score_min: -51.477180; Accuracy 0.996\n",
      "Train Epoch: 30 [100/1000 (10%)]\tLoss: 0.000456\t score_max: 5.210796\t score_min: -44.501038; Accuracy 0.996\n",
      "Train Epoch: 30 [150/1000 (15%)]\tLoss: 0.000444\t score_max: 5.210969\t score_min: -46.179356; Accuracy 0.996\n",
      "Train Epoch: 30 [200/1000 (20%)]\tLoss: 0.000427\t score_max: 5.211252\t score_min: -41.692841; Accuracy 0.994\n",
      "Train Epoch: 30 [250/1000 (25%)]\tLoss: 0.000471\t score_max: 5.211613\t score_min: -47.653633; Accuracy 0.995\n",
      "Train Epoch: 30 [300/1000 (30%)]\tLoss: 0.000310\t score_max: 5.212121\t score_min: -44.044098; Accuracy 0.996\n",
      "Train Epoch: 30 [350/1000 (35%)]\tLoss: 0.000179\t score_max: 5.212549\t score_min: -45.781830; Accuracy 0.995\n",
      "Train Epoch: 30 [400/1000 (40%)]\tLoss: 0.000430\t score_max: 5.213006\t score_min: -50.446220; Accuracy 0.998\n",
      "Train Epoch: 30 [450/1000 (45%)]\tLoss: 0.000253\t score_max: 5.213473\t score_min: -48.727146; Accuracy 0.996\n",
      "Train Epoch: 30 [500/1000 (50%)]\tLoss: 0.000377\t score_max: 5.213924\t score_min: -48.443634; Accuracy 0.995\n",
      "Train Epoch: 30 [550/1000 (55%)]\tLoss: 0.000499\t score_max: 5.214378\t score_min: -46.113670; Accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [600/1000 (60%)]\tLoss: 0.000204\t score_max: 5.214787\t score_min: -47.614388; Accuracy 0.995\n",
      "Train Epoch: 30 [650/1000 (65%)]\tLoss: 0.000663\t score_max: 5.215179\t score_min: -40.309769; Accuracy 0.995\n",
      "Train Epoch: 30 [700/1000 (70%)]\tLoss: 0.000134\t score_max: 5.215416\t score_min: -49.825211; Accuracy 0.996\n",
      "Train Epoch: 30 [750/1000 (75%)]\tLoss: 0.000447\t score_max: 5.215633\t score_min: -41.629040; Accuracy 0.992\n",
      "Train Epoch: 30 [800/1000 (80%)]\tLoss: 0.000338\t score_max: 5.215769\t score_min: -45.238514; Accuracy 0.994\n",
      "Train Epoch: 30 [850/1000 (85%)]\tLoss: 0.000356\t score_max: 5.215912\t score_min: -45.224167; Accuracy 0.994\n",
      "Train Epoch: 30 [900/1000 (90%)]\tLoss: 0.000847\t score_max: 5.216056\t score_min: -41.847893; Accuracy 0.993\n",
      "Train Epoch: 30 [950/1000 (95%)]\tLoss: 0.000565\t score_max: 5.215933\t score_min: -42.550938; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00039003461060929114 ACCURACY: 0.9950724840164185\n",
      "Epoch:  31\n",
      "Train Epoch: 31 [0/1000 (0%)]\tLoss: 0.000133\t score_max: 5.215822\t score_min: -48.762981; Accuracy 0.996\n",
      "Train Epoch: 31 [50/1000 (5%)]\tLoss: 0.000449\t score_max: 5.215695\t score_min: -43.515030; Accuracy 0.996\n",
      "Train Epoch: 31 [100/1000 (10%)]\tLoss: 0.000322\t score_max: 5.215714\t score_min: -44.985275; Accuracy 0.994\n",
      "Train Epoch: 31 [150/1000 (15%)]\tLoss: 0.000389\t score_max: 5.215801\t score_min: -45.848938; Accuracy 0.996\n",
      "Train Epoch: 31 [200/1000 (20%)]\tLoss: 0.000156\t score_max: 5.215875\t score_min: -50.353657; Accuracy 0.997\n",
      "Train Epoch: 31 [250/1000 (25%)]\tLoss: 0.000631\t score_max: 5.216027\t score_min: -40.059643; Accuracy 0.993\n",
      "Train Epoch: 31 [300/1000 (30%)]\tLoss: 0.000333\t score_max: 5.216330\t score_min: -48.329628; Accuracy 0.996\n",
      "Train Epoch: 31 [350/1000 (35%)]\tLoss: 0.000221\t score_max: 5.216709\t score_min: -47.888157; Accuracy 0.995\n",
      "Train Epoch: 31 [400/1000 (40%)]\tLoss: 0.000199\t score_max: 5.217157\t score_min: -51.204369; Accuracy 0.997\n",
      "Train Epoch: 31 [450/1000 (45%)]\tLoss: 0.000462\t score_max: 5.217608\t score_min: -50.705879; Accuracy 0.995\n",
      "Train Epoch: 31 [500/1000 (50%)]\tLoss: 0.000356\t score_max: 5.218230\t score_min: -49.695377; Accuracy 0.995\n",
      "Train Epoch: 31 [550/1000 (55%)]\tLoss: 0.000234\t score_max: 5.218777\t score_min: -46.947079; Accuracy 0.996\n",
      "Train Epoch: 31 [600/1000 (60%)]\tLoss: 0.000528\t score_max: 5.219303\t score_min: -44.886261; Accuracy 0.995\n",
      "Train Epoch: 31 [650/1000 (65%)]\tLoss: 0.001547\t score_max: 5.219597\t score_min: -38.337135; Accuracy 0.990\n",
      "Train Epoch: 31 [700/1000 (70%)]\tLoss: 0.000351\t score_max: 5.220269\t score_min: -41.210304; Accuracy 0.993\n",
      "Train Epoch: 31 [750/1000 (75%)]\tLoss: 0.000584\t score_max: 5.220824\t score_min: -41.171726; Accuracy 0.994\n",
      "Train Epoch: 31 [800/1000 (80%)]\tLoss: 0.000509\t score_max: 5.221197\t score_min: -44.661083; Accuracy 0.992\n",
      "Train Epoch: 31 [850/1000 (85%)]\tLoss: 0.000407\t score_max: 5.221514\t score_min: -44.995926; Accuracy 0.991\n",
      "Train Epoch: 31 [900/1000 (90%)]\tLoss: 0.000408\t score_max: 5.221775\t score_min: -44.626358; Accuracy 0.996\n",
      "Train Epoch: 31 [950/1000 (95%)]\tLoss: 0.000618\t score_max: 5.221871\t score_min: -37.987839; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004418981319759041 ACCURACY: 0.9946124732494355\n",
      "Epoch:  32\n",
      "Train Epoch: 32 [0/1000 (0%)]\tLoss: 0.000213\t score_max: 5.221763\t score_min: -46.879436; Accuracy 0.996\n",
      "Train Epoch: 32 [50/1000 (5%)]\tLoss: 0.000521\t score_max: 5.221702\t score_min: -52.737095; Accuracy 0.996\n",
      "Train Epoch: 32 [100/1000 (10%)]\tLoss: 0.000201\t score_max: 5.221766\t score_min: -42.489113; Accuracy 0.996\n",
      "Train Epoch: 32 [150/1000 (15%)]\tLoss: 0.000363\t score_max: 5.221887\t score_min: -46.562004; Accuracy 0.996\n",
      "Train Epoch: 32 [200/1000 (20%)]\tLoss: 0.000301\t score_max: 5.221966\t score_min: -45.329353; Accuracy 0.996\n",
      "Train Epoch: 32 [250/1000 (25%)]\tLoss: 0.000147\t score_max: 5.222098\t score_min: -45.167458; Accuracy 0.996\n",
      "Train Epoch: 32 [300/1000 (30%)]\tLoss: 0.000335\t score_max: 5.222205\t score_min: -43.689758; Accuracy 0.993\n",
      "Train Epoch: 32 [350/1000 (35%)]\tLoss: 0.000234\t score_max: 5.222425\t score_min: -51.272095; Accuracy 0.995\n",
      "Train Epoch: 32 [400/1000 (40%)]\tLoss: 0.000812\t score_max: 5.222668\t score_min: -45.006630; Accuracy 0.993\n",
      "Train Epoch: 32 [450/1000 (45%)]\tLoss: 0.000425\t score_max: 5.223091\t score_min: -48.305801; Accuracy 0.995\n",
      "Train Epoch: 32 [500/1000 (50%)]\tLoss: 0.000402\t score_max: 5.223616\t score_min: -44.894287; Accuracy 0.995\n",
      "Train Epoch: 32 [550/1000 (55%)]\tLoss: 0.000334\t score_max: 5.224078\t score_min: -44.862331; Accuracy 0.994\n",
      "Train Epoch: 32 [600/1000 (60%)]\tLoss: 0.000158\t score_max: 5.224497\t score_min: -48.307465; Accuracy 0.996\n",
      "Train Epoch: 32 [650/1000 (65%)]\tLoss: 0.000657\t score_max: 5.224946\t score_min: -43.204075; Accuracy 0.993\n",
      "Train Epoch: 32 [700/1000 (70%)]\tLoss: 0.000355\t score_max: 5.225536\t score_min: -49.432549; Accuracy 0.995\n",
      "Train Epoch: 32 [750/1000 (75%)]\tLoss: 0.000572\t score_max: 5.226063\t score_min: -45.331593; Accuracy 0.991\n",
      "Train Epoch: 32 [800/1000 (80%)]\tLoss: 0.000429\t score_max: 5.226735\t score_min: -44.398331; Accuracy 0.996\n",
      "Train Epoch: 32 [850/1000 (85%)]\tLoss: 0.000833\t score_max: 5.227236\t score_min: -41.085655; Accuracy 0.993\n",
      "Train Epoch: 32 [900/1000 (90%)]\tLoss: 0.000517\t score_max: 5.227536\t score_min: -45.447590; Accuracy 0.993\n",
      "Train Epoch: 32 [950/1000 (95%)]\tLoss: 0.000318\t score_max: 5.227669\t score_min: -52.848701; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004063343942107167 ACCURACY: 0.9947049736976623\n",
      "Epoch:  33\n",
      "Train Epoch: 33 [0/1000 (0%)]\tLoss: 0.000491\t score_max: 5.227725\t score_min: -50.872753; Accuracy 0.996\n",
      "Train Epoch: 33 [50/1000 (5%)]\tLoss: 0.000361\t score_max: 5.227633\t score_min: -45.818295; Accuracy 0.995\n",
      "Train Epoch: 33 [100/1000 (10%)]\tLoss: 0.000399\t score_max: 5.227456\t score_min: -45.448776; Accuracy 0.995\n",
      "Train Epoch: 33 [150/1000 (15%)]\tLoss: 0.000581\t score_max: 5.227185\t score_min: -48.005329; Accuracy 0.994\n",
      "Train Epoch: 33 [200/1000 (20%)]\tLoss: 0.000508\t score_max: 5.227025\t score_min: -48.070969; Accuracy 0.995\n",
      "Train Epoch: 33 [250/1000 (25%)]\tLoss: 0.000481\t score_max: 5.226841\t score_min: -50.384277; Accuracy 0.998\n",
      "Train Epoch: 33 [300/1000 (30%)]\tLoss: 0.001352\t score_max: 5.226633\t score_min: -44.842422; Accuracy 0.995\n",
      "Train Epoch: 33 [350/1000 (35%)]\tLoss: 0.000295\t score_max: 5.226751\t score_min: -48.711372; Accuracy 0.996\n",
      "Train Epoch: 33 [400/1000 (40%)]\tLoss: 0.000247\t score_max: 5.226986\t score_min: -48.233936; Accuracy 0.996\n",
      "Train Epoch: 33 [450/1000 (45%)]\tLoss: 0.000426\t score_max: 5.227302\t score_min: -47.164276; Accuracy 0.994\n",
      "Train Epoch: 33 [500/1000 (50%)]\tLoss: 0.000501\t score_max: 5.227673\t score_min: -45.355042; Accuracy 0.994\n",
      "Train Epoch: 33 [550/1000 (55%)]\tLoss: 0.000189\t score_max: 5.228151\t score_min: -48.912476; Accuracy 0.996\n",
      "Train Epoch: 33 [600/1000 (60%)]\tLoss: 0.000552\t score_max: 5.228611\t score_min: -41.934967; Accuracy 0.995\n",
      "Train Epoch: 33 [650/1000 (65%)]\tLoss: 0.000586\t score_max: 5.229072\t score_min: -47.106667; Accuracy 0.995\n",
      "Train Epoch: 33 [700/1000 (70%)]\tLoss: 0.000287\t score_max: 5.229587\t score_min: -50.131905; Accuracy 0.996\n",
      "Train Epoch: 33 [750/1000 (75%)]\tLoss: 0.000609\t score_max: 5.230133\t score_min: -45.053867; Accuracy 0.992\n",
      "Train Epoch: 33 [800/1000 (80%)]\tLoss: 0.000526\t score_max: 5.230687\t score_min: -43.968025; Accuracy 0.995\n",
      "Train Epoch: 33 [850/1000 (85%)]\tLoss: 0.000407\t score_max: 5.231021\t score_min: -34.886372; Accuracy 0.992\n",
      "Train Epoch: 33 [900/1000 (90%)]\tLoss: 0.000406\t score_max: 5.231413\t score_min: -38.226864; Accuracy 0.994\n",
      "Train Epoch: 33 [950/1000 (95%)]\tLoss: 0.000435\t score_max: 5.231718\t score_min: -46.419243; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004818868495931383 ACCURACY: 0.9949424713850021\n",
      "Epoch:  34\n",
      "Train Epoch: 34 [0/1000 (0%)]\tLoss: 0.000592\t score_max: 5.231865\t score_min: -44.157974; Accuracy 0.995\n",
      "Train Epoch: 34 [50/1000 (5%)]\tLoss: 0.000553\t score_max: 5.231868\t score_min: -43.668957; Accuracy 0.995\n",
      "Train Epoch: 34 [100/1000 (10%)]\tLoss: 0.000377\t score_max: 5.231733\t score_min: -50.651718; Accuracy 0.996\n",
      "Train Epoch: 34 [150/1000 (15%)]\tLoss: 0.000215\t score_max: 5.231573\t score_min: -51.921616; Accuracy 0.998\n",
      "Train Epoch: 34 [200/1000 (20%)]\tLoss: 0.000318\t score_max: 5.231401\t score_min: -45.090832; Accuracy 0.995\n",
      "Train Epoch: 34 [250/1000 (25%)]\tLoss: 0.000710\t score_max: 5.231253\t score_min: -40.909523; Accuracy 0.992\n",
      "Train Epoch: 34 [300/1000 (30%)]\tLoss: 0.000432\t score_max: 5.231339\t score_min: -48.725060; Accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [350/1000 (35%)]\tLoss: 0.000363\t score_max: 5.231538\t score_min: -46.952003; Accuracy 0.995\n",
      "Train Epoch: 34 [400/1000 (40%)]\tLoss: 0.000292\t score_max: 5.231856\t score_min: -44.209373; Accuracy 0.995\n",
      "Train Epoch: 34 [450/1000 (45%)]\tLoss: 0.000531\t score_max: 5.232072\t score_min: -49.700001; Accuracy 0.996\n",
      "Train Epoch: 34 [500/1000 (50%)]\tLoss: 0.000200\t score_max: 5.232419\t score_min: -53.298019; Accuracy 0.997\n",
      "Train Epoch: 34 [550/1000 (55%)]\tLoss: 0.000326\t score_max: 5.232751\t score_min: -47.488659; Accuracy 0.996\n",
      "Train Epoch: 34 [600/1000 (60%)]\tLoss: 0.000199\t score_max: 5.233083\t score_min: -46.996880; Accuracy 0.996\n",
      "Train Epoch: 34 [650/1000 (65%)]\tLoss: 0.000502\t score_max: 5.233329\t score_min: -42.323418; Accuracy 0.992\n",
      "Train Epoch: 34 [700/1000 (70%)]\tLoss: 0.000465\t score_max: 5.233603\t score_min: -43.675514; Accuracy 0.992\n",
      "Train Epoch: 34 [750/1000 (75%)]\tLoss: 0.000368\t score_max: 5.233991\t score_min: -44.279827; Accuracy 0.994\n",
      "Train Epoch: 34 [800/1000 (80%)]\tLoss: 0.000671\t score_max: 5.234251\t score_min: -41.979218; Accuracy 0.991\n",
      "Train Epoch: 34 [850/1000 (85%)]\tLoss: 0.000226\t score_max: 5.234689\t score_min: -47.720287; Accuracy 0.995\n",
      "Train Epoch: 34 [900/1000 (90%)]\tLoss: 0.000431\t score_max: 5.235039\t score_min: -47.037350; Accuracy 0.995\n",
      "Train Epoch: 34 [950/1000 (95%)]\tLoss: 0.000389\t score_max: 5.235401\t score_min: -44.708626; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.00040801184295560235 ACCURACY: 0.9948724776506424\n",
      "Epoch:  35\n",
      "Train Epoch: 35 [0/1000 (0%)]\tLoss: 0.000356\t score_max: 5.235674\t score_min: -45.705902; Accuracy 0.995\n",
      "Train Epoch: 35 [50/1000 (5%)]\tLoss: 0.000358\t score_max: 5.235847\t score_min: -41.979046; Accuracy 0.994\n",
      "Train Epoch: 35 [100/1000 (10%)]\tLoss: 0.000449\t score_max: 5.235929\t score_min: -46.729721; Accuracy 0.995\n",
      "Train Epoch: 35 [150/1000 (15%)]\tLoss: 0.000524\t score_max: 5.235996\t score_min: -47.720699; Accuracy 0.995\n",
      "Train Epoch: 35 [200/1000 (20%)]\tLoss: 0.000372\t score_max: 5.236176\t score_min: -46.205669; Accuracy 0.994\n",
      "Train Epoch: 35 [250/1000 (25%)]\tLoss: 0.000433\t score_max: 5.236423\t score_min: -44.991512; Accuracy 0.994\n",
      "Train Epoch: 35 [300/1000 (30%)]\tLoss: 0.000279\t score_max: 5.236739\t score_min: -45.800354; Accuracy 0.995\n",
      "Train Epoch: 35 [350/1000 (35%)]\tLoss: 0.000344\t score_max: 5.237022\t score_min: -40.436283; Accuracy 0.995\n",
      "Train Epoch: 35 [400/1000 (40%)]\tLoss: 0.000165\t score_max: 5.237216\t score_min: -46.583832; Accuracy 0.995\n",
      "Train Epoch: 35 [450/1000 (45%)]\tLoss: 0.000374\t score_max: 5.237352\t score_min: -42.391342; Accuracy 0.994\n",
      "Train Epoch: 35 [500/1000 (50%)]\tLoss: 0.000294\t score_max: 5.237475\t score_min: -48.482651; Accuracy 0.995\n",
      "Train Epoch: 35 [550/1000 (55%)]\tLoss: 0.000472\t score_max: 5.237562\t score_min: -45.504807; Accuracy 0.996\n",
      "Train Epoch: 35 [600/1000 (60%)]\tLoss: 0.000897\t score_max: 5.237615\t score_min: -43.910881; Accuracy 0.993\n",
      "Train Epoch: 35 [650/1000 (65%)]\tLoss: 0.000365\t score_max: 5.237814\t score_min: -45.205601; Accuracy 0.994\n",
      "Train Epoch: 35 [700/1000 (70%)]\tLoss: 0.000174\t score_max: 5.238034\t score_min: -50.292118; Accuracy 0.997\n",
      "Train Epoch: 35 [750/1000 (75%)]\tLoss: 0.000295\t score_max: 5.238235\t score_min: -51.005898; Accuracy 0.995\n",
      "Train Epoch: 35 [800/1000 (80%)]\tLoss: 0.000474\t score_max: 5.238475\t score_min: -43.463474; Accuracy 0.993\n",
      "Train Epoch: 35 [850/1000 (85%)]\tLoss: 0.000533\t score_max: 5.238803\t score_min: -43.443302; Accuracy 0.994\n",
      "Train Epoch: 35 [900/1000 (90%)]\tLoss: 0.000125\t score_max: 5.239236\t score_min: -51.075024; Accuracy 0.997\n",
      "Train Epoch: 35 [950/1000 (95%)]\tLoss: 0.000402\t score_max: 5.239666\t score_min: -42.941784; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.000384244040469639 ACCURACY: 0.9947699725627899\n",
      "Epoch:  36\n",
      "Train Epoch: 36 [0/1000 (0%)]\tLoss: 0.000302\t score_max: 5.240079\t score_min: -46.921783; Accuracy 0.994\n",
      "Train Epoch: 36 [50/1000 (5%)]\tLoss: 0.000710\t score_max: 5.240520\t score_min: -47.814503; Accuracy 0.994\n",
      "Train Epoch: 36 [100/1000 (10%)]\tLoss: 0.000387\t score_max: 5.241011\t score_min: -42.315094; Accuracy 0.993\n",
      "Train Epoch: 36 [150/1000 (15%)]\tLoss: 0.000350\t score_max: 5.241538\t score_min: -41.500427; Accuracy 0.995\n",
      "Train Epoch: 36 [200/1000 (20%)]\tLoss: 0.000232\t score_max: 5.241964\t score_min: -47.510445; Accuracy 0.993\n",
      "Train Epoch: 36 [250/1000 (25%)]\tLoss: 0.000424\t score_max: 5.242335\t score_min: -43.226727; Accuracy 0.993\n",
      "Train Epoch: 36 [300/1000 (30%)]\tLoss: 0.000339\t score_max: 5.242599\t score_min: -46.754955; Accuracy 0.994\n",
      "Train Epoch: 36 [350/1000 (35%)]\tLoss: 0.000619\t score_max: 5.242800\t score_min: -42.645210; Accuracy 0.995\n",
      "Train Epoch: 36 [400/1000 (40%)]\tLoss: 0.000784\t score_max: 5.242862\t score_min: -39.388607; Accuracy 0.997\n",
      "Train Epoch: 36 [450/1000 (45%)]\tLoss: 0.000277\t score_max: 5.242859\t score_min: -51.059860; Accuracy 0.994\n",
      "Train Epoch: 36 [500/1000 (50%)]\tLoss: 0.000550\t score_max: 5.242867\t score_min: -43.414692; Accuracy 0.995\n",
      "Train Epoch: 36 [550/1000 (55%)]\tLoss: 0.000260\t score_max: 5.242801\t score_min: -46.201920; Accuracy 0.994\n",
      "Train Epoch: 36 [600/1000 (60%)]\tLoss: 0.000499\t score_max: 5.242814\t score_min: -48.485813; Accuracy 0.995\n",
      "Train Epoch: 36 [650/1000 (65%)]\tLoss: 0.000390\t score_max: 5.242984\t score_min: -48.124733; Accuracy 0.996\n",
      "Train Epoch: 36 [700/1000 (70%)]\tLoss: 0.001042\t score_max: 5.243179\t score_min: -41.852669; Accuracy 0.992\n",
      "Train Epoch: 36 [750/1000 (75%)]\tLoss: 0.000202\t score_max: 5.243640\t score_min: -50.195702; Accuracy 0.996\n",
      "Train Epoch: 36 [800/1000 (80%)]\tLoss: 0.000161\t score_max: 5.244106\t score_min: -45.848019; Accuracy 0.994\n",
      "Train Epoch: 36 [850/1000 (85%)]\tLoss: 0.000292\t score_max: 5.244563\t score_min: -47.279377; Accuracy 0.996\n",
      "Train Epoch: 36 [900/1000 (90%)]\tLoss: 0.000296\t score_max: 5.245040\t score_min: -44.273781; Accuracy 0.994\n",
      "Train Epoch: 36 [950/1000 (95%)]\tLoss: 0.000517\t score_max: 5.245494\t score_min: -41.844444; Accuracy 0.992\n",
      "---EPOCH AVG TRAIN LOSS: 0.000431634538108483 ACCURACY: 0.9942399740219117\n",
      "Epoch:  37\n",
      "Train Epoch: 37 [0/1000 (0%)]\tLoss: 0.000503\t score_max: 5.246080\t score_min: -47.185120; Accuracy 0.995\n",
      "Train Epoch: 37 [50/1000 (5%)]\tLoss: 0.000531\t score_max: 5.246710\t score_min: -42.403347; Accuracy 0.994\n",
      "Train Epoch: 37 [100/1000 (10%)]\tLoss: 0.000401\t score_max: 5.247176\t score_min: -46.102165; Accuracy 0.996\n",
      "Train Epoch: 37 [150/1000 (15%)]\tLoss: 0.000467\t score_max: 5.247526\t score_min: -43.981430; Accuracy 0.994\n",
      "Train Epoch: 37 [200/1000 (20%)]\tLoss: 0.000380\t score_max: 5.247733\t score_min: -45.488789; Accuracy 0.995\n",
      "Train Epoch: 37 [250/1000 (25%)]\tLoss: 0.000501\t score_max: 5.247830\t score_min: -49.006516; Accuracy 0.996\n",
      "Train Epoch: 37 [300/1000 (30%)]\tLoss: 0.000357\t score_max: 5.247780\t score_min: -50.056465; Accuracy 0.996\n",
      "Train Epoch: 37 [350/1000 (35%)]\tLoss: 0.000254\t score_max: 5.247743\t score_min: -49.408459; Accuracy 0.996\n",
      "Train Epoch: 37 [400/1000 (40%)]\tLoss: 0.000225\t score_max: 5.247732\t score_min: -47.015488; Accuracy 0.995\n",
      "Train Epoch: 37 [450/1000 (45%)]\tLoss: 0.000370\t score_max: 5.247754\t score_min: -45.926945; Accuracy 0.996\n",
      "Train Epoch: 37 [500/1000 (50%)]\tLoss: 0.000348\t score_max: 5.247674\t score_min: -42.563065; Accuracy 0.994\n",
      "Train Epoch: 37 [550/1000 (55%)]\tLoss: 0.000775\t score_max: 5.247657\t score_min: -44.144756; Accuracy 0.994\n",
      "Train Epoch: 37 [600/1000 (60%)]\tLoss: 0.000316\t score_max: 5.247868\t score_min: -51.671722; Accuracy 0.997\n",
      "Train Epoch: 37 [650/1000 (65%)]\tLoss: 0.000535\t score_max: 5.248141\t score_min: -41.446228; Accuracy 0.994\n",
      "Train Epoch: 37 [700/1000 (70%)]\tLoss: 0.000858\t score_max: 5.248545\t score_min: -44.007797; Accuracy 0.994\n",
      "Train Epoch: 37 [750/1000 (75%)]\tLoss: 0.000434\t score_max: 5.249135\t score_min: -45.943253; Accuracy 0.994\n",
      "Train Epoch: 37 [800/1000 (80%)]\tLoss: 0.000325\t score_max: 5.249800\t score_min: -48.050991; Accuracy 0.993\n",
      "Train Epoch: 37 [850/1000 (85%)]\tLoss: 0.000697\t score_max: 5.250411\t score_min: -39.872978; Accuracy 0.993\n",
      "Train Epoch: 37 [900/1000 (90%)]\tLoss: 0.000473\t score_max: 5.251148\t score_min: -43.880169; Accuracy 0.995\n",
      "Train Epoch: 37 [950/1000 (95%)]\tLoss: 0.000367\t score_max: 5.251695\t score_min: -40.585880; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00045588352368213235 ACCURACY: 0.9947474777698517\n",
      "Epoch:  38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [0/1000 (0%)]\tLoss: 0.000476\t score_max: 5.252171\t score_min: -44.460785; Accuracy 0.995\n",
      "Train Epoch: 38 [50/1000 (5%)]\tLoss: 0.000338\t score_max: 5.252462\t score_min: -46.800980; Accuracy 0.995\n",
      "Train Epoch: 38 [100/1000 (10%)]\tLoss: 0.000315\t score_max: 5.252701\t score_min: -49.834595; Accuracy 0.996\n",
      "Train Epoch: 38 [150/1000 (15%)]\tLoss: 0.000668\t score_max: 5.252835\t score_min: -43.108852; Accuracy 0.992\n",
      "Train Epoch: 38 [200/1000 (20%)]\tLoss: 0.000465\t score_max: 5.252970\t score_min: -40.485840; Accuracy 0.992\n",
      "Train Epoch: 38 [250/1000 (25%)]\tLoss: 0.000160\t score_max: 5.253103\t score_min: -47.959389; Accuracy 0.995\n",
      "Train Epoch: 38 [300/1000 (30%)]\tLoss: 0.000462\t score_max: 5.253230\t score_min: -42.995750; Accuracy 0.995\n",
      "Train Epoch: 38 [350/1000 (35%)]\tLoss: 0.000567\t score_max: 5.253178\t score_min: -49.817768; Accuracy 0.995\n",
      "Train Epoch: 38 [400/1000 (40%)]\tLoss: 0.000550\t score_max: 5.253249\t score_min: -41.615944; Accuracy 0.992\n",
      "Train Epoch: 38 [450/1000 (45%)]\tLoss: 0.000116\t score_max: 5.253525\t score_min: -47.723404; Accuracy 0.994\n",
      "Train Epoch: 38 [500/1000 (50%)]\tLoss: 0.000208\t score_max: 5.253808\t score_min: -49.615746; Accuracy 0.995\n",
      "Train Epoch: 38 [550/1000 (55%)]\tLoss: 0.000449\t score_max: 5.254101\t score_min: -48.504871; Accuracy 0.995\n",
      "Train Epoch: 38 [600/1000 (60%)]\tLoss: 0.000490\t score_max: 5.254295\t score_min: -43.199818; Accuracy 0.993\n",
      "Train Epoch: 38 [650/1000 (65%)]\tLoss: 0.000493\t score_max: 5.254580\t score_min: -50.651009; Accuracy 0.996\n",
      "Train Epoch: 38 [700/1000 (70%)]\tLoss: 0.000383\t score_max: 5.254814\t score_min: -52.027344; Accuracy 0.996\n",
      "Train Epoch: 38 [750/1000 (75%)]\tLoss: 0.000196\t score_max: 5.255053\t score_min: -40.851463; Accuracy 0.992\n",
      "Train Epoch: 38 [800/1000 (80%)]\tLoss: 0.000316\t score_max: 5.255318\t score_min: -46.193523; Accuracy 0.995\n",
      "Train Epoch: 38 [850/1000 (85%)]\tLoss: 0.000380\t score_max: 5.255590\t score_min: -45.197506; Accuracy 0.994\n",
      "Train Epoch: 38 [900/1000 (90%)]\tLoss: 0.000366\t score_max: 5.255831\t score_min: -50.645153; Accuracy 0.996\n",
      "Train Epoch: 38 [950/1000 (95%)]\tLoss: 0.000256\t score_max: 5.256044\t score_min: -49.642822; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003827260854450287 ACCURACY: 0.9944124728441238\n",
      "Epoch:  39\n",
      "Train Epoch: 39 [0/1000 (0%)]\tLoss: 0.000108\t score_max: 5.256327\t score_min: -52.518906; Accuracy 0.996\n",
      "Train Epoch: 39 [50/1000 (5%)]\tLoss: 0.000578\t score_max: 5.256611\t score_min: -41.923775; Accuracy 0.992\n",
      "Train Epoch: 39 [100/1000 (10%)]\tLoss: 0.000315\t score_max: 5.257084\t score_min: -54.454048; Accuracy 0.996\n",
      "Train Epoch: 39 [150/1000 (15%)]\tLoss: 0.000218\t score_max: 5.257441\t score_min: -48.125900; Accuracy 0.995\n",
      "Train Epoch: 39 [200/1000 (20%)]\tLoss: 0.000370\t score_max: 5.257742\t score_min: -44.214527; Accuracy 0.994\n",
      "Train Epoch: 39 [250/1000 (25%)]\tLoss: 0.000396\t score_max: 5.257940\t score_min: -46.651836; Accuracy 0.992\n",
      "Train Epoch: 39 [300/1000 (30%)]\tLoss: 0.000607\t score_max: 5.258220\t score_min: -45.105942; Accuracy 0.994\n",
      "Train Epoch: 39 [350/1000 (35%)]\tLoss: 0.000359\t score_max: 5.258564\t score_min: -46.919895; Accuracy 0.995\n",
      "Train Epoch: 39 [400/1000 (40%)]\tLoss: 0.000453\t score_max: 5.258824\t score_min: -47.865021; Accuracy 0.995\n",
      "Train Epoch: 39 [450/1000 (45%)]\tLoss: 0.000193\t score_max: 5.258959\t score_min: -53.614044; Accuracy 0.995\n",
      "Train Epoch: 39 [500/1000 (50%)]\tLoss: 0.000551\t score_max: 5.259114\t score_min: -46.031231; Accuracy 0.993\n",
      "Train Epoch: 39 [550/1000 (55%)]\tLoss: 0.000635\t score_max: 5.259405\t score_min: -46.615944; Accuracy 0.993\n",
      "Train Epoch: 39 [600/1000 (60%)]\tLoss: 0.000606\t score_max: 5.259781\t score_min: -46.980328; Accuracy 0.992\n",
      "Train Epoch: 39 [650/1000 (65%)]\tLoss: 0.000175\t score_max: 5.260191\t score_min: -52.697365; Accuracy 0.997\n",
      "Train Epoch: 39 [700/1000 (70%)]\tLoss: 0.000452\t score_max: 5.260573\t score_min: -49.756626; Accuracy 0.995\n",
      "Train Epoch: 39 [750/1000 (75%)]\tLoss: 0.000519\t score_max: 5.260983\t score_min: -45.863441; Accuracy 0.993\n",
      "Train Epoch: 39 [800/1000 (80%)]\tLoss: 0.000511\t score_max: 5.261289\t score_min: -44.426018; Accuracy 0.996\n",
      "Train Epoch: 39 [850/1000 (85%)]\tLoss: 0.000349\t score_max: 5.261483\t score_min: -44.814682; Accuracy 0.993\n",
      "Train Epoch: 39 [900/1000 (90%)]\tLoss: 0.000179\t score_max: 5.261737\t score_min: -56.477974; Accuracy 0.996\n",
      "Train Epoch: 39 [950/1000 (95%)]\tLoss: 0.000516\t score_max: 5.261939\t score_min: -41.823421; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.000404431565766572 ACCURACY: 0.9943874716758728\n",
      "Epoch:  40\n",
      "Train Epoch: 40 [0/1000 (0%)]\tLoss: 0.000183\t score_max: 5.262115\t score_min: -52.115616; Accuracy 0.996\n",
      "Train Epoch: 40 [50/1000 (5%)]\tLoss: 0.000556\t score_max: 5.262280\t score_min: -48.239182; Accuracy 0.993\n",
      "Train Epoch: 40 [100/1000 (10%)]\tLoss: 0.000222\t score_max: 5.262448\t score_min: -50.116520; Accuracy 0.997\n",
      "Train Epoch: 40 [150/1000 (15%)]\tLoss: 0.000589\t score_max: 5.262641\t score_min: -43.712257; Accuracy 0.990\n",
      "Train Epoch: 40 [200/1000 (20%)]\tLoss: 0.000442\t score_max: 5.262988\t score_min: -49.151375; Accuracy 0.995\n",
      "Train Epoch: 40 [250/1000 (25%)]\tLoss: 0.000231\t score_max: 5.263278\t score_min: -49.556065; Accuracy 0.996\n",
      "Train Epoch: 40 [300/1000 (30%)]\tLoss: 0.000181\t score_max: 5.263628\t score_min: -52.395477; Accuracy 0.996\n",
      "Train Epoch: 40 [350/1000 (35%)]\tLoss: 0.000099\t score_max: 5.264000\t score_min: -49.138206; Accuracy 0.996\n",
      "Train Epoch: 40 [400/1000 (40%)]\tLoss: 0.000608\t score_max: 5.264322\t score_min: -44.119797; Accuracy 0.995\n",
      "Train Epoch: 40 [450/1000 (45%)]\tLoss: 0.000526\t score_max: 5.264427\t score_min: -41.733765; Accuracy 0.994\n",
      "Train Epoch: 40 [500/1000 (50%)]\tLoss: 0.000412\t score_max: 5.264617\t score_min: -51.047188; Accuracy 0.995\n",
      "Train Epoch: 40 [550/1000 (55%)]\tLoss: 0.000335\t score_max: 5.264890\t score_min: -46.585030; Accuracy 0.995\n",
      "Train Epoch: 40 [600/1000 (60%)]\tLoss: 0.000653\t score_max: 5.265087\t score_min: -46.674480; Accuracy 0.995\n",
      "Train Epoch: 40 [650/1000 (65%)]\tLoss: 0.000194\t score_max: 5.265194\t score_min: -53.798164; Accuracy 0.996\n",
      "Train Epoch: 40 [700/1000 (70%)]\tLoss: 0.001525\t score_max: 5.265256\t score_min: -39.563267; Accuracy 0.993\n",
      "Train Epoch: 40 [750/1000 (75%)]\tLoss: 0.000745\t score_max: 5.265609\t score_min: -43.052715; Accuracy 0.996\n",
      "Train Epoch: 40 [800/1000 (80%)]\tLoss: 0.000677\t score_max: 5.265869\t score_min: -46.091064; Accuracy 0.995\n",
      "Train Epoch: 40 [850/1000 (85%)]\tLoss: 0.000221\t score_max: 5.265936\t score_min: -47.672073; Accuracy 0.995\n",
      "Train Epoch: 40 [900/1000 (90%)]\tLoss: 0.000272\t score_max: 5.266029\t score_min: -45.693611; Accuracy 0.995\n",
      "Train Epoch: 40 [950/1000 (95%)]\tLoss: 0.000549\t score_max: 5.266188\t score_min: -43.566246; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004608312705386197 ACCURACY: 0.9948924809694291\n",
      "Epoch:  41\n",
      "Train Epoch: 41 [0/1000 (0%)]\tLoss: 0.000423\t score_max: 5.266193\t score_min: -50.901493; Accuracy 0.996\n",
      "Train Epoch: 41 [50/1000 (5%)]\tLoss: 0.000440\t score_max: 5.266315\t score_min: -46.773716; Accuracy 0.996\n",
      "Train Epoch: 41 [100/1000 (10%)]\tLoss: 0.000444\t score_max: 5.266529\t score_min: -48.403648; Accuracy 0.993\n",
      "Train Epoch: 41 [150/1000 (15%)]\tLoss: 0.000486\t score_max: 5.266886\t score_min: -51.296680; Accuracy 0.996\n",
      "Train Epoch: 41 [200/1000 (20%)]\tLoss: 0.000245\t score_max: 5.267374\t score_min: -47.801445; Accuracy 0.996\n",
      "Train Epoch: 41 [250/1000 (25%)]\tLoss: 0.000282\t score_max: 5.267877\t score_min: -48.344170; Accuracy 0.995\n",
      "Train Epoch: 41 [300/1000 (30%)]\tLoss: 0.000701\t score_max: 5.268340\t score_min: -43.609226; Accuracy 0.995\n",
      "Train Epoch: 41 [350/1000 (35%)]\tLoss: 0.000401\t score_max: 5.268645\t score_min: -46.029202; Accuracy 0.994\n",
      "Train Epoch: 41 [400/1000 (40%)]\tLoss: 0.000289\t score_max: 5.268841\t score_min: -49.878002; Accuracy 0.996\n",
      "Train Epoch: 41 [450/1000 (45%)]\tLoss: 0.000448\t score_max: 5.268992\t score_min: -45.485016; Accuracy 0.993\n",
      "Train Epoch: 41 [500/1000 (50%)]\tLoss: 0.001230\t score_max: 5.269099\t score_min: -40.111095; Accuracy 0.991\n",
      "Train Epoch: 41 [550/1000 (55%)]\tLoss: 0.000493\t score_max: 5.269422\t score_min: -46.283752; Accuracy 0.995\n",
      "Train Epoch: 41 [600/1000 (60%)]\tLoss: 0.000393\t score_max: 5.269633\t score_min: -41.865509; Accuracy 0.996\n",
      "Train Epoch: 41 [650/1000 (65%)]\tLoss: 0.000231\t score_max: 5.269780\t score_min: -49.851326; Accuracy 0.996\n",
      "Train Epoch: 41 [700/1000 (70%)]\tLoss: 0.000206\t score_max: 5.269951\t score_min: -45.072285; Accuracy 0.995\n",
      "Train Epoch: 41 [750/1000 (75%)]\tLoss: 0.000517\t score_max: 5.270063\t score_min: -45.727406; Accuracy 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [800/1000 (80%)]\tLoss: 0.000535\t score_max: 5.270255\t score_min: -43.964745; Accuracy 0.995\n",
      "Train Epoch: 41 [850/1000 (85%)]\tLoss: 0.000249\t score_max: 5.270422\t score_min: -47.068676; Accuracy 0.995\n",
      "Train Epoch: 41 [900/1000 (90%)]\tLoss: 0.000267\t score_max: 5.270569\t score_min: -39.521744; Accuracy 0.994\n",
      "Train Epoch: 41 [950/1000 (95%)]\tLoss: 0.000393\t score_max: 5.270741\t score_min: -47.273857; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00043363645163481125 ACCURACY: 0.9947249740362167\n",
      "Epoch:  42\n",
      "Train Epoch: 42 [0/1000 (0%)]\tLoss: 0.000373\t score_max: 5.270931\t score_min: -47.133961; Accuracy 0.996\n",
      "Train Epoch: 42 [50/1000 (5%)]\tLoss: 0.000242\t score_max: 5.271090\t score_min: -50.770378; Accuracy 0.995\n",
      "Train Epoch: 42 [100/1000 (10%)]\tLoss: 0.000420\t score_max: 5.271269\t score_min: -43.713097; Accuracy 0.996\n",
      "Train Epoch: 42 [150/1000 (15%)]\tLoss: 0.000527\t score_max: 5.271420\t score_min: -45.327480; Accuracy 0.993\n",
      "Train Epoch: 42 [200/1000 (20%)]\tLoss: 0.000159\t score_max: 5.271554\t score_min: -52.026772; Accuracy 0.995\n",
      "Train Epoch: 42 [250/1000 (25%)]\tLoss: 0.000628\t score_max: 5.271697\t score_min: -48.117390; Accuracy 0.994\n",
      "Train Epoch: 42 [300/1000 (30%)]\tLoss: 0.000298\t score_max: 5.272027\t score_min: -48.409397; Accuracy 0.995\n",
      "Train Epoch: 42 [350/1000 (35%)]\tLoss: 0.000249\t score_max: 5.272375\t score_min: -49.221764; Accuracy 0.995\n",
      "Train Epoch: 42 [400/1000 (40%)]\tLoss: 0.000145\t score_max: 5.272742\t score_min: -46.327656; Accuracy 0.995\n",
      "Train Epoch: 42 [450/1000 (45%)]\tLoss: 0.000531\t score_max: 5.273107\t score_min: -43.742641; Accuracy 0.995\n",
      "Train Epoch: 42 [500/1000 (50%)]\tLoss: 0.000428\t score_max: 5.273436\t score_min: -47.736179; Accuracy 0.993\n",
      "Train Epoch: 42 [550/1000 (55%)]\tLoss: 0.000387\t score_max: 5.273880\t score_min: -49.244118; Accuracy 0.996\n",
      "Train Epoch: 42 [600/1000 (60%)]\tLoss: 0.000143\t score_max: 5.274264\t score_min: -54.935486; Accuracy 0.997\n",
      "Train Epoch: 42 [650/1000 (65%)]\tLoss: 0.000308\t score_max: 5.274681\t score_min: -48.889328; Accuracy 0.996\n",
      "Train Epoch: 42 [700/1000 (70%)]\tLoss: 0.000453\t score_max: 5.274971\t score_min: -42.571007; Accuracy 0.994\n",
      "Train Epoch: 42 [750/1000 (75%)]\tLoss: 0.000207\t score_max: 5.275122\t score_min: -52.420799; Accuracy 0.996\n",
      "Train Epoch: 42 [800/1000 (80%)]\tLoss: 0.000323\t score_max: 5.275229\t score_min: -56.398491; Accuracy 0.997\n",
      "Train Epoch: 42 [850/1000 (85%)]\tLoss: 0.000288\t score_max: 5.275382\t score_min: -52.344360; Accuracy 0.996\n",
      "Train Epoch: 42 [900/1000 (90%)]\tLoss: 0.000367\t score_max: 5.275571\t score_min: -47.130810; Accuracy 0.996\n",
      "Train Epoch: 42 [950/1000 (95%)]\tLoss: 0.000265\t score_max: 5.275655\t score_min: -49.601139; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00033696316604618913 ACCURACY: 0.9953249752521515\n",
      "Epoch:  43\n",
      "Train Epoch: 43 [0/1000 (0%)]\tLoss: 0.000347\t score_max: 5.275789\t score_min: -46.529289; Accuracy 0.995\n",
      "Train Epoch: 43 [50/1000 (5%)]\tLoss: 0.000299\t score_max: 5.275882\t score_min: -51.992466; Accuracy 0.994\n",
      "Train Epoch: 43 [100/1000 (10%)]\tLoss: 0.000422\t score_max: 5.275906\t score_min: -45.378643; Accuracy 0.994\n",
      "Train Epoch: 43 [150/1000 (15%)]\tLoss: 0.000484\t score_max: 5.276070\t score_min: -45.428032; Accuracy 0.995\n",
      "Train Epoch: 43 [200/1000 (20%)]\tLoss: 0.000225\t score_max: 5.276265\t score_min: -49.493542; Accuracy 0.995\n",
      "Train Epoch: 43 [250/1000 (25%)]\tLoss: 0.000139\t score_max: 5.276504\t score_min: -47.623318; Accuracy 0.995\n",
      "Train Epoch: 43 [300/1000 (30%)]\tLoss: 0.000947\t score_max: 5.276745\t score_min: -44.168854; Accuracy 0.992\n",
      "Train Epoch: 43 [350/1000 (35%)]\tLoss: 0.000469\t score_max: 5.277249\t score_min: -47.983513; Accuracy 0.993\n",
      "Train Epoch: 43 [400/1000 (40%)]\tLoss: 0.000421\t score_max: 5.277790\t score_min: -49.528183; Accuracy 0.995\n",
      "Train Epoch: 43 [450/1000 (45%)]\tLoss: 0.000174\t score_max: 5.278285\t score_min: -46.478245; Accuracy 0.995\n",
      "Train Epoch: 43 [500/1000 (50%)]\tLoss: 0.000493\t score_max: 5.278744\t score_min: -47.317028; Accuracy 0.994\n",
      "Train Epoch: 43 [550/1000 (55%)]\tLoss: 0.000197\t score_max: 5.279171\t score_min: -52.207954; Accuracy 0.997\n",
      "Train Epoch: 43 [600/1000 (60%)]\tLoss: 0.000581\t score_max: 5.279549\t score_min: -41.830368; Accuracy 0.992\n",
      "Train Epoch: 43 [650/1000 (65%)]\tLoss: 0.000221\t score_max: 5.279818\t score_min: -43.723953; Accuracy 0.995\n",
      "Train Epoch: 43 [700/1000 (70%)]\tLoss: 0.000342\t score_max: 5.280034\t score_min: -53.251270; Accuracy 0.996\n",
      "Train Epoch: 43 [750/1000 (75%)]\tLoss: 0.000230\t score_max: 5.280234\t score_min: -44.521397; Accuracy 0.994\n",
      "Train Epoch: 43 [800/1000 (80%)]\tLoss: 0.000249\t score_max: 5.280418\t score_min: -45.441643; Accuracy 0.994\n",
      "Train Epoch: 43 [850/1000 (85%)]\tLoss: 0.000177\t score_max: 5.280659\t score_min: -48.967834; Accuracy 0.995\n",
      "Train Epoch: 43 [900/1000 (90%)]\tLoss: 0.000481\t score_max: 5.280849\t score_min: -42.899303; Accuracy 0.995\n",
      "Train Epoch: 43 [950/1000 (95%)]\tLoss: 0.000433\t score_max: 5.280996\t score_min: -45.749161; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.00036660956175182946 ACCURACY: 0.9944874763488769\n",
      "Epoch:  44\n",
      "Train Epoch: 44 [0/1000 (0%)]\tLoss: 0.000361\t score_max: 5.281004\t score_min: -43.172928; Accuracy 0.991\n",
      "Train Epoch: 44 [50/1000 (5%)]\tLoss: 0.000404\t score_max: 5.281078\t score_min: -54.538185; Accuracy 0.995\n",
      "Train Epoch: 44 [100/1000 (10%)]\tLoss: 0.000420\t score_max: 5.281052\t score_min: -43.314945; Accuracy 0.996\n",
      "Train Epoch: 44 [150/1000 (15%)]\tLoss: 0.000373\t score_max: 5.280991\t score_min: -44.105370; Accuracy 0.996\n",
      "Train Epoch: 44 [200/1000 (20%)]\tLoss: 0.000191\t score_max: 5.280898\t score_min: -54.895359; Accuracy 0.997\n",
      "Train Epoch: 44 [250/1000 (25%)]\tLoss: 0.000440\t score_max: 5.280911\t score_min: -51.689995; Accuracy 0.997\n",
      "Train Epoch: 44 [300/1000 (30%)]\tLoss: 0.000577\t score_max: 5.281084\t score_min: -49.260010; Accuracy 0.993\n",
      "Train Epoch: 44 [350/1000 (35%)]\tLoss: 0.000258\t score_max: 5.281420\t score_min: -49.875610; Accuracy 0.996\n",
      "Train Epoch: 44 [400/1000 (40%)]\tLoss: 0.000413\t score_max: 5.281731\t score_min: -46.363075; Accuracy 0.993\n",
      "Train Epoch: 44 [450/1000 (45%)]\tLoss: 0.000217\t score_max: 5.282124\t score_min: -46.876568; Accuracy 0.994\n",
      "Train Epoch: 44 [500/1000 (50%)]\tLoss: 0.000248\t score_max: 5.282475\t score_min: -51.194115; Accuracy 0.994\n",
      "Train Epoch: 44 [550/1000 (55%)]\tLoss: 0.000362\t score_max: 5.282812\t score_min: -47.093254; Accuracy 0.994\n",
      "Train Epoch: 44 [600/1000 (60%)]\tLoss: 0.000206\t score_max: 5.283149\t score_min: -47.448681; Accuracy 0.996\n",
      "Train Epoch: 44 [650/1000 (65%)]\tLoss: 0.000242\t score_max: 5.283417\t score_min: -46.092392; Accuracy 0.995\n",
      "Train Epoch: 44 [700/1000 (70%)]\tLoss: 0.000386\t score_max: 5.283665\t score_min: -46.665966; Accuracy 0.995\n",
      "Train Epoch: 44 [750/1000 (75%)]\tLoss: 0.000191\t score_max: 5.283841\t score_min: -47.548656; Accuracy 0.996\n",
      "Train Epoch: 44 [800/1000 (80%)]\tLoss: 0.000584\t score_max: 5.284050\t score_min: -45.660999; Accuracy 0.992\n",
      "Train Epoch: 44 [850/1000 (85%)]\tLoss: 0.000292\t score_max: 5.284331\t score_min: -44.812885; Accuracy 0.996\n",
      "Train Epoch: 44 [900/1000 (90%)]\tLoss: 0.000661\t score_max: 5.284631\t score_min: -46.519382; Accuracy 0.996\n",
      "Train Epoch: 44 [950/1000 (95%)]\tLoss: 0.000310\t score_max: 5.284714\t score_min: -43.576382; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003568041356629692 ACCURACY: 0.9949824690818787\n",
      "Epoch:  45\n",
      "Train Epoch: 45 [0/1000 (0%)]\tLoss: 0.000460\t score_max: 5.284789\t score_min: -41.478817; Accuracy 0.994\n",
      "Train Epoch: 45 [50/1000 (5%)]\tLoss: 0.000397\t score_max: 5.284859\t score_min: -52.716866; Accuracy 0.993\n",
      "Train Epoch: 45 [100/1000 (10%)]\tLoss: 0.000265\t score_max: 5.284899\t score_min: -48.484322; Accuracy 0.994\n",
      "Train Epoch: 45 [150/1000 (15%)]\tLoss: 0.000247\t score_max: 5.284987\t score_min: -55.248909; Accuracy 0.997\n",
      "Train Epoch: 45 [200/1000 (20%)]\tLoss: 0.000297\t score_max: 5.285152\t score_min: -48.132591; Accuracy 0.995\n",
      "Train Epoch: 45 [250/1000 (25%)]\tLoss: 0.000259\t score_max: 5.285260\t score_min: -51.181370; Accuracy 0.996\n",
      "Train Epoch: 45 [300/1000 (30%)]\tLoss: 0.000537\t score_max: 5.285398\t score_min: -53.665039; Accuracy 0.995\n",
      "Train Epoch: 45 [350/1000 (35%)]\tLoss: 0.000880\t score_max: 5.285679\t score_min: -45.258106; Accuracy 0.992\n",
      "Train Epoch: 45 [400/1000 (40%)]\tLoss: 0.000255\t score_max: 5.286248\t score_min: -47.827774; Accuracy 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [450/1000 (45%)]\tLoss: 0.000642\t score_max: 5.286738\t score_min: -46.057404; Accuracy 0.992\n",
      "Train Epoch: 45 [500/1000 (50%)]\tLoss: 0.000279\t score_max: 5.287391\t score_min: -51.974579; Accuracy 0.994\n",
      "Train Epoch: 45 [550/1000 (55%)]\tLoss: 0.000796\t score_max: 5.288006\t score_min: -44.690933; Accuracy 0.994\n",
      "Train Epoch: 45 [600/1000 (60%)]\tLoss: 0.000586\t score_max: 5.288582\t score_min: -49.978680; Accuracy 0.995\n",
      "Train Epoch: 45 [650/1000 (65%)]\tLoss: 0.000670\t score_max: 5.288982\t score_min: -45.956306; Accuracy 0.995\n",
      "Train Epoch: 45 [700/1000 (70%)]\tLoss: 0.000112\t score_max: 5.289170\t score_min: -52.747704; Accuracy 0.997\n",
      "Train Epoch: 45 [750/1000 (75%)]\tLoss: 0.000605\t score_max: 5.289335\t score_min: -51.315327; Accuracy 0.996\n",
      "Train Epoch: 45 [800/1000 (80%)]\tLoss: 0.000368\t score_max: 5.289402\t score_min: -48.542065; Accuracy 0.994\n",
      "Train Epoch: 45 [850/1000 (85%)]\tLoss: 0.000216\t score_max: 5.289440\t score_min: -43.300095; Accuracy 0.994\n",
      "Train Epoch: 45 [900/1000 (90%)]\tLoss: 0.000754\t score_max: 5.289510\t score_min: -42.423870; Accuracy 0.994\n",
      "Train Epoch: 45 [950/1000 (95%)]\tLoss: 0.000071\t score_max: 5.289361\t score_min: -54.017467; Accuracy 0.998\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004348088121332694 ACCURACY: 0.9947599679231643\n",
      "Epoch:  46\n",
      "Train Epoch: 46 [0/1000 (0%)]\tLoss: 0.000819\t score_max: 5.289252\t score_min: -48.750938; Accuracy 0.993\n",
      "Train Epoch: 46 [50/1000 (5%)]\tLoss: 0.000181\t score_max: 5.289339\t score_min: -47.595680; Accuracy 0.996\n",
      "Train Epoch: 46 [100/1000 (10%)]\tLoss: 0.000428\t score_max: 5.289476\t score_min: -51.030071; Accuracy 0.994\n",
      "Train Epoch: 46 [150/1000 (15%)]\tLoss: 0.000371\t score_max: 5.289671\t score_min: -56.795647; Accuracy 0.995\n",
      "Train Epoch: 46 [200/1000 (20%)]\tLoss: 0.000381\t score_max: 5.289958\t score_min: -49.522499; Accuracy 0.996\n",
      "Train Epoch: 46 [250/1000 (25%)]\tLoss: 0.000631\t score_max: 5.290299\t score_min: -47.306480; Accuracy 0.993\n",
      "Train Epoch: 46 [300/1000 (30%)]\tLoss: 0.000188\t score_max: 5.290810\t score_min: -49.325035; Accuracy 0.994\n",
      "Train Epoch: 46 [350/1000 (35%)]\tLoss: 0.000481\t score_max: 5.291306\t score_min: -42.472595; Accuracy 0.992\n",
      "Train Epoch: 46 [400/1000 (40%)]\tLoss: 0.000612\t score_max: 5.291800\t score_min: -43.435959; Accuracy 0.991\n",
      "Train Epoch: 46 [450/1000 (45%)]\tLoss: 0.000838\t score_max: 5.292340\t score_min: -51.872105; Accuracy 0.996\n",
      "Train Epoch: 46 [500/1000 (50%)]\tLoss: 0.000359\t score_max: 5.292628\t score_min: -56.616482; Accuracy 0.996\n",
      "Train Epoch: 46 [550/1000 (55%)]\tLoss: 0.000509\t score_max: 5.292794\t score_min: -43.123932; Accuracy 0.991\n",
      "Train Epoch: 46 [600/1000 (60%)]\tLoss: 0.000480\t score_max: 5.292951\t score_min: -51.032841; Accuracy 0.994\n",
      "Train Epoch: 46 [650/1000 (65%)]\tLoss: 0.000840\t score_max: 5.293057\t score_min: -46.714851; Accuracy 0.993\n",
      "Train Epoch: 46 [700/1000 (70%)]\tLoss: 0.000364\t score_max: 5.292946\t score_min: -36.063770; Accuracy 0.995\n",
      "Train Epoch: 46 [750/1000 (75%)]\tLoss: 0.000847\t score_max: 5.292821\t score_min: -46.738762; Accuracy 0.993\n",
      "Train Epoch: 46 [800/1000 (80%)]\tLoss: 0.000241\t score_max: 5.292898\t score_min: -53.309422; Accuracy 0.993\n",
      "Train Epoch: 46 [850/1000 (85%)]\tLoss: 0.000431\t score_max: 5.293005\t score_min: -55.681843; Accuracy 0.996\n",
      "Train Epoch: 46 [900/1000 (90%)]\tLoss: 0.000268\t score_max: 5.293205\t score_min: -48.363182; Accuracy 0.994\n",
      "Train Epoch: 46 [950/1000 (95%)]\tLoss: 0.000158\t score_max: 5.293421\t score_min: -55.803753; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00047135344939306376 ACCURACY: 0.9940224707126617\n",
      "Epoch:  47\n",
      "Train Epoch: 47 [0/1000 (0%)]\tLoss: 0.000202\t score_max: 5.293674\t score_min: -53.243542; Accuracy 0.996\n",
      "Train Epoch: 47 [50/1000 (5%)]\tLoss: 0.000390\t score_max: 5.293889\t score_min: -43.238792; Accuracy 0.995\n",
      "Train Epoch: 47 [100/1000 (10%)]\tLoss: 0.000422\t score_max: 5.294127\t score_min: -49.967587; Accuracy 0.995\n",
      "Train Epoch: 47 [150/1000 (15%)]\tLoss: 0.000729\t score_max: 5.294431\t score_min: -42.848148; Accuracy 0.992\n",
      "Train Epoch: 47 [200/1000 (20%)]\tLoss: 0.000244\t score_max: 5.294921\t score_min: -52.118153; Accuracy 0.995\n",
      "Train Epoch: 47 [250/1000 (25%)]\tLoss: 0.000091\t score_max: 5.295345\t score_min: -53.224674; Accuracy 0.997\n",
      "Train Epoch: 47 [300/1000 (30%)]\tLoss: 0.000230\t score_max: 5.295722\t score_min: -54.025238; Accuracy 0.996\n",
      "Train Epoch: 47 [350/1000 (35%)]\tLoss: 0.000297\t score_max: 5.296046\t score_min: -46.197147; Accuracy 0.995\n",
      "Train Epoch: 47 [400/1000 (40%)]\tLoss: 0.000366\t score_max: 5.296318\t score_min: -54.807640; Accuracy 0.996\n",
      "Train Epoch: 47 [450/1000 (45%)]\tLoss: 0.000361\t score_max: 5.296471\t score_min: -50.001789; Accuracy 0.994\n",
      "Train Epoch: 47 [500/1000 (50%)]\tLoss: 0.000331\t score_max: 5.296599\t score_min: -46.204304; Accuracy 0.994\n",
      "Train Epoch: 47 [550/1000 (55%)]\tLoss: 0.000576\t score_max: 5.296691\t score_min: -44.014439; Accuracy 0.993\n",
      "Train Epoch: 47 [600/1000 (60%)]\tLoss: 0.000285\t score_max: 5.296652\t score_min: -49.131493; Accuracy 0.996\n",
      "Train Epoch: 47 [650/1000 (65%)]\tLoss: 0.000398\t score_max: 5.296637\t score_min: -55.994221; Accuracy 0.995\n",
      "Train Epoch: 47 [700/1000 (70%)]\tLoss: 0.000284\t score_max: 5.296773\t score_min: -53.287731; Accuracy 0.995\n",
      "Train Epoch: 47 [750/1000 (75%)]\tLoss: 0.000538\t score_max: 5.296927\t score_min: -47.128452; Accuracy 0.995\n",
      "Train Epoch: 47 [800/1000 (80%)]\tLoss: 0.000661\t score_max: 5.296970\t score_min: -49.682384; Accuracy 0.995\n",
      "Train Epoch: 47 [850/1000 (85%)]\tLoss: 0.000218\t score_max: 5.297150\t score_min: -48.091194; Accuracy 0.994\n",
      "Train Epoch: 47 [900/1000 (90%)]\tLoss: 0.000358\t score_max: 5.297401\t score_min: -53.953114; Accuracy 0.995\n",
      "Train Epoch: 47 [950/1000 (95%)]\tLoss: 0.000332\t score_max: 5.297763\t score_min: -48.946060; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00036568698269547897 ACCURACY: 0.9949749767780304\n",
      "Epoch:  48\n",
      "Train Epoch: 48 [0/1000 (0%)]\tLoss: 0.000197\t score_max: 5.298096\t score_min: -46.317345; Accuracy 0.995\n",
      "Train Epoch: 48 [50/1000 (5%)]\tLoss: 0.000512\t score_max: 5.298444\t score_min: -46.495258; Accuracy 0.994\n",
      "Train Epoch: 48 [100/1000 (10%)]\tLoss: 0.000324\t score_max: 5.298700\t score_min: -47.246391; Accuracy 0.995\n",
      "Train Epoch: 48 [150/1000 (15%)]\tLoss: 0.000302\t score_max: 5.299028\t score_min: -47.176758; Accuracy 0.994\n",
      "Train Epoch: 48 [200/1000 (20%)]\tLoss: 0.000434\t score_max: 5.299379\t score_min: -54.958282; Accuracy 0.996\n",
      "Train Epoch: 48 [250/1000 (25%)]\tLoss: 0.000153\t score_max: 5.299661\t score_min: -51.003731; Accuracy 0.997\n",
      "Train Epoch: 48 [300/1000 (30%)]\tLoss: 0.000421\t score_max: 5.299880\t score_min: -44.749847; Accuracy 0.994\n",
      "Train Epoch: 48 [350/1000 (35%)]\tLoss: 0.000603\t score_max: 5.300016\t score_min: -40.401234; Accuracy 0.993\n",
      "Train Epoch: 48 [400/1000 (40%)]\tLoss: 0.000294\t score_max: 5.300219\t score_min: -42.716938; Accuracy 0.994\n",
      "Train Epoch: 48 [450/1000 (45%)]\tLoss: 0.000574\t score_max: 5.300394\t score_min: -47.627464; Accuracy 0.994\n",
      "Train Epoch: 48 [500/1000 (50%)]\tLoss: 0.000336\t score_max: 5.300375\t score_min: -50.221107; Accuracy 0.994\n",
      "Train Epoch: 48 [550/1000 (55%)]\tLoss: 0.000168\t score_max: 5.300355\t score_min: -47.360565; Accuracy 0.996\n",
      "Train Epoch: 48 [600/1000 (60%)]\tLoss: 0.000319\t score_max: 5.300356\t score_min: -49.703873; Accuracy 0.994\n",
      "Train Epoch: 48 [650/1000 (65%)]\tLoss: 0.000162\t score_max: 5.300443\t score_min: -47.855240; Accuracy 0.995\n",
      "Train Epoch: 48 [700/1000 (70%)]\tLoss: 0.000345\t score_max: 5.300570\t score_min: -45.092422; Accuracy 0.995\n",
      "Train Epoch: 48 [750/1000 (75%)]\tLoss: 0.000284\t score_max: 5.300792\t score_min: -52.776070; Accuracy 0.996\n",
      "Train Epoch: 48 [800/1000 (80%)]\tLoss: 0.000318\t score_max: 5.301058\t score_min: -55.238918; Accuracy 0.996\n",
      "Train Epoch: 48 [850/1000 (85%)]\tLoss: 0.000886\t score_max: 5.301346\t score_min: -41.536537; Accuracy 0.993\n",
      "Train Epoch: 48 [900/1000 (90%)]\tLoss: 0.000399\t score_max: 5.301618\t score_min: -51.776901; Accuracy 0.995\n",
      "Train Epoch: 48 [950/1000 (95%)]\tLoss: 0.000488\t score_max: 5.301918\t score_min: -44.182972; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003759744133276399 ACCURACY: 0.9947274714708328\n",
      "Epoch:  49\n",
      "Train Epoch: 49 [0/1000 (0%)]\tLoss: 0.000158\t score_max: 5.302362\t score_min: -54.174515; Accuracy 0.997\n",
      "Train Epoch: 49 [50/1000 (5%)]\tLoss: 0.000203\t score_max: 5.302754\t score_min: -47.141380; Accuracy 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [100/1000 (10%)]\tLoss: 0.000188\t score_max: 5.303148\t score_min: -55.495842; Accuracy 0.996\n",
      "Train Epoch: 49 [150/1000 (15%)]\tLoss: 0.000293\t score_max: 5.303560\t score_min: -48.078186; Accuracy 0.995\n",
      "Train Epoch: 49 [200/1000 (20%)]\tLoss: 0.000568\t score_max: 5.303880\t score_min: -50.227119; Accuracy 0.995\n",
      "Train Epoch: 49 [250/1000 (25%)]\tLoss: 0.000312\t score_max: 5.304054\t score_min: -43.346836; Accuracy 0.993\n",
      "Train Epoch: 49 [300/1000 (30%)]\tLoss: 0.000336\t score_max: 5.304221\t score_min: -50.700371; Accuracy 0.995\n",
      "Train Epoch: 49 [350/1000 (35%)]\tLoss: 0.000515\t score_max: 5.304462\t score_min: -48.546337; Accuracy 0.994\n",
      "Train Epoch: 49 [400/1000 (40%)]\tLoss: 0.000220\t score_max: 5.304576\t score_min: -53.565914; Accuracy 0.995\n",
      "Train Epoch: 49 [450/1000 (45%)]\tLoss: 0.000205\t score_max: 5.304708\t score_min: -50.884178; Accuracy 0.995\n",
      "Train Epoch: 49 [500/1000 (50%)]\tLoss: 0.000367\t score_max: 5.304808\t score_min: -50.502769; Accuracy 0.995\n",
      "Train Epoch: 49 [550/1000 (55%)]\tLoss: 0.000523\t score_max: 5.305023\t score_min: -49.066353; Accuracy 0.993\n",
      "Train Epoch: 49 [600/1000 (60%)]\tLoss: 0.000531\t score_max: 5.305285\t score_min: -42.631493; Accuracy 0.994\n",
      "Train Epoch: 49 [650/1000 (65%)]\tLoss: 0.000233\t score_max: 5.305537\t score_min: -55.049828; Accuracy 0.995\n",
      "Train Epoch: 49 [700/1000 (70%)]\tLoss: 0.000202\t score_max: 5.305788\t score_min: -50.827065; Accuracy 0.995\n",
      "Train Epoch: 49 [750/1000 (75%)]\tLoss: 0.000543\t score_max: 5.306008\t score_min: -49.738682; Accuracy 0.994\n",
      "Train Epoch: 49 [800/1000 (80%)]\tLoss: 0.000287\t score_max: 5.306305\t score_min: -52.934753; Accuracy 0.996\n",
      "Train Epoch: 49 [850/1000 (85%)]\tLoss: 0.000133\t score_max: 5.306488\t score_min: -51.295521; Accuracy 0.996\n",
      "Train Epoch: 49 [900/1000 (90%)]\tLoss: 0.000283\t score_max: 5.306687\t score_min: -51.026127; Accuracy 0.994\n",
      "Train Epoch: 49 [950/1000 (95%)]\tLoss: 0.000326\t score_max: 5.306944\t score_min: -52.477139; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00032118646340677514 ACCURACY: 0.9949349671602249\n",
      "Epoch:  50\n",
      "Train Epoch: 50 [0/1000 (0%)]\tLoss: 0.000248\t score_max: 5.307178\t score_min: -48.992599; Accuracy 0.994\n",
      "Train Epoch: 50 [50/1000 (5%)]\tLoss: 0.000237\t score_max: 5.307393\t score_min: -43.729069; Accuracy 0.993\n",
      "Train Epoch: 50 [100/1000 (10%)]\tLoss: 0.000541\t score_max: 5.307578\t score_min: -57.086189; Accuracy 0.997\n",
      "Train Epoch: 50 [150/1000 (15%)]\tLoss: 0.000457\t score_max: 5.307760\t score_min: -51.606964; Accuracy 0.995\n",
      "Train Epoch: 50 [200/1000 (20%)]\tLoss: 0.000346\t score_max: 5.308018\t score_min: -48.285458; Accuracy 0.994\n",
      "Train Epoch: 50 [250/1000 (25%)]\tLoss: 0.000299\t score_max: 5.308357\t score_min: -55.994110; Accuracy 0.996\n",
      "Train Epoch: 50 [300/1000 (30%)]\tLoss: 0.000611\t score_max: 5.308644\t score_min: -51.636627; Accuracy 0.996\n",
      "Train Epoch: 50 [350/1000 (35%)]\tLoss: 0.000369\t score_max: 5.308821\t score_min: -52.704445; Accuracy 0.997\n",
      "Train Epoch: 50 [400/1000 (40%)]\tLoss: 0.000402\t score_max: 5.308836\t score_min: -54.772400; Accuracy 0.995\n",
      "Train Epoch: 50 [450/1000 (45%)]\tLoss: 0.000230\t score_max: 5.308986\t score_min: -50.366928; Accuracy 0.994\n",
      "Train Epoch: 50 [500/1000 (50%)]\tLoss: 0.000332\t score_max: 5.309141\t score_min: -52.704407; Accuracy 0.996\n",
      "Train Epoch: 50 [550/1000 (55%)]\tLoss: 0.000249\t score_max: 5.309346\t score_min: -48.342850; Accuracy 0.994\n",
      "Train Epoch: 50 [600/1000 (60%)]\tLoss: 0.000526\t score_max: 5.309552\t score_min: -49.985729; Accuracy 0.995\n",
      "Train Epoch: 50 [650/1000 (65%)]\tLoss: 0.000321\t score_max: 5.309618\t score_min: -51.957935; Accuracy 0.996\n",
      "Train Epoch: 50 [700/1000 (70%)]\tLoss: 0.000639\t score_max: 5.309640\t score_min: -48.139347; Accuracy 0.993\n",
      "Train Epoch: 50 [750/1000 (75%)]\tLoss: 0.000394\t score_max: 5.309850\t score_min: -46.117561; Accuracy 0.994\n",
      "Train Epoch: 50 [800/1000 (80%)]\tLoss: 0.000259\t score_max: 5.310030\t score_min: -49.641178; Accuracy 0.994\n",
      "Train Epoch: 50 [850/1000 (85%)]\tLoss: 0.000361\t score_max: 5.310281\t score_min: -53.328648; Accuracy 0.996\n",
      "Train Epoch: 50 [900/1000 (90%)]\tLoss: 0.000257\t score_max: 5.310402\t score_min: -55.386288; Accuracy 0.996\n",
      "Train Epoch: 50 [950/1000 (95%)]\tLoss: 0.000259\t score_max: 5.310568\t score_min: -48.049324; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003667675104225054 ACCURACY: 0.9949774712324142\n",
      "Epoch:  51\n",
      "Train Epoch: 51 [0/1000 (0%)]\tLoss: 0.000783\t score_max: 5.310725\t score_min: -47.028397; Accuracy 0.992\n",
      "Train Epoch: 51 [50/1000 (5%)]\tLoss: 0.000567\t score_max: 5.311180\t score_min: -48.629906; Accuracy 0.993\n",
      "Train Epoch: 51 [100/1000 (10%)]\tLoss: 0.000200\t score_max: 5.311799\t score_min: -55.429638; Accuracy 0.996\n",
      "Train Epoch: 51 [150/1000 (15%)]\tLoss: 0.000238\t score_max: 5.312348\t score_min: -46.356686; Accuracy 0.995\n",
      "Train Epoch: 51 [200/1000 (20%)]\tLoss: 0.000304\t score_max: 5.312768\t score_min: -49.325916; Accuracy 0.993\n",
      "Train Epoch: 51 [250/1000 (25%)]\tLoss: 0.000867\t score_max: 5.313153\t score_min: -46.830013; Accuracy 0.996\n",
      "Train Epoch: 51 [300/1000 (30%)]\tLoss: 0.000252\t score_max: 5.313215\t score_min: -51.314438; Accuracy 0.996\n",
      "Train Epoch: 51 [350/1000 (35%)]\tLoss: 0.000392\t score_max: 5.313281\t score_min: -50.346813; Accuracy 0.995\n",
      "Train Epoch: 51 [400/1000 (40%)]\tLoss: 0.001044\t score_max: 5.313295\t score_min: -44.930466; Accuracy 0.993\n",
      "Train Epoch: 51 [450/1000 (45%)]\tLoss: 0.000803\t score_max: 5.313513\t score_min: -47.338768; Accuracy 0.993\n",
      "Train Epoch: 51 [500/1000 (50%)]\tLoss: 0.000278\t score_max: 5.313783\t score_min: -43.548409; Accuracy 0.996\n",
      "Train Epoch: 51 [550/1000 (55%)]\tLoss: 0.000205\t score_max: 5.313977\t score_min: -46.080761; Accuracy 0.994\n",
      "Train Epoch: 51 [600/1000 (60%)]\tLoss: 0.000295\t score_max: 5.314140\t score_min: -56.760357; Accuracy 0.996\n",
      "Train Epoch: 51 [650/1000 (65%)]\tLoss: 0.000168\t score_max: 5.314381\t score_min: -50.137367; Accuracy 0.996\n",
      "Train Epoch: 51 [700/1000 (70%)]\tLoss: 0.000743\t score_max: 5.314623\t score_min: -50.939301; Accuracy 0.993\n",
      "Train Epoch: 51 [750/1000 (75%)]\tLoss: 0.000255\t score_max: 5.315084\t score_min: -49.889671; Accuracy 0.994\n",
      "Train Epoch: 51 [800/1000 (80%)]\tLoss: 0.000671\t score_max: 5.315537\t score_min: -47.342251; Accuracy 0.995\n",
      "Train Epoch: 51 [850/1000 (85%)]\tLoss: 0.000430\t score_max: 5.316092\t score_min: -52.969383; Accuracy 0.996\n",
      "Train Epoch: 51 [900/1000 (90%)]\tLoss: 0.000938\t score_max: 5.316506\t score_min: -46.957069; Accuracy 0.995\n",
      "Train Epoch: 51 [950/1000 (95%)]\tLoss: 0.000350\t score_max: 5.316667\t score_min: -54.727253; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004891633354418446 ACCURACY: 0.9945699781179428\n",
      "Epoch:  52\n",
      "Train Epoch: 52 [0/1000 (0%)]\tLoss: 0.000388\t score_max: 5.316738\t score_min: -49.185444; Accuracy 0.994\n",
      "Train Epoch: 52 [50/1000 (5%)]\tLoss: 0.000331\t score_max: 5.316900\t score_min: -48.418156; Accuracy 0.994\n",
      "Train Epoch: 52 [100/1000 (10%)]\tLoss: 0.000241\t score_max: 5.317109\t score_min: -51.784786; Accuracy 0.996\n",
      "Train Epoch: 52 [150/1000 (15%)]\tLoss: 0.000352\t score_max: 5.317367\t score_min: -47.452003; Accuracy 0.993\n",
      "Train Epoch: 52 [200/1000 (20%)]\tLoss: 0.000327\t score_max: 5.317612\t score_min: -45.812111; Accuracy 0.995\n",
      "Train Epoch: 52 [250/1000 (25%)]\tLoss: 0.000382\t score_max: 5.317715\t score_min: -49.546223; Accuracy 0.995\n",
      "Train Epoch: 52 [300/1000 (30%)]\tLoss: 0.000382\t score_max: 5.317789\t score_min: -47.275677; Accuracy 0.994\n",
      "Train Epoch: 52 [350/1000 (35%)]\tLoss: 0.000725\t score_max: 5.317942\t score_min: -37.473152; Accuracy 0.993\n",
      "Train Epoch: 52 [400/1000 (40%)]\tLoss: 0.000421\t score_max: 5.318264\t score_min: -51.346272; Accuracy 0.995\n",
      "Train Epoch: 52 [450/1000 (45%)]\tLoss: 0.000369\t score_max: 5.318659\t score_min: -47.978798; Accuracy 0.994\n",
      "Train Epoch: 52 [500/1000 (50%)]\tLoss: 0.000144\t score_max: 5.318936\t score_min: -52.864811; Accuracy 0.996\n",
      "Train Epoch: 52 [550/1000 (55%)]\tLoss: 0.000549\t score_max: 5.319211\t score_min: -43.262276; Accuracy 0.993\n",
      "Train Epoch: 52 [600/1000 (60%)]\tLoss: 0.000681\t score_max: 5.319345\t score_min: -45.557674; Accuracy 0.993\n",
      "Train Epoch: 52 [650/1000 (65%)]\tLoss: 0.000326\t score_max: 5.319615\t score_min: -55.393280; Accuracy 0.996\n",
      "Train Epoch: 52 [700/1000 (70%)]\tLoss: 0.000276\t score_max: 5.319906\t score_min: -46.673939; Accuracy 0.994\n",
      "Train Epoch: 52 [750/1000 (75%)]\tLoss: 0.000136\t score_max: 5.320125\t score_min: -48.815277; Accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52 [800/1000 (80%)]\tLoss: 0.000606\t score_max: 5.320356\t score_min: -48.364155; Accuracy 0.995\n",
      "Train Epoch: 52 [850/1000 (85%)]\tLoss: 0.000451\t score_max: 5.320688\t score_min: -49.986153; Accuracy 0.996\n",
      "Train Epoch: 52 [900/1000 (90%)]\tLoss: 0.000343\t score_max: 5.321028\t score_min: -52.600170; Accuracy 0.996\n",
      "Train Epoch: 52 [950/1000 (95%)]\tLoss: 0.000186\t score_max: 5.321462\t score_min: -51.821907; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00038075410557212306 ACCURACY: 0.9946074813604355\n",
      "Epoch:  53\n",
      "Train Epoch: 53 [0/1000 (0%)]\tLoss: 0.000331\t score_max: 5.321810\t score_min: -51.404892; Accuracy 0.996\n",
      "Train Epoch: 53 [50/1000 (5%)]\tLoss: 0.000552\t score_max: 5.322045\t score_min: -45.318542; Accuracy 0.995\n",
      "Train Epoch: 53 [100/1000 (10%)]\tLoss: 0.000378\t score_max: 5.322261\t score_min: -49.657211; Accuracy 0.994\n",
      "Train Epoch: 53 [150/1000 (15%)]\tLoss: 0.000168\t score_max: 5.322533\t score_min: -57.180065; Accuracy 0.997\n",
      "Train Epoch: 53 [200/1000 (20%)]\tLoss: 0.000379\t score_max: 5.322745\t score_min: -56.872482; Accuracy 0.995\n",
      "Train Epoch: 53 [250/1000 (25%)]\tLoss: 0.000435\t score_max: 5.323058\t score_min: -49.060638; Accuracy 0.994\n",
      "Train Epoch: 53 [300/1000 (30%)]\tLoss: 0.000507\t score_max: 5.323285\t score_min: -46.178745; Accuracy 0.994\n",
      "Train Epoch: 53 [350/1000 (35%)]\tLoss: 0.000197\t score_max: 5.323554\t score_min: -45.386513; Accuracy 0.993\n",
      "Train Epoch: 53 [400/1000 (40%)]\tLoss: 0.000557\t score_max: 5.323818\t score_min: -43.501926; Accuracy 0.991\n",
      "Train Epoch: 53 [450/1000 (45%)]\tLoss: 0.000367\t score_max: 5.324197\t score_min: -46.447071; Accuracy 0.995\n",
      "Train Epoch: 53 [500/1000 (50%)]\tLoss: 0.000564\t score_max: 5.324484\t score_min: -51.652107; Accuracy 0.995\n",
      "Train Epoch: 53 [550/1000 (55%)]\tLoss: 0.000575\t score_max: 5.324713\t score_min: -45.622986; Accuracy 0.994\n",
      "Train Epoch: 53 [600/1000 (60%)]\tLoss: 0.000183\t score_max: 5.324913\t score_min: -49.502960; Accuracy 0.994\n",
      "Train Epoch: 53 [650/1000 (65%)]\tLoss: 0.000608\t score_max: 5.325074\t score_min: -47.342815; Accuracy 0.994\n",
      "Train Epoch: 53 [700/1000 (70%)]\tLoss: 0.000443\t score_max: 5.325274\t score_min: -45.408203; Accuracy 0.995\n",
      "Train Epoch: 53 [750/1000 (75%)]\tLoss: 0.000428\t score_max: 5.325327\t score_min: -51.276966; Accuracy 0.994\n",
      "Train Epoch: 53 [800/1000 (80%)]\tLoss: 0.000617\t score_max: 5.325291\t score_min: -41.692451; Accuracy 0.992\n",
      "Train Epoch: 53 [850/1000 (85%)]\tLoss: 0.000360\t score_max: 5.325384\t score_min: -48.716431; Accuracy 0.996\n",
      "Train Epoch: 53 [900/1000 (90%)]\tLoss: 0.000405\t score_max: 5.325604\t score_min: -49.900696; Accuracy 0.994\n",
      "Train Epoch: 53 [950/1000 (95%)]\tLoss: 0.000179\t score_max: 5.325791\t score_min: -50.332935; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041158728854497897 ACCURACY: 0.9944349735975265\n",
      "Epoch:  54\n",
      "Train Epoch: 54 [0/1000 (0%)]\tLoss: 0.000206\t score_max: 5.325961\t score_min: -57.816376; Accuracy 0.997\n",
      "Train Epoch: 54 [50/1000 (5%)]\tLoss: 0.000340\t score_max: 5.326081\t score_min: -47.852589; Accuracy 0.993\n",
      "Train Epoch: 54 [100/1000 (10%)]\tLoss: 0.000220\t score_max: 5.326213\t score_min: -50.505951; Accuracy 0.995\n",
      "Train Epoch: 54 [150/1000 (15%)]\tLoss: 0.000259\t score_max: 5.326407\t score_min: -51.968193; Accuracy 0.995\n",
      "Train Epoch: 54 [200/1000 (20%)]\tLoss: 0.000096\t score_max: 5.326621\t score_min: -53.933105; Accuracy 0.996\n",
      "Train Epoch: 54 [250/1000 (25%)]\tLoss: 0.000600\t score_max: 5.326802\t score_min: -46.633778; Accuracy 0.993\n",
      "Train Epoch: 54 [300/1000 (30%)]\tLoss: 0.000229\t score_max: 5.327045\t score_min: -46.832150; Accuracy 0.992\n",
      "Train Epoch: 54 [350/1000 (35%)]\tLoss: 0.000182\t score_max: 5.327358\t score_min: -58.459042; Accuracy 0.998\n",
      "Train Epoch: 54 [400/1000 (40%)]\tLoss: 0.000678\t score_max: 5.327651\t score_min: -45.759464; Accuracy 0.992\n",
      "Train Epoch: 54 [450/1000 (45%)]\tLoss: 0.000416\t score_max: 5.328132\t score_min: -52.543770; Accuracy 0.996\n",
      "Train Epoch: 54 [500/1000 (50%)]\tLoss: 0.001502\t score_max: 5.328472\t score_min: -43.983967; Accuracy 0.990\n",
      "Train Epoch: 54 [550/1000 (55%)]\tLoss: 0.000448\t score_max: 5.329229\t score_min: -55.413864; Accuracy 0.995\n",
      "Train Epoch: 54 [600/1000 (60%)]\tLoss: 0.000480\t score_max: 5.329836\t score_min: -44.462044; Accuracy 0.993\n",
      "Train Epoch: 54 [650/1000 (65%)]\tLoss: 0.000144\t score_max: 5.330310\t score_min: -45.580296; Accuracy 0.995\n",
      "Train Epoch: 54 [700/1000 (70%)]\tLoss: 0.000961\t score_max: 5.330716\t score_min: -45.403111; Accuracy 0.993\n",
      "Train Epoch: 54 [750/1000 (75%)]\tLoss: 0.000264\t score_max: 5.330882\t score_min: -56.588860; Accuracy 0.996\n",
      "Train Epoch: 54 [800/1000 (80%)]\tLoss: 0.000398\t score_max: 5.331048\t score_min: -48.095356; Accuracy 0.993\n",
      "Train Epoch: 54 [850/1000 (85%)]\tLoss: 0.000420\t score_max: 5.331158\t score_min: -50.318844; Accuracy 0.996\n",
      "Train Epoch: 54 [900/1000 (90%)]\tLoss: 0.000215\t score_max: 5.331243\t score_min: -55.935318; Accuracy 0.996\n",
      "Train Epoch: 54 [950/1000 (95%)]\tLoss: 0.000238\t score_max: 5.331380\t score_min: -53.185875; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041470624855719505 ACCURACY: 0.9945049792528152\n",
      "Epoch:  55\n",
      "Train Epoch: 55 [0/1000 (0%)]\tLoss: 0.000205\t score_max: 5.331493\t score_min: -53.271317; Accuracy 0.996\n",
      "Train Epoch: 55 [50/1000 (5%)]\tLoss: 0.000635\t score_max: 5.331535\t score_min: -49.480129; Accuracy 0.994\n",
      "Train Epoch: 55 [100/1000 (10%)]\tLoss: 0.000891\t score_max: 5.331696\t score_min: -54.451920; Accuracy 0.996\n",
      "Train Epoch: 55 [150/1000 (15%)]\tLoss: 0.000532\t score_max: 5.331915\t score_min: -45.345055; Accuracy 0.993\n",
      "Train Epoch: 55 [200/1000 (20%)]\tLoss: 0.000390\t score_max: 5.332235\t score_min: -42.657967; Accuracy 0.991\n",
      "Train Epoch: 55 [250/1000 (25%)]\tLoss: 0.000257\t score_max: 5.332672\t score_min: -46.857613; Accuracy 0.994\n",
      "Train Epoch: 55 [300/1000 (30%)]\tLoss: 0.000282\t score_max: 5.333117\t score_min: -59.981621; Accuracy 0.997\n",
      "Train Epoch: 55 [350/1000 (35%)]\tLoss: 0.000259\t score_max: 5.333443\t score_min: -53.338364; Accuracy 0.996\n",
      "Train Epoch: 55 [400/1000 (40%)]\tLoss: 0.000340\t score_max: 5.333696\t score_min: -52.239204; Accuracy 0.996\n",
      "Train Epoch: 55 [450/1000 (45%)]\tLoss: 0.000361\t score_max: 5.333918\t score_min: -51.444695; Accuracy 0.994\n",
      "Train Epoch: 55 [500/1000 (50%)]\tLoss: 0.000434\t score_max: 5.334238\t score_min: -49.377647; Accuracy 0.993\n",
      "Train Epoch: 55 [550/1000 (55%)]\tLoss: 0.000271\t score_max: 5.334565\t score_min: -48.971947; Accuracy 0.997\n",
      "Train Epoch: 55 [600/1000 (60%)]\tLoss: 0.000425\t score_max: 5.334782\t score_min: -47.364975; Accuracy 0.994\n",
      "Train Epoch: 55 [650/1000 (65%)]\tLoss: 0.000330\t score_max: 5.334906\t score_min: -50.682930; Accuracy 0.996\n",
      "Train Epoch: 55 [700/1000 (70%)]\tLoss: 0.000420\t score_max: 5.335072\t score_min: -47.466499; Accuracy 0.994\n",
      "Train Epoch: 55 [750/1000 (75%)]\tLoss: 0.000359\t score_max: 5.335301\t score_min: -52.962624; Accuracy 0.994\n",
      "Train Epoch: 55 [800/1000 (80%)]\tLoss: 0.000561\t score_max: 5.335647\t score_min: -52.900677; Accuracy 0.996\n",
      "Train Epoch: 55 [850/1000 (85%)]\tLoss: 0.000213\t score_max: 5.336042\t score_min: -54.246010; Accuracy 0.996\n",
      "Train Epoch: 55 [900/1000 (90%)]\tLoss: 0.000270\t score_max: 5.336449\t score_min: -51.900780; Accuracy 0.995\n",
      "Train Epoch: 55 [950/1000 (95%)]\tLoss: 0.000248\t score_max: 5.336828\t score_min: -47.107235; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.000384092160675209 ACCURACY: 0.9947499781847\n",
      "Epoch:  56\n",
      "Train Epoch: 56 [0/1000 (0%)]\tLoss: 0.000284\t score_max: 5.337226\t score_min: -51.190586; Accuracy 0.993\n",
      "Train Epoch: 56 [50/1000 (5%)]\tLoss: 0.000521\t score_max: 5.337541\t score_min: -49.488510; Accuracy 0.996\n",
      "Train Epoch: 56 [100/1000 (10%)]\tLoss: 0.000142\t score_max: 5.337732\t score_min: -52.898453; Accuracy 0.996\n",
      "Train Epoch: 56 [150/1000 (15%)]\tLoss: 0.000236\t score_max: 5.337917\t score_min: -53.888897; Accuracy 0.994\n",
      "Train Epoch: 56 [200/1000 (20%)]\tLoss: 0.000469\t score_max: 5.338086\t score_min: -52.444199; Accuracy 0.995\n",
      "Train Epoch: 56 [250/1000 (25%)]\tLoss: 0.000431\t score_max: 5.338241\t score_min: -46.580143; Accuracy 0.995\n",
      "Train Epoch: 56 [300/1000 (30%)]\tLoss: 0.000514\t score_max: 5.338251\t score_min: -44.461411; Accuracy 0.994\n",
      "Train Epoch: 56 [350/1000 (35%)]\tLoss: 0.000289\t score_max: 5.338350\t score_min: -50.714828; Accuracy 0.994\n",
      "Train Epoch: 56 [400/1000 (40%)]\tLoss: 0.000198\t score_max: 5.338435\t score_min: -48.157413; Accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [450/1000 (45%)]\tLoss: 0.000566\t score_max: 5.338515\t score_min: -52.754559; Accuracy 0.995\n",
      "Train Epoch: 56 [500/1000 (50%)]\tLoss: 0.000282\t score_max: 5.338765\t score_min: -54.632710; Accuracy 0.996\n",
      "Train Epoch: 56 [550/1000 (55%)]\tLoss: 0.000313\t score_max: 5.339074\t score_min: -56.970345; Accuracy 0.996\n",
      "Train Epoch: 56 [600/1000 (60%)]\tLoss: 0.000186\t score_max: 5.339362\t score_min: -47.278214; Accuracy 0.993\n",
      "Train Epoch: 56 [650/1000 (65%)]\tLoss: 0.000455\t score_max: 5.339671\t score_min: -51.808693; Accuracy 0.992\n",
      "Train Epoch: 56 [700/1000 (70%)]\tLoss: 0.000328\t score_max: 5.340167\t score_min: -52.424698; Accuracy 0.995\n",
      "Train Epoch: 56 [750/1000 (75%)]\tLoss: 0.000317\t score_max: 5.340655\t score_min: -48.476032; Accuracy 0.994\n",
      "Train Epoch: 56 [800/1000 (80%)]\tLoss: 0.000574\t score_max: 5.341044\t score_min: -50.721924; Accuracy 0.995\n",
      "Train Epoch: 56 [850/1000 (85%)]\tLoss: 0.000410\t score_max: 5.341283\t score_min: -55.301003; Accuracy 0.995\n",
      "Train Epoch: 56 [900/1000 (90%)]\tLoss: 0.000431\t score_max: 5.341457\t score_min: -53.475780; Accuracy 0.994\n",
      "Train Epoch: 56 [950/1000 (95%)]\tLoss: 0.000236\t score_max: 5.341470\t score_min: -55.127151; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00035910782244172876 ACCURACY: 0.9944949716329574\n",
      "Epoch:  57\n",
      "Train Epoch: 57 [0/1000 (0%)]\tLoss: 0.000468\t score_max: 5.341437\t score_min: -45.546909; Accuracy 0.993\n",
      "Train Epoch: 57 [50/1000 (5%)]\tLoss: 0.000215\t score_max: 5.341365\t score_min: -46.704739; Accuracy 0.994\n",
      "Train Epoch: 57 [100/1000 (10%)]\tLoss: 0.000268\t score_max: 5.341328\t score_min: -45.794239; Accuracy 0.994\n",
      "Train Epoch: 57 [150/1000 (15%)]\tLoss: 0.000401\t score_max: 5.341352\t score_min: -52.403301; Accuracy 0.996\n",
      "Train Epoch: 57 [200/1000 (20%)]\tLoss: 0.000248\t score_max: 5.341474\t score_min: -49.082951; Accuracy 0.994\n",
      "Train Epoch: 57 [250/1000 (25%)]\tLoss: 0.000369\t score_max: 5.341705\t score_min: -46.882935; Accuracy 0.994\n",
      "Train Epoch: 57 [300/1000 (30%)]\tLoss: 0.000463\t score_max: 5.341949\t score_min: -59.638496; Accuracy 0.996\n",
      "Train Epoch: 57 [350/1000 (35%)]\tLoss: 0.000607\t score_max: 5.342308\t score_min: -51.525742; Accuracy 0.993\n",
      "Train Epoch: 57 [400/1000 (40%)]\tLoss: 0.000296\t score_max: 5.342694\t score_min: -57.417255; Accuracy 0.998\n",
      "Train Epoch: 57 [450/1000 (45%)]\tLoss: 0.000392\t score_max: 5.343101\t score_min: -43.476879; Accuracy 0.993\n",
      "Train Epoch: 57 [500/1000 (50%)]\tLoss: 0.000732\t score_max: 5.343565\t score_min: -45.521820; Accuracy 0.994\n",
      "Train Epoch: 57 [550/1000 (55%)]\tLoss: 0.000389\t score_max: 5.343966\t score_min: -39.395203; Accuracy 0.995\n",
      "Train Epoch: 57 [600/1000 (60%)]\tLoss: 0.000284\t score_max: 5.344352\t score_min: -54.793278; Accuracy 0.995\n",
      "Train Epoch: 57 [650/1000 (65%)]\tLoss: 0.000270\t score_max: 5.344754\t score_min: -52.330212; Accuracy 0.994\n",
      "Train Epoch: 57 [700/1000 (70%)]\tLoss: 0.000569\t score_max: 5.345126\t score_min: -45.511703; Accuracy 0.992\n",
      "Train Epoch: 57 [750/1000 (75%)]\tLoss: 0.000571\t score_max: 5.345544\t score_min: -52.498867; Accuracy 0.995\n",
      "Train Epoch: 57 [800/1000 (80%)]\tLoss: 0.000172\t score_max: 5.345779\t score_min: -54.364517; Accuracy 0.997\n",
      "Train Epoch: 57 [850/1000 (85%)]\tLoss: 0.000422\t score_max: 5.346000\t score_min: -55.511494; Accuracy 0.996\n",
      "Train Epoch: 57 [900/1000 (90%)]\tLoss: 0.000160\t score_max: 5.346139\t score_min: -54.940071; Accuracy 0.996\n",
      "Train Epoch: 57 [950/1000 (95%)]\tLoss: 0.000259\t score_max: 5.346283\t score_min: -53.243610; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003777778176299762 ACCURACY: 0.9947624772787094\n",
      "Epoch:  58\n",
      "Train Epoch: 58 [0/1000 (0%)]\tLoss: 0.000542\t score_max: 5.346456\t score_min: -45.736973; Accuracy 0.994\n",
      "Train Epoch: 58 [50/1000 (5%)]\tLoss: 0.000388\t score_max: 5.346528\t score_min: -48.177307; Accuracy 0.992\n",
      "Train Epoch: 58 [100/1000 (10%)]\tLoss: 0.000460\t score_max: 5.346702\t score_min: -48.697697; Accuracy 0.994\n",
      "Train Epoch: 58 [150/1000 (15%)]\tLoss: 0.000366\t score_max: 5.346889\t score_min: -55.071182; Accuracy 0.996\n",
      "Train Epoch: 58 [200/1000 (20%)]\tLoss: 0.000211\t score_max: 5.347064\t score_min: -57.336636; Accuracy 0.997\n",
      "Train Epoch: 58 [250/1000 (25%)]\tLoss: 0.000238\t score_max: 5.347282\t score_min: -48.049454; Accuracy 0.996\n",
      "Train Epoch: 58 [300/1000 (30%)]\tLoss: 0.000398\t score_max: 5.347499\t score_min: -42.617260; Accuracy 0.993\n",
      "Train Epoch: 58 [350/1000 (35%)]\tLoss: 0.000205\t score_max: 5.347775\t score_min: -55.451763; Accuracy 0.996\n",
      "Train Epoch: 58 [400/1000 (40%)]\tLoss: 0.001012\t score_max: 5.348066\t score_min: -43.970100; Accuracy 0.991\n",
      "Train Epoch: 58 [450/1000 (45%)]\tLoss: 0.000213\t score_max: 5.348674\t score_min: -55.662609; Accuracy 0.996\n",
      "Train Epoch: 58 [500/1000 (50%)]\tLoss: 0.000697\t score_max: 5.349211\t score_min: -52.083107; Accuracy 0.997\n",
      "Train Epoch: 58 [550/1000 (55%)]\tLoss: 0.000467\t score_max: 5.349518\t score_min: -42.914845; Accuracy 0.995\n",
      "Train Epoch: 58 [600/1000 (60%)]\tLoss: 0.000460\t score_max: 5.349672\t score_min: -42.453079; Accuracy 0.994\n",
      "Train Epoch: 58 [650/1000 (65%)]\tLoss: 0.000537\t score_max: 5.349918\t score_min: -46.165867; Accuracy 0.994\n",
      "Train Epoch: 58 [700/1000 (70%)]\tLoss: 0.000246\t score_max: 5.350050\t score_min: -52.982018; Accuracy 0.995\n",
      "Train Epoch: 58 [750/1000 (75%)]\tLoss: 0.000318\t score_max: 5.350215\t score_min: -49.859463; Accuracy 0.995\n",
      "Train Epoch: 58 [800/1000 (80%)]\tLoss: 0.000456\t score_max: 5.350316\t score_min: -47.093891; Accuracy 0.994\n",
      "Train Epoch: 58 [850/1000 (85%)]\tLoss: 0.000347\t score_max: 5.350308\t score_min: -49.301571; Accuracy 0.994\n",
      "Train Epoch: 58 [900/1000 (90%)]\tLoss: 0.000275\t score_max: 5.350360\t score_min: -55.325684; Accuracy 0.996\n",
      "Train Epoch: 58 [950/1000 (95%)]\tLoss: 0.000468\t score_max: 5.350460\t score_min: -55.438046; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004153366215177812 ACCURACY: 0.9946724712848664\n",
      "Epoch:  59\n",
      "Train Epoch: 59 [0/1000 (0%)]\tLoss: 0.000612\t score_max: 5.350739\t score_min: -48.349419; Accuracy 0.995\n",
      "Train Epoch: 59 [50/1000 (5%)]\tLoss: 0.000821\t score_max: 5.350933\t score_min: -49.861027; Accuracy 0.995\n",
      "Train Epoch: 59 [100/1000 (10%)]\tLoss: 0.000327\t score_max: 5.350835\t score_min: -51.245823; Accuracy 0.995\n",
      "Train Epoch: 59 [150/1000 (15%)]\tLoss: 0.000612\t score_max: 5.350838\t score_min: -50.212749; Accuracy 0.993\n",
      "Train Epoch: 59 [200/1000 (20%)]\tLoss: 0.000083\t score_max: 5.351004\t score_min: -55.404793; Accuracy 0.996\n",
      "Train Epoch: 59 [250/1000 (25%)]\tLoss: 0.000438\t score_max: 5.351188\t score_min: -48.691402; Accuracy 0.994\n",
      "Train Epoch: 59 [300/1000 (30%)]\tLoss: 0.000352\t score_max: 5.351351\t score_min: -50.616650; Accuracy 0.995\n",
      "Train Epoch: 59 [350/1000 (35%)]\tLoss: 0.000358\t score_max: 5.351531\t score_min: -53.841438; Accuracy 0.995\n",
      "Train Epoch: 59 [400/1000 (40%)]\tLoss: 0.000528\t score_max: 5.351820\t score_min: -45.255936; Accuracy 0.995\n",
      "Train Epoch: 59 [450/1000 (45%)]\tLoss: 0.000235\t score_max: 5.352150\t score_min: -52.039284; Accuracy 0.994\n",
      "Train Epoch: 59 [500/1000 (50%)]\tLoss: 0.000552\t score_max: 5.352460\t score_min: -51.827858; Accuracy 0.993\n",
      "Train Epoch: 59 [550/1000 (55%)]\tLoss: 0.000494\t score_max: 5.352934\t score_min: -51.969746; Accuracy 0.994\n",
      "Train Epoch: 59 [600/1000 (60%)]\tLoss: 0.000372\t score_max: 5.353227\t score_min: -42.650654; Accuracy 0.994\n",
      "Train Epoch: 59 [650/1000 (65%)]\tLoss: 0.000361\t score_max: 5.353420\t score_min: -56.775581; Accuracy 0.995\n",
      "Train Epoch: 59 [700/1000 (70%)]\tLoss: 0.000226\t score_max: 5.353567\t score_min: -46.044693; Accuracy 0.996\n",
      "Train Epoch: 59 [750/1000 (75%)]\tLoss: 0.000592\t score_max: 5.353649\t score_min: -50.326462; Accuracy 0.992\n",
      "Train Epoch: 59 [800/1000 (80%)]\tLoss: 0.000297\t score_max: 5.353943\t score_min: -58.644283; Accuracy 0.997\n",
      "Train Epoch: 59 [850/1000 (85%)]\tLoss: 0.000127\t score_max: 5.354133\t score_min: -50.841236; Accuracy 0.996\n",
      "Train Epoch: 59 [900/1000 (90%)]\tLoss: 0.000354\t score_max: 5.354336\t score_min: -56.987095; Accuracy 0.996\n",
      "Train Epoch: 59 [950/1000 (95%)]\tLoss: 0.000129\t score_max: 5.354575\t score_min: -51.820190; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.00039353768734144977 ACCURACY: 0.9948524743318558\n",
      "Epoch:  60\n",
      "Train Epoch: 60 [0/1000 (0%)]\tLoss: 0.000363\t score_max: 5.354797\t score_min: -47.540245; Accuracy 0.996\n",
      "Train Epoch: 60 [50/1000 (5%)]\tLoss: 0.000412\t score_max: 5.354924\t score_min: -50.860451; Accuracy 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [100/1000 (10%)]\tLoss: 0.000309\t score_max: 5.355065\t score_min: -50.001060; Accuracy 0.996\n",
      "Train Epoch: 60 [150/1000 (15%)]\tLoss: 0.000342\t score_max: 5.355231\t score_min: -48.592705; Accuracy 0.994\n",
      "Train Epoch: 60 [200/1000 (20%)]\tLoss: 0.000415\t score_max: 5.355471\t score_min: -53.283569; Accuracy 0.996\n",
      "Train Epoch: 60 [250/1000 (25%)]\tLoss: 0.000352\t score_max: 5.355660\t score_min: -53.590096; Accuracy 0.995\n",
      "Train Epoch: 60 [300/1000 (30%)]\tLoss: 0.000333\t score_max: 5.355769\t score_min: -52.754520; Accuracy 0.995\n",
      "Train Epoch: 60 [350/1000 (35%)]\tLoss: 0.000370\t score_max: 5.355864\t score_min: -49.931374; Accuracy 0.994\n",
      "Train Epoch: 60 [400/1000 (40%)]\tLoss: 0.000229\t score_max: 5.355940\t score_min: -47.922958; Accuracy 0.997\n",
      "Train Epoch: 60 [450/1000 (45%)]\tLoss: 0.000256\t score_max: 5.355973\t score_min: -50.522911; Accuracy 0.994\n",
      "Train Epoch: 60 [500/1000 (50%)]\tLoss: 0.000359\t score_max: 5.356035\t score_min: -54.134727; Accuracy 0.995\n",
      "Train Epoch: 60 [550/1000 (55%)]\tLoss: 0.000506\t score_max: 5.356195\t score_min: -45.880322; Accuracy 0.993\n",
      "Train Epoch: 60 [600/1000 (60%)]\tLoss: 0.000075\t score_max: 5.356417\t score_min: -61.078709; Accuracy 0.996\n",
      "Train Epoch: 60 [650/1000 (65%)]\tLoss: 0.000181\t score_max: 5.356631\t score_min: -54.439232; Accuracy 0.995\n",
      "Train Epoch: 60 [700/1000 (70%)]\tLoss: 0.000199\t score_max: 5.356895\t score_min: -47.056652; Accuracy 0.993\n",
      "Train Epoch: 60 [750/1000 (75%)]\tLoss: 0.000546\t score_max: 5.357153\t score_min: -54.420731; Accuracy 0.996\n",
      "Train Epoch: 60 [800/1000 (80%)]\tLoss: 0.000254\t score_max: 5.357571\t score_min: -58.199665; Accuracy 0.996\n",
      "Train Epoch: 60 [850/1000 (85%)]\tLoss: 0.000303\t score_max: 5.358054\t score_min: -51.920849; Accuracy 0.994\n",
      "Train Epoch: 60 [900/1000 (90%)]\tLoss: 0.000438\t score_max: 5.358467\t score_min: -52.046913; Accuracy 0.995\n",
      "Train Epoch: 60 [950/1000 (95%)]\tLoss: 0.000756\t score_max: 5.358927\t score_min: -45.174896; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003498759266221896 ACCURACY: 0.9949974745512009\n",
      "Epoch:  61\n",
      "Train Epoch: 61 [0/1000 (0%)]\tLoss: 0.000318\t score_max: 5.359129\t score_min: -55.464119; Accuracy 0.996\n",
      "Train Epoch: 61 [50/1000 (5%)]\tLoss: 0.000351\t score_max: 5.359267\t score_min: -42.052662; Accuracy 0.995\n",
      "Train Epoch: 61 [100/1000 (10%)]\tLoss: 0.000219\t score_max: 5.359400\t score_min: -51.118683; Accuracy 0.995\n",
      "Train Epoch: 61 [150/1000 (15%)]\tLoss: 0.000385\t score_max: 5.359525\t score_min: -47.657383; Accuracy 0.993\n",
      "Train Epoch: 61 [200/1000 (20%)]\tLoss: 0.000352\t score_max: 5.359619\t score_min: -46.758442; Accuracy 0.993\n",
      "Train Epoch: 61 [250/1000 (25%)]\tLoss: 0.000300\t score_max: 5.359704\t score_min: -57.182991; Accuracy 0.997\n",
      "Train Epoch: 61 [300/1000 (30%)]\tLoss: 0.000082\t score_max: 5.359783\t score_min: -56.771751; Accuracy 0.997\n",
      "Train Epoch: 61 [350/1000 (35%)]\tLoss: 0.000225\t score_max: 5.359898\t score_min: -55.113758; Accuracy 0.995\n",
      "Train Epoch: 61 [400/1000 (40%)]\tLoss: 0.000295\t score_max: 5.360043\t score_min: -52.327042; Accuracy 0.995\n",
      "Train Epoch: 61 [450/1000 (45%)]\tLoss: 0.000352\t score_max: 5.360181\t score_min: -45.486740; Accuracy 0.994\n",
      "Train Epoch: 61 [500/1000 (50%)]\tLoss: 0.000208\t score_max: 5.360412\t score_min: -55.487629; Accuracy 0.996\n",
      "Train Epoch: 61 [550/1000 (55%)]\tLoss: 0.000345\t score_max: 5.360657\t score_min: -48.874809; Accuracy 0.995\n",
      "Train Epoch: 61 [600/1000 (60%)]\tLoss: 0.000282\t score_max: 5.360847\t score_min: -58.463543; Accuracy 0.997\n",
      "Train Epoch: 61 [650/1000 (65%)]\tLoss: 0.000342\t score_max: 5.361038\t score_min: -48.478210; Accuracy 0.995\n",
      "Train Epoch: 61 [700/1000 (70%)]\tLoss: 0.000313\t score_max: 5.361194\t score_min: -49.771400; Accuracy 0.995\n",
      "Train Epoch: 61 [750/1000 (75%)]\tLoss: 0.000239\t score_max: 5.361308\t score_min: -57.474922; Accuracy 0.998\n",
      "Train Epoch: 61 [800/1000 (80%)]\tLoss: 0.000292\t score_max: 5.361478\t score_min: -46.754387; Accuracy 0.994\n",
      "Train Epoch: 61 [850/1000 (85%)]\tLoss: 0.000674\t score_max: 5.361702\t score_min: -43.795033; Accuracy 0.992\n",
      "Train Epoch: 61 [900/1000 (90%)]\tLoss: 0.000329\t score_max: 5.362092\t score_min: -54.937691; Accuracy 0.996\n",
      "Train Epoch: 61 [950/1000 (95%)]\tLoss: 0.000663\t score_max: 5.362473\t score_min: -47.102089; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003283881440438563 ACCURACY: 0.9952299803495407\n",
      "Epoch:  62\n",
      "Train Epoch: 62 [0/1000 (0%)]\tLoss: 0.000686\t score_max: 5.362923\t score_min: -45.020657; Accuracy 0.991\n",
      "Train Epoch: 62 [50/1000 (5%)]\tLoss: 0.000228\t score_max: 5.363541\t score_min: -56.517723; Accuracy 0.998\n",
      "Train Epoch: 62 [100/1000 (10%)]\tLoss: 0.000400\t score_max: 5.364041\t score_min: -46.633999; Accuracy 0.993\n",
      "Train Epoch: 62 [150/1000 (15%)]\tLoss: 0.000569\t score_max: 5.364473\t score_min: -51.526329; Accuracy 0.995\n",
      "Train Epoch: 62 [200/1000 (20%)]\tLoss: 0.000585\t score_max: 5.364677\t score_min: -46.237698; Accuracy 0.991\n",
      "Train Epoch: 62 [250/1000 (25%)]\tLoss: 0.000146\t score_max: 5.364825\t score_min: -55.399853; Accuracy 0.996\n",
      "Train Epoch: 62 [300/1000 (30%)]\tLoss: 0.000451\t score_max: 5.364976\t score_min: -52.519703; Accuracy 0.995\n",
      "Train Epoch: 62 [350/1000 (35%)]\tLoss: 0.000298\t score_max: 5.365042\t score_min: -43.969246; Accuracy 0.993\n",
      "Train Epoch: 62 [400/1000 (40%)]\tLoss: 0.000584\t score_max: 5.365119\t score_min: -47.392807; Accuracy 0.993\n",
      "Train Epoch: 62 [450/1000 (45%)]\tLoss: 0.000126\t score_max: 5.365244\t score_min: -52.810699; Accuracy 0.996\n",
      "Train Epoch: 62 [500/1000 (50%)]\tLoss: 0.000415\t score_max: 5.365351\t score_min: -53.240601; Accuracy 0.995\n",
      "Train Epoch: 62 [550/1000 (55%)]\tLoss: 0.000236\t score_max: 5.365526\t score_min: -52.003433; Accuracy 0.995\n",
      "Train Epoch: 62 [600/1000 (60%)]\tLoss: 0.000379\t score_max: 5.365728\t score_min: -51.899616; Accuracy 0.994\n",
      "Train Epoch: 62 [650/1000 (65%)]\tLoss: 0.000269\t score_max: 5.365968\t score_min: -48.454151; Accuracy 0.993\n",
      "Train Epoch: 62 [700/1000 (70%)]\tLoss: 0.000133\t score_max: 5.366260\t score_min: -58.719944; Accuracy 0.997\n",
      "Train Epoch: 62 [750/1000 (75%)]\tLoss: 0.000440\t score_max: 5.366496\t score_min: -52.554192; Accuracy 0.995\n",
      "Train Epoch: 62 [800/1000 (80%)]\tLoss: 0.000238\t score_max: 5.366817\t score_min: -52.252396; Accuracy 0.996\n",
      "Train Epoch: 62 [850/1000 (85%)]\tLoss: 0.000300\t score_max: 5.367095\t score_min: -51.459568; Accuracy 0.995\n",
      "Train Epoch: 62 [900/1000 (90%)]\tLoss: 0.000467\t score_max: 5.367308\t score_min: -49.045883; Accuracy 0.994\n",
      "Train Epoch: 62 [950/1000 (95%)]\tLoss: 0.000365\t score_max: 5.367508\t score_min: -54.668957; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003656685468740761 ACCURACY: 0.9945549756288529\n",
      "Epoch:  63\n",
      "Train Epoch: 63 [0/1000 (0%)]\tLoss: 0.000389\t score_max: 5.367690\t score_min: -55.589092; Accuracy 0.995\n",
      "Train Epoch: 63 [50/1000 (5%)]\tLoss: 0.000055\t score_max: 5.368048\t score_min: -57.864971; Accuracy 0.997\n",
      "Train Epoch: 63 [100/1000 (10%)]\tLoss: 0.000423\t score_max: 5.368400\t score_min: -53.651730; Accuracy 0.994\n",
      "Train Epoch: 63 [150/1000 (15%)]\tLoss: 0.000143\t score_max: 5.368850\t score_min: -53.683128; Accuracy 0.994\n",
      "Train Epoch: 63 [200/1000 (20%)]\tLoss: 0.000278\t score_max: 5.369312\t score_min: -48.770332; Accuracy 0.994\n",
      "Train Epoch: 63 [250/1000 (25%)]\tLoss: 0.000239\t score_max: 5.369763\t score_min: -52.702854; Accuracy 0.995\n",
      "Train Epoch: 63 [300/1000 (30%)]\tLoss: 0.000490\t score_max: 5.370152\t score_min: -45.362053; Accuracy 0.993\n",
      "Train Epoch: 63 [350/1000 (35%)]\tLoss: 0.000238\t score_max: 5.370461\t score_min: -49.993713; Accuracy 0.995\n",
      "Train Epoch: 63 [400/1000 (40%)]\tLoss: 0.000343\t score_max: 5.370708\t score_min: -45.844547; Accuracy 0.992\n",
      "Train Epoch: 63 [450/1000 (45%)]\tLoss: 0.000228\t score_max: 5.370939\t score_min: -47.654388; Accuracy 0.994\n",
      "Train Epoch: 63 [500/1000 (50%)]\tLoss: 0.000934\t score_max: 5.371130\t score_min: -40.738564; Accuracy 0.993\n",
      "Train Epoch: 63 [550/1000 (55%)]\tLoss: 0.000470\t score_max: 5.371484\t score_min: -55.662498; Accuracy 0.996\n",
      "Train Epoch: 63 [600/1000 (60%)]\tLoss: 0.000292\t score_max: 5.371695\t score_min: -50.927757; Accuracy 0.993\n",
      "Train Epoch: 63 [650/1000 (65%)]\tLoss: 0.000471\t score_max: 5.371901\t score_min: -57.636703; Accuracy 0.997\n",
      "Train Epoch: 63 [700/1000 (70%)]\tLoss: 0.000211\t score_max: 5.371933\t score_min: -53.299763; Accuracy 0.996\n",
      "Train Epoch: 63 [750/1000 (75%)]\tLoss: 0.000370\t score_max: 5.371944\t score_min: -48.172222; Accuracy 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [800/1000 (80%)]\tLoss: 0.000243\t score_max: 5.372028\t score_min: -54.481140; Accuracy 0.995\n",
      "Train Epoch: 63 [850/1000 (85%)]\tLoss: 0.000086\t score_max: 5.372062\t score_min: -62.027573; Accuracy 0.997\n",
      "Train Epoch: 63 [900/1000 (90%)]\tLoss: 0.000333\t score_max: 5.372128\t score_min: -56.769619; Accuracy 0.996\n",
      "Train Epoch: 63 [950/1000 (95%)]\tLoss: 0.000252\t score_max: 5.372334\t score_min: -51.985920; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003242869350287947 ACCURACY: 0.9946724742650985\n",
      "Epoch:  64\n",
      "Train Epoch: 64 [0/1000 (0%)]\tLoss: 0.000193\t score_max: 5.372617\t score_min: -55.388832; Accuracy 0.996\n",
      "Train Epoch: 64 [50/1000 (5%)]\tLoss: 0.002053\t score_max: 5.372956\t score_min: -47.335609; Accuracy 0.991\n",
      "Train Epoch: 64 [100/1000 (10%)]\tLoss: 0.000363\t score_max: 5.373827\t score_min: -49.819756; Accuracy 0.995\n",
      "Train Epoch: 64 [150/1000 (15%)]\tLoss: 0.000361\t score_max: 5.374603\t score_min: -41.203995; Accuracy 0.994\n",
      "Train Epoch: 64 [200/1000 (20%)]\tLoss: 0.000287\t score_max: 5.375338\t score_min: -51.094078; Accuracy 0.994\n",
      "Train Epoch: 64 [250/1000 (25%)]\tLoss: 0.000791\t score_max: 5.375916\t score_min: -49.734440; Accuracy 0.993\n",
      "Train Epoch: 64 [300/1000 (30%)]\tLoss: 0.000495\t score_max: 5.376271\t score_min: -48.257069; Accuracy 0.992\n",
      "Train Epoch: 64 [350/1000 (35%)]\tLoss: 0.000309\t score_max: 5.376605\t score_min: -52.883152; Accuracy 0.995\n",
      "Train Epoch: 64 [400/1000 (40%)]\tLoss: 0.000456\t score_max: 5.376837\t score_min: -58.776810; Accuracy 0.997\n",
      "Train Epoch: 64 [450/1000 (45%)]\tLoss: 0.000181\t score_max: 5.376916\t score_min: -52.756302; Accuracy 0.995\n",
      "Train Epoch: 64 [500/1000 (50%)]\tLoss: 0.000166\t score_max: 5.376941\t score_min: -54.830589; Accuracy 0.996\n",
      "Train Epoch: 64 [550/1000 (55%)]\tLoss: 0.000172\t score_max: 5.376970\t score_min: -50.571617; Accuracy 0.993\n",
      "Train Epoch: 64 [600/1000 (60%)]\tLoss: 0.000744\t score_max: 5.376989\t score_min: -38.715282; Accuracy 0.993\n",
      "Train Epoch: 64 [650/1000 (65%)]\tLoss: 0.000227\t score_max: 5.376976\t score_min: -51.164371; Accuracy 0.995\n",
      "Train Epoch: 64 [700/1000 (70%)]\tLoss: 0.000310\t score_max: 5.376978\t score_min: -50.284821; Accuracy 0.995\n",
      "Train Epoch: 64 [750/1000 (75%)]\tLoss: 0.000241\t score_max: 5.376995\t score_min: -50.087189; Accuracy 0.994\n",
      "Train Epoch: 64 [800/1000 (80%)]\tLoss: 0.000224\t score_max: 5.377011\t score_min: -45.686665; Accuracy 0.993\n",
      "Train Epoch: 64 [850/1000 (85%)]\tLoss: 0.000874\t score_max: 5.377026\t score_min: -43.065109; Accuracy 0.993\n",
      "Train Epoch: 64 [900/1000 (90%)]\tLoss: 0.000336\t score_max: 5.377239\t score_min: -51.008060; Accuracy 0.994\n",
      "Train Epoch: 64 [950/1000 (95%)]\tLoss: 0.000559\t score_max: 5.377456\t score_min: -55.050541; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00046716392898815684 ACCURACY: 0.9941149771213531\n",
      "Epoch:  65\n",
      "Train Epoch: 65 [0/1000 (0%)]\tLoss: 0.000387\t score_max: 5.377656\t score_min: -50.372757; Accuracy 0.994\n",
      "Train Epoch: 65 [50/1000 (5%)]\tLoss: 0.000650\t score_max: 5.377828\t score_min: -51.235683; Accuracy 0.995\n",
      "Train Epoch: 65 [100/1000 (10%)]\tLoss: 0.000148\t score_max: 5.378137\t score_min: -52.763920; Accuracy 0.996\n",
      "Train Epoch: 65 [150/1000 (15%)]\tLoss: 0.000418\t score_max: 5.378450\t score_min: -51.431694; Accuracy 0.993\n",
      "Train Epoch: 65 [200/1000 (20%)]\tLoss: 0.000521\t score_max: 5.378830\t score_min: -46.917328; Accuracy 0.992\n",
      "Train Epoch: 65 [250/1000 (25%)]\tLoss: 0.000640\t score_max: 5.379379\t score_min: -51.993229; Accuracy 0.995\n",
      "Train Epoch: 65 [300/1000 (30%)]\tLoss: 0.000266\t score_max: 5.380079\t score_min: -56.579617; Accuracy 0.995\n",
      "Train Epoch: 65 [350/1000 (35%)]\tLoss: 0.000301\t score_max: 5.380674\t score_min: -50.650650; Accuracy 0.995\n",
      "Train Epoch: 65 [400/1000 (40%)]\tLoss: 0.000228\t score_max: 5.381170\t score_min: -58.513962; Accuracy 0.997\n",
      "Train Epoch: 65 [450/1000 (45%)]\tLoss: 0.000958\t score_max: 5.381608\t score_min: -41.853546; Accuracy 0.993\n",
      "Train Epoch: 65 [500/1000 (50%)]\tLoss: 0.000372\t score_max: 5.381886\t score_min: -53.156891; Accuracy 0.997\n",
      "Train Epoch: 65 [550/1000 (55%)]\tLoss: 0.000515\t score_max: 5.382019\t score_min: -50.607849; Accuracy 0.993\n",
      "Train Epoch: 65 [600/1000 (60%)]\tLoss: 0.000198\t score_max: 5.382132\t score_min: -53.972694; Accuracy 0.995\n",
      "Train Epoch: 65 [650/1000 (65%)]\tLoss: 0.000431\t score_max: 5.382256\t score_min: -47.627258; Accuracy 0.993\n",
      "Train Epoch: 65 [700/1000 (70%)]\tLoss: 0.000566\t score_max: 5.382315\t score_min: -49.938347; Accuracy 0.994\n",
      "Train Epoch: 65 [750/1000 (75%)]\tLoss: 0.000389\t score_max: 5.382440\t score_min: -51.061207; Accuracy 0.994\n",
      "Train Epoch: 65 [800/1000 (80%)]\tLoss: 0.000586\t score_max: 5.382571\t score_min: -46.491497; Accuracy 0.990\n",
      "Train Epoch: 65 [850/1000 (85%)]\tLoss: 0.000393\t score_max: 5.382815\t score_min: -44.773026; Accuracy 0.992\n",
      "Train Epoch: 65 [900/1000 (90%)]\tLoss: 0.000163\t score_max: 5.383023\t score_min: -49.595348; Accuracy 0.993\n",
      "Train Epoch: 65 [950/1000 (95%)]\tLoss: 0.000214\t score_max: 5.383248\t score_min: -49.270901; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041721725137904285 ACCURACY: 0.9941524773836136\n",
      "Epoch:  66\n",
      "Train Epoch: 66 [0/1000 (0%)]\tLoss: 0.000240\t score_max: 5.383399\t score_min: -55.773132; Accuracy 0.995\n",
      "Train Epoch: 66 [50/1000 (5%)]\tLoss: 0.000578\t score_max: 5.383560\t score_min: -56.627602; Accuracy 0.996\n",
      "Train Epoch: 66 [100/1000 (10%)]\tLoss: 0.000275\t score_max: 5.383776\t score_min: -57.852203; Accuracy 0.995\n",
      "Train Epoch: 66 [150/1000 (15%)]\tLoss: 0.000331\t score_max: 5.383929\t score_min: -54.232925; Accuracy 0.995\n",
      "Train Epoch: 66 [200/1000 (20%)]\tLoss: 0.000153\t score_max: 5.384086\t score_min: -55.370758; Accuracy 0.996\n",
      "Train Epoch: 66 [250/1000 (25%)]\tLoss: 0.000240\t score_max: 5.384229\t score_min: -56.781029; Accuracy 0.996\n",
      "Train Epoch: 66 [300/1000 (30%)]\tLoss: 0.000258\t score_max: 5.384386\t score_min: -54.012726; Accuracy 0.995\n",
      "Train Epoch: 66 [350/1000 (35%)]\tLoss: 0.000357\t score_max: 5.384572\t score_min: -50.063473; Accuracy 0.995\n",
      "Train Epoch: 66 [400/1000 (40%)]\tLoss: 0.000365\t score_max: 5.384634\t score_min: -48.471157; Accuracy 0.996\n",
      "Train Epoch: 66 [450/1000 (45%)]\tLoss: 0.000358\t score_max: 5.384748\t score_min: -47.658947; Accuracy 0.993\n",
      "Train Epoch: 66 [500/1000 (50%)]\tLoss: 0.000222\t score_max: 5.384936\t score_min: -42.141068; Accuracy 0.995\n",
      "Train Epoch: 66 [550/1000 (55%)]\tLoss: 0.000282\t score_max: 5.385139\t score_min: -47.407368; Accuracy 0.992\n",
      "Train Epoch: 66 [600/1000 (60%)]\tLoss: 0.000293\t score_max: 5.385382\t score_min: -47.400009; Accuracy 0.996\n",
      "Train Epoch: 66 [650/1000 (65%)]\tLoss: 0.000711\t score_max: 5.385504\t score_min: -44.574738; Accuracy 0.993\n",
      "Train Epoch: 66 [700/1000 (70%)]\tLoss: 0.000395\t score_max: 5.385600\t score_min: -49.478378; Accuracy 0.995\n",
      "Train Epoch: 66 [750/1000 (75%)]\tLoss: 0.000339\t score_max: 5.385775\t score_min: -46.288422; Accuracy 0.994\n",
      "Train Epoch: 66 [800/1000 (80%)]\tLoss: 0.000481\t score_max: 5.385943\t score_min: -50.488548; Accuracy 0.992\n",
      "Train Epoch: 66 [850/1000 (85%)]\tLoss: 0.000226\t score_max: 5.386162\t score_min: -54.547829; Accuracy 0.995\n",
      "Train Epoch: 66 [900/1000 (90%)]\tLoss: 0.000358\t score_max: 5.386444\t score_min: -50.690414; Accuracy 0.993\n",
      "Train Epoch: 66 [950/1000 (95%)]\tLoss: 0.000551\t score_max: 5.386688\t score_min: -49.245697; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003507338944473304 ACCURACY: 0.994604977965355\n",
      "Epoch:  67\n",
      "Train Epoch: 67 [0/1000 (0%)]\tLoss: 0.000496\t score_max: 5.386780\t score_min: -45.718899; Accuracy 0.995\n",
      "Train Epoch: 67 [50/1000 (5%)]\tLoss: 0.000541\t score_max: 5.386852\t score_min: -42.595318; Accuracy 0.992\n",
      "Train Epoch: 67 [100/1000 (10%)]\tLoss: 0.000339\t score_max: 5.387087\t score_min: -45.687016; Accuracy 0.994\n",
      "Train Epoch: 67 [150/1000 (15%)]\tLoss: 0.000645\t score_max: 5.387281\t score_min: -47.401634; Accuracy 0.993\n",
      "Train Epoch: 67 [200/1000 (20%)]\tLoss: 0.000327\t score_max: 5.387616\t score_min: -45.704964; Accuracy 0.994\n",
      "Train Epoch: 67 [250/1000 (25%)]\tLoss: 0.000254\t score_max: 5.387875\t score_min: -53.928116; Accuracy 0.994\n",
      "Train Epoch: 67 [300/1000 (30%)]\tLoss: 0.000096\t score_max: 5.388076\t score_min: -56.822250; Accuracy 0.996\n",
      "Train Epoch: 67 [350/1000 (35%)]\tLoss: 0.000172\t score_max: 5.388290\t score_min: -51.608330; Accuracy 0.995\n",
      "Train Epoch: 67 [400/1000 (40%)]\tLoss: 0.000165\t score_max: 5.388545\t score_min: -49.764568; Accuracy 0.996\n",
      "Train Epoch: 67 [450/1000 (45%)]\tLoss: 0.000203\t score_max: 5.388758\t score_min: -55.826271; Accuracy 0.995\n",
      "Train Epoch: 67 [500/1000 (50%)]\tLoss: 0.000370\t score_max: 5.388980\t score_min: -58.853664; Accuracy 0.996\n",
      "Train Epoch: 67 [550/1000 (55%)]\tLoss: 0.000241\t score_max: 5.389252\t score_min: -55.924095; Accuracy 0.995\n",
      "Train Epoch: 67 [600/1000 (60%)]\tLoss: 0.000609\t score_max: 5.389462\t score_min: -54.573730; Accuracy 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [650/1000 (65%)]\tLoss: 0.000825\t score_max: 5.389714\t score_min: -49.804752; Accuracy 0.994\n",
      "Train Epoch: 67 [700/1000 (70%)]\tLoss: 0.000247\t score_max: 5.389711\t score_min: -55.202148; Accuracy 0.994\n",
      "Train Epoch: 67 [750/1000 (75%)]\tLoss: 0.000168\t score_max: 5.389755\t score_min: -53.635441; Accuracy 0.995\n",
      "Train Epoch: 67 [800/1000 (80%)]\tLoss: 0.000513\t score_max: 5.389800\t score_min: -45.037022; Accuracy 0.994\n",
      "Train Epoch: 67 [850/1000 (85%)]\tLoss: 0.000412\t score_max: 5.389865\t score_min: -47.972080; Accuracy 0.992\n",
      "Train Epoch: 67 [900/1000 (90%)]\tLoss: 0.000319\t score_max: 5.390031\t score_min: -53.512684; Accuracy 0.994\n",
      "Train Epoch: 67 [950/1000 (95%)]\tLoss: 0.000350\t score_max: 5.390188\t score_min: -52.501350; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00036454597247939093 ACCURACY: 0.9945949673652649\n",
      "Epoch:  68\n",
      "Train Epoch: 68 [0/1000 (0%)]\tLoss: 0.000416\t score_max: 5.390352\t score_min: -49.778275; Accuracy 0.994\n",
      "Train Epoch: 68 [50/1000 (5%)]\tLoss: 0.000387\t score_max: 5.390492\t score_min: -48.237762; Accuracy 0.994\n",
      "Train Epoch: 68 [100/1000 (10%)]\tLoss: 0.000582\t score_max: 5.390659\t score_min: -57.783436; Accuracy 0.993\n",
      "Train Epoch: 68 [150/1000 (15%)]\tLoss: 0.000290\t score_max: 5.390800\t score_min: -44.440590; Accuracy 0.994\n",
      "Train Epoch: 68 [200/1000 (20%)]\tLoss: 0.000707\t score_max: 5.390895\t score_min: -43.264004; Accuracy 0.992\n",
      "Train Epoch: 68 [250/1000 (25%)]\tLoss: 0.000286\t score_max: 5.391228\t score_min: -51.645088; Accuracy 0.995\n",
      "Train Epoch: 68 [300/1000 (30%)]\tLoss: 0.000437\t score_max: 5.391500\t score_min: -50.049225; Accuracy 0.993\n",
      "Train Epoch: 68 [350/1000 (35%)]\tLoss: 0.000146\t score_max: 5.391807\t score_min: -55.597340; Accuracy 0.996\n",
      "Train Epoch: 68 [400/1000 (40%)]\tLoss: 0.000248\t score_max: 5.392109\t score_min: -50.943069; Accuracy 0.993\n",
      "Train Epoch: 68 [450/1000 (45%)]\tLoss: 0.000314\t score_max: 5.392512\t score_min: -52.931450; Accuracy 0.994\n",
      "Train Epoch: 68 [500/1000 (50%)]\tLoss: 0.000157\t score_max: 5.392852\t score_min: -59.620712; Accuracy 0.997\n",
      "Train Epoch: 68 [550/1000 (55%)]\tLoss: 0.000475\t score_max: 5.393176\t score_min: -55.532963; Accuracy 0.995\n",
      "Train Epoch: 68 [600/1000 (60%)]\tLoss: 0.000243\t score_max: 5.393645\t score_min: -54.334305; Accuracy 0.994\n",
      "Train Epoch: 68 [650/1000 (65%)]\tLoss: 0.000524\t score_max: 5.394027\t score_min: -52.984123; Accuracy 0.997\n",
      "Train Epoch: 68 [700/1000 (70%)]\tLoss: 0.000264\t score_max: 5.394242\t score_min: -54.415073; Accuracy 0.996\n",
      "Train Epoch: 68 [750/1000 (75%)]\tLoss: 0.000362\t score_max: 5.394456\t score_min: -50.347244; Accuracy 0.995\n",
      "Train Epoch: 68 [800/1000 (80%)]\tLoss: 0.000273\t score_max: 5.394556\t score_min: -52.219254; Accuracy 0.994\n",
      "Train Epoch: 68 [850/1000 (85%)]\tLoss: 0.000338\t score_max: 5.394727\t score_min: -52.322865; Accuracy 0.993\n",
      "Train Epoch: 68 [900/1000 (90%)]\tLoss: 0.000454\t score_max: 5.394971\t score_min: -61.580143; Accuracy 0.997\n",
      "Train Epoch: 68 [950/1000 (95%)]\tLoss: 0.000788\t score_max: 5.395248\t score_min: -48.751293; Accuracy 0.992\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003846693769446574 ACCURACY: 0.9944124758243561\n",
      "Epoch:  69\n",
      "Train Epoch: 69 [0/1000 (0%)]\tLoss: 0.000298\t score_max: 5.395792\t score_min: -45.717690; Accuracy 0.995\n",
      "Train Epoch: 69 [50/1000 (5%)]\tLoss: 0.000411\t score_max: 5.396278\t score_min: -47.793419; Accuracy 0.995\n",
      "Train Epoch: 69 [100/1000 (10%)]\tLoss: 0.000407\t score_max: 5.396685\t score_min: -56.505501; Accuracy 0.996\n",
      "Train Epoch: 69 [150/1000 (15%)]\tLoss: 0.000269\t score_max: 5.396968\t score_min: -51.391628; Accuracy 0.992\n",
      "Train Epoch: 69 [200/1000 (20%)]\tLoss: 0.000307\t score_max: 5.397293\t score_min: -55.046627; Accuracy 0.995\n",
      "Train Epoch: 69 [250/1000 (25%)]\tLoss: 0.000288\t score_max: 5.397493\t score_min: -53.287304; Accuracy 0.995\n",
      "Train Epoch: 69 [300/1000 (30%)]\tLoss: 0.000182\t score_max: 5.397649\t score_min: -53.107544; Accuracy 0.996\n",
      "Train Epoch: 69 [350/1000 (35%)]\tLoss: 0.000188\t score_max: 5.397768\t score_min: -56.348282; Accuracy 0.996\n",
      "Train Epoch: 69 [400/1000 (40%)]\tLoss: 0.000358\t score_max: 5.397890\t score_min: -50.373245; Accuracy 0.994\n",
      "Train Epoch: 69 [450/1000 (45%)]\tLoss: 0.000275\t score_max: 5.398005\t score_min: -55.374313; Accuracy 0.995\n",
      "Train Epoch: 69 [500/1000 (50%)]\tLoss: 0.001090\t score_max: 5.398098\t score_min: -50.368515; Accuracy 0.990\n",
      "Train Epoch: 69 [550/1000 (55%)]\tLoss: 0.000379\t score_max: 5.398451\t score_min: -45.893147; Accuracy 0.993\n",
      "Train Epoch: 69 [600/1000 (60%)]\tLoss: 0.000448\t score_max: 5.398829\t score_min: -48.561340; Accuracy 0.994\n",
      "Train Epoch: 69 [650/1000 (65%)]\tLoss: 0.000154\t score_max: 5.399220\t score_min: -55.793983; Accuracy 0.995\n",
      "Train Epoch: 69 [700/1000 (70%)]\tLoss: 0.000582\t score_max: 5.399648\t score_min: -46.012398; Accuracy 0.992\n",
      "Train Epoch: 69 [750/1000 (75%)]\tLoss: 0.000434\t score_max: 5.400185\t score_min: -50.821499; Accuracy 0.994\n",
      "Train Epoch: 69 [800/1000 (80%)]\tLoss: 0.000220\t score_max: 5.400641\t score_min: -54.072472; Accuracy 0.994\n",
      "Train Epoch: 69 [850/1000 (85%)]\tLoss: 0.000356\t score_max: 5.401082\t score_min: -54.445175; Accuracy 0.994\n",
      "Train Epoch: 69 [900/1000 (90%)]\tLoss: 0.000642\t score_max: 5.401398\t score_min: -51.405247; Accuracy 0.993\n",
      "Train Epoch: 69 [950/1000 (95%)]\tLoss: 0.000279\t score_max: 5.401525\t score_min: -58.613384; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00037833350725122725 ACCURACY: 0.9942799717187881\n",
      "Epoch:  70\n",
      "Train Epoch: 70 [0/1000 (0%)]\tLoss: 0.000756\t score_max: 5.401669\t score_min: -55.444717; Accuracy 0.994\n",
      "Train Epoch: 70 [50/1000 (5%)]\tLoss: 0.000712\t score_max: 5.401620\t score_min: -49.794804; Accuracy 0.994\n",
      "Train Epoch: 70 [100/1000 (10%)]\tLoss: 0.000129\t score_max: 5.401380\t score_min: -54.593636; Accuracy 0.997\n",
      "Train Epoch: 70 [150/1000 (15%)]\tLoss: 0.000378\t score_max: 5.401218\t score_min: -53.824135; Accuracy 0.994\n",
      "Train Epoch: 70 [200/1000 (20%)]\tLoss: 0.000736\t score_max: 5.401221\t score_min: -47.261395; Accuracy 0.995\n",
      "Train Epoch: 70 [250/1000 (25%)]\tLoss: 0.001001\t score_max: 5.401062\t score_min: -57.051739; Accuracy 0.996\n",
      "Train Epoch: 70 [300/1000 (30%)]\tLoss: 0.000310\t score_max: 5.401210\t score_min: -50.024876; Accuracy 0.995\n",
      "Train Epoch: 70 [350/1000 (35%)]\tLoss: 0.000146\t score_max: 5.401409\t score_min: -60.149555; Accuracy 0.995\n",
      "Train Epoch: 70 [400/1000 (40%)]\tLoss: 0.000388\t score_max: 5.401625\t score_min: -48.896187; Accuracy 0.995\n",
      "Train Epoch: 70 [450/1000 (45%)]\tLoss: 0.000220\t score_max: 5.401972\t score_min: -59.987541; Accuracy 0.997\n",
      "Train Epoch: 70 [500/1000 (50%)]\tLoss: 0.000262\t score_max: 5.402350\t score_min: -49.374146; Accuracy 0.995\n",
      "Train Epoch: 70 [550/1000 (55%)]\tLoss: 0.000655\t score_max: 5.402663\t score_min: -51.494572; Accuracy 0.994\n",
      "Train Epoch: 70 [600/1000 (60%)]\tLoss: 0.000217\t score_max: 5.402979\t score_min: -50.860615; Accuracy 0.993\n",
      "Train Epoch: 70 [650/1000 (65%)]\tLoss: 0.000450\t score_max: 5.403306\t score_min: -45.592709; Accuracy 0.993\n",
      "Train Epoch: 70 [700/1000 (70%)]\tLoss: 0.000460\t score_max: 5.403536\t score_min: -47.227058; Accuracy 0.992\n",
      "Train Epoch: 70 [750/1000 (75%)]\tLoss: 0.000291\t score_max: 5.403780\t score_min: -50.131065; Accuracy 0.995\n",
      "Train Epoch: 70 [800/1000 (80%)]\tLoss: 0.000086\t score_max: 5.403983\t score_min: -50.031013; Accuracy 0.993\n",
      "Train Epoch: 70 [850/1000 (85%)]\tLoss: 0.000394\t score_max: 5.404196\t score_min: -48.470711; Accuracy 0.995\n",
      "Train Epoch: 70 [900/1000 (90%)]\tLoss: 0.000327\t score_max: 5.404460\t score_min: -57.041786; Accuracy 0.996\n",
      "Train Epoch: 70 [950/1000 (95%)]\tLoss: 0.000238\t score_max: 5.404709\t score_min: -50.190659; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00040775166344246826 ACCURACY: 0.9945924699306488\n",
      "Epoch:  71\n",
      "Train Epoch: 71 [0/1000 (0%)]\tLoss: 0.000261\t score_max: 5.404934\t score_min: -51.153229; Accuracy 0.994\n",
      "Train Epoch: 71 [50/1000 (5%)]\tLoss: 0.000309\t score_max: 5.405227\t score_min: -47.711990; Accuracy 0.994\n",
      "Train Epoch: 71 [100/1000 (10%)]\tLoss: 0.000476\t score_max: 5.405468\t score_min: -52.667900; Accuracy 0.994\n",
      "Train Epoch: 71 [150/1000 (15%)]\tLoss: 0.000377\t score_max: 5.405697\t score_min: -48.981586; Accuracy 0.993\n",
      "Train Epoch: 71 [200/1000 (20%)]\tLoss: 0.000345\t score_max: 5.405944\t score_min: -52.389526; Accuracy 0.995\n",
      "Train Epoch: 71 [250/1000 (25%)]\tLoss: 0.000577\t score_max: 5.406126\t score_min: -45.272781; Accuracy 0.993\n",
      "Train Epoch: 71 [300/1000 (30%)]\tLoss: 0.000395\t score_max: 5.406379\t score_min: -57.742725; Accuracy 0.996\n",
      "Train Epoch: 71 [350/1000 (35%)]\tLoss: 0.000257\t score_max: 5.406618\t score_min: -48.994286; Accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [400/1000 (40%)]\tLoss: 0.000354\t score_max: 5.406861\t score_min: -54.354919; Accuracy 0.995\n",
      "Train Epoch: 71 [450/1000 (45%)]\tLoss: 0.000238\t score_max: 5.407186\t score_min: -47.517380; Accuracy 0.994\n",
      "Train Epoch: 71 [500/1000 (50%)]\tLoss: 0.000341\t score_max: 5.407551\t score_min: -56.396217; Accuracy 0.995\n",
      "Train Epoch: 71 [550/1000 (55%)]\tLoss: 0.000155\t score_max: 5.407826\t score_min: -47.333210; Accuracy 0.994\n",
      "Train Epoch: 71 [600/1000 (60%)]\tLoss: 0.000450\t score_max: 5.408087\t score_min: -51.225266; Accuracy 0.995\n",
      "Train Epoch: 71 [650/1000 (65%)]\tLoss: 0.000639\t score_max: 5.408190\t score_min: -41.185913; Accuracy 0.992\n",
      "Train Epoch: 71 [700/1000 (70%)]\tLoss: 0.000540\t score_max: 5.408283\t score_min: -47.407146; Accuracy 0.993\n",
      "Train Epoch: 71 [750/1000 (75%)]\tLoss: 0.000247\t score_max: 5.408437\t score_min: -50.500538; Accuracy 0.994\n",
      "Train Epoch: 71 [800/1000 (80%)]\tLoss: 0.000148\t score_max: 5.408600\t score_min: -61.381111; Accuracy 0.998\n",
      "Train Epoch: 71 [850/1000 (85%)]\tLoss: 0.000138\t score_max: 5.408782\t score_min: -53.406353; Accuracy 0.994\n",
      "Train Epoch: 71 [900/1000 (90%)]\tLoss: 0.000271\t score_max: 5.408990\t score_min: -57.858479; Accuracy 0.996\n",
      "Train Epoch: 71 [950/1000 (95%)]\tLoss: 0.000279\t score_max: 5.409169\t score_min: -55.530525; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003398927699890919 ACCURACY: 0.9943349748849869\n",
      "Epoch:  72\n",
      "Train Epoch: 72 [0/1000 (0%)]\tLoss: 0.000100\t score_max: 5.409414\t score_min: -56.464615; Accuracy 0.995\n",
      "Train Epoch: 72 [50/1000 (5%)]\tLoss: 0.000337\t score_max: 5.409663\t score_min: -51.064045; Accuracy 0.994\n",
      "Train Epoch: 72 [100/1000 (10%)]\tLoss: 0.000292\t score_max: 5.409852\t score_min: -56.032360; Accuracy 0.995\n",
      "Train Epoch: 72 [150/1000 (15%)]\tLoss: 0.000216\t score_max: 5.410089\t score_min: -53.871361; Accuracy 0.996\n",
      "Train Epoch: 72 [200/1000 (20%)]\tLoss: 0.000301\t score_max: 5.410362\t score_min: -54.197491; Accuracy 0.995\n",
      "Train Epoch: 72 [250/1000 (25%)]\tLoss: 0.000317\t score_max: 5.410568\t score_min: -47.068569; Accuracy 0.994\n",
      "Train Epoch: 72 [300/1000 (30%)]\tLoss: 0.000326\t score_max: 5.410781\t score_min: -50.400085; Accuracy 0.995\n",
      "Train Epoch: 72 [350/1000 (35%)]\tLoss: 0.000368\t score_max: 5.410949\t score_min: -46.764618; Accuracy 0.993\n",
      "Train Epoch: 72 [400/1000 (40%)]\tLoss: 0.000307\t score_max: 5.411075\t score_min: -53.554253; Accuracy 0.994\n",
      "Train Epoch: 72 [450/1000 (45%)]\tLoss: 0.000793\t score_max: 5.411152\t score_min: -48.307800; Accuracy 0.993\n",
      "Train Epoch: 72 [500/1000 (50%)]\tLoss: 0.000602\t score_max: 5.411463\t score_min: -53.131924; Accuracy 0.994\n",
      "Train Epoch: 72 [550/1000 (55%)]\tLoss: 0.000554\t score_max: 5.411743\t score_min: -45.642330; Accuracy 0.992\n",
      "Train Epoch: 72 [600/1000 (60%)]\tLoss: 0.000568\t score_max: 5.412157\t score_min: -55.543919; Accuracy 0.995\n",
      "Train Epoch: 72 [650/1000 (65%)]\tLoss: 0.000515\t score_max: 5.412481\t score_min: -53.690193; Accuracy 0.995\n",
      "Train Epoch: 72 [700/1000 (70%)]\tLoss: 0.000549\t score_max: 5.412750\t score_min: -45.894295; Accuracy 0.994\n",
      "Train Epoch: 72 [750/1000 (75%)]\tLoss: 0.000387\t score_max: 5.412902\t score_min: -57.151382; Accuracy 0.996\n",
      "Train Epoch: 72 [800/1000 (80%)]\tLoss: 0.000239\t score_max: 5.413133\t score_min: -55.253529; Accuracy 0.996\n",
      "Train Epoch: 72 [850/1000 (85%)]\tLoss: 0.000198\t score_max: 5.413277\t score_min: -52.268135; Accuracy 0.995\n",
      "Train Epoch: 72 [900/1000 (90%)]\tLoss: 0.000260\t score_max: 5.413417\t score_min: -58.725933; Accuracy 0.997\n",
      "Train Epoch: 72 [950/1000 (95%)]\tLoss: 0.000331\t score_max: 5.413588\t score_min: -55.135323; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.00037803751147293954 ACCURACY: 0.994812473654747\n",
      "Epoch:  73\n",
      "Train Epoch: 73 [0/1000 (0%)]\tLoss: 0.000318\t score_max: 5.413784\t score_min: -53.152370; Accuracy 0.995\n",
      "Train Epoch: 73 [50/1000 (5%)]\tLoss: 0.000437\t score_max: 5.414093\t score_min: -55.111729; Accuracy 0.994\n",
      "Train Epoch: 73 [100/1000 (10%)]\tLoss: 0.000217\t score_max: 5.414537\t score_min: -50.456177; Accuracy 0.994\n",
      "Train Epoch: 73 [150/1000 (15%)]\tLoss: 0.000361\t score_max: 5.414983\t score_min: -57.455315; Accuracy 0.996\n",
      "Train Epoch: 73 [200/1000 (20%)]\tLoss: 0.000212\t score_max: 5.415482\t score_min: -56.513783; Accuracy 0.997\n",
      "Train Epoch: 73 [250/1000 (25%)]\tLoss: 0.000362\t score_max: 5.415931\t score_min: -60.206039; Accuracy 0.996\n",
      "Train Epoch: 73 [300/1000 (30%)]\tLoss: 0.000485\t score_max: 5.416194\t score_min: -51.312725; Accuracy 0.995\n",
      "Train Epoch: 73 [350/1000 (35%)]\tLoss: 0.000294\t score_max: 5.416315\t score_min: -56.603691; Accuracy 0.996\n",
      "Train Epoch: 73 [400/1000 (40%)]\tLoss: 0.000192\t score_max: 5.416455\t score_min: -58.365520; Accuracy 0.997\n",
      "Train Epoch: 73 [450/1000 (45%)]\tLoss: 0.000135\t score_max: 5.416611\t score_min: -57.763168; Accuracy 0.996\n",
      "Train Epoch: 73 [500/1000 (50%)]\tLoss: 0.000243\t score_max: 5.416739\t score_min: -54.072090; Accuracy 0.995\n",
      "Train Epoch: 73 [550/1000 (55%)]\tLoss: 0.001249\t score_max: 5.416904\t score_min: -40.975838; Accuracy 0.991\n",
      "Train Epoch: 73 [600/1000 (60%)]\tLoss: 0.000312\t score_max: 5.417454\t score_min: -51.230717; Accuracy 0.994\n",
      "Train Epoch: 73 [650/1000 (65%)]\tLoss: 0.001412\t score_max: 5.417934\t score_min: -41.028660; Accuracy 0.991\n",
      "Train Epoch: 73 [700/1000 (70%)]\tLoss: 0.001047\t score_max: 5.418731\t score_min: -45.679871; Accuracy 0.994\n",
      "Train Epoch: 73 [750/1000 (75%)]\tLoss: 0.000719\t score_max: 5.419280\t score_min: -45.916260; Accuracy 0.995\n",
      "Train Epoch: 73 [800/1000 (80%)]\tLoss: 0.000219\t score_max: 5.419631\t score_min: -64.745132; Accuracy 0.998\n",
      "Train Epoch: 73 [850/1000 (85%)]\tLoss: 0.000294\t score_max: 5.419895\t score_min: -61.484196; Accuracy 0.998\n",
      "Train Epoch: 73 [900/1000 (90%)]\tLoss: 0.000457\t score_max: 5.420048\t score_min: -51.362900; Accuracy 0.994\n",
      "Train Epoch: 73 [950/1000 (95%)]\tLoss: 0.000094\t score_max: 5.420074\t score_min: -57.072674; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.00045287516368262 ACCURACY: 0.994959968328476\n",
      "Epoch:  74\n",
      "Train Epoch: 74 [0/1000 (0%)]\tLoss: 0.000347\t score_max: 5.420099\t score_min: -55.750893; Accuracy 0.996\n",
      "Train Epoch: 74 [50/1000 (5%)]\tLoss: 0.000583\t score_max: 5.420174\t score_min: -46.559311; Accuracy 0.993\n",
      "Train Epoch: 74 [100/1000 (10%)]\tLoss: 0.000205\t score_max: 5.420326\t score_min: -53.752087; Accuracy 0.995\n",
      "Train Epoch: 74 [150/1000 (15%)]\tLoss: 0.000240\t score_max: 5.420482\t score_min: -58.953182; Accuracy 0.996\n",
      "Train Epoch: 74 [200/1000 (20%)]\tLoss: 0.000170\t score_max: 5.420692\t score_min: -54.098793; Accuracy 0.995\n",
      "Train Epoch: 74 [250/1000 (25%)]\tLoss: 0.000328\t score_max: 5.420943\t score_min: -52.637005; Accuracy 0.995\n",
      "Train Epoch: 74 [300/1000 (30%)]\tLoss: 0.000390\t score_max: 5.421272\t score_min: -56.836876; Accuracy 0.998\n",
      "Train Epoch: 74 [350/1000 (35%)]\tLoss: 0.000360\t score_max: 5.421511\t score_min: -53.187397; Accuracy 0.996\n",
      "Train Epoch: 74 [400/1000 (40%)]\tLoss: 0.000482\t score_max: 5.421688\t score_min: -50.457760; Accuracy 0.995\n",
      "Train Epoch: 74 [450/1000 (45%)]\tLoss: 0.000242\t score_max: 5.421716\t score_min: -53.812756; Accuracy 0.994\n",
      "Train Epoch: 74 [500/1000 (50%)]\tLoss: 0.000111\t score_max: 5.421770\t score_min: -54.606468; Accuracy 0.994\n",
      "Train Epoch: 74 [550/1000 (55%)]\tLoss: 0.000095\t score_max: 5.421845\t score_min: -56.959972; Accuracy 0.996\n",
      "Train Epoch: 74 [600/1000 (60%)]\tLoss: 0.000162\t score_max: 5.421938\t score_min: -55.936432; Accuracy 0.996\n",
      "Train Epoch: 74 [650/1000 (65%)]\tLoss: 0.000207\t score_max: 5.422086\t score_min: -49.553555; Accuracy 0.995\n",
      "Train Epoch: 74 [700/1000 (70%)]\tLoss: 0.000445\t score_max: 5.422274\t score_min: -58.044720; Accuracy 0.996\n",
      "Train Epoch: 74 [750/1000 (75%)]\tLoss: 0.000277\t score_max: 5.422619\t score_min: -59.877621; Accuracy 0.996\n",
      "Train Epoch: 74 [800/1000 (80%)]\tLoss: 0.000552\t score_max: 5.423039\t score_min: -53.294548; Accuracy 0.996\n",
      "Train Epoch: 74 [850/1000 (85%)]\tLoss: 0.000242\t score_max: 5.423526\t score_min: -56.028954; Accuracy 0.995\n",
      "Train Epoch: 74 [900/1000 (90%)]\tLoss: 0.000491\t score_max: 5.424043\t score_min: -55.059135; Accuracy 0.996\n",
      "Train Epoch: 74 [950/1000 (95%)]\tLoss: 0.000189\t score_max: 5.424662\t score_min: -56.401787; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003059101363760419 ACCURACY: 0.9954074770212173\n",
      "Epoch:  75\n",
      "Train Epoch: 75 [0/1000 (0%)]\tLoss: 0.000831\t score_max: 5.425196\t score_min: -47.083344; Accuracy 0.995\n",
      "Train Epoch: 75 [50/1000 (5%)]\tLoss: 0.000638\t score_max: 5.425487\t score_min: -52.313927; Accuracy 0.995\n",
      "Train Epoch: 75 [100/1000 (10%)]\tLoss: 0.000284\t score_max: 5.425600\t score_min: -58.514027; Accuracy 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [150/1000 (15%)]\tLoss: 0.000489\t score_max: 5.425667\t score_min: -48.680641; Accuracy 0.995\n",
      "Train Epoch: 75 [200/1000 (20%)]\tLoss: 0.000363\t score_max: 5.425709\t score_min: -62.883549; Accuracy 0.996\n",
      "Train Epoch: 75 [250/1000 (25%)]\tLoss: 0.000118\t score_max: 5.425728\t score_min: -62.756866; Accuracy 0.997\n",
      "Train Epoch: 75 [300/1000 (30%)]\tLoss: 0.000405\t score_max: 5.425727\t score_min: -54.967888; Accuracy 0.996\n",
      "Train Epoch: 75 [350/1000 (35%)]\tLoss: 0.000370\t score_max: 5.425650\t score_min: -49.771255; Accuracy 0.994\n",
      "Train Epoch: 75 [400/1000 (40%)]\tLoss: 0.000229\t score_max: 5.425471\t score_min: -41.405594; Accuracy 0.995\n",
      "Train Epoch: 75 [450/1000 (45%)]\tLoss: 0.000325\t score_max: 5.425270\t score_min: -56.383335; Accuracy 0.996\n",
      "Train Epoch: 75 [500/1000 (50%)]\tLoss: 0.000339\t score_max: 5.425145\t score_min: -50.363873; Accuracy 0.993\n",
      "Train Epoch: 75 [550/1000 (55%)]\tLoss: 0.000636\t score_max: 5.425146\t score_min: -46.603168; Accuracy 0.995\n",
      "Train Epoch: 75 [600/1000 (60%)]\tLoss: 0.000298\t score_max: 5.425042\t score_min: -48.526730; Accuracy 0.994\n",
      "Train Epoch: 75 [650/1000 (65%)]\tLoss: 0.000748\t score_max: 5.425020\t score_min: -48.073204; Accuracy 0.993\n",
      "Train Epoch: 75 [700/1000 (70%)]\tLoss: 0.000482\t score_max: 5.425004\t score_min: -55.229275; Accuracy 0.996\n",
      "Train Epoch: 75 [750/1000 (75%)]\tLoss: 0.001256\t score_max: 5.425086\t score_min: -45.522743; Accuracy 0.991\n",
      "Train Epoch: 75 [800/1000 (80%)]\tLoss: 0.000135\t score_max: 5.425551\t score_min: -50.935699; Accuracy 0.995\n",
      "Train Epoch: 75 [850/1000 (85%)]\tLoss: 0.000339\t score_max: 5.426019\t score_min: -47.621101; Accuracy 0.995\n",
      "Train Epoch: 75 [900/1000 (90%)]\tLoss: 0.000245\t score_max: 5.426369\t score_min: -56.480709; Accuracy 0.997\n",
      "Train Epoch: 75 [950/1000 (95%)]\tLoss: 0.000090\t score_max: 5.426753\t score_min: -52.381580; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0004309653275413439 ACCURACY: 0.9950999766588211\n",
      "Epoch:  76\n",
      "Train Epoch: 76 [0/1000 (0%)]\tLoss: 0.000191\t score_max: 5.427125\t score_min: -54.829662; Accuracy 0.995\n",
      "Train Epoch: 76 [50/1000 (5%)]\tLoss: 0.000236\t score_max: 5.427457\t score_min: -56.017303; Accuracy 0.997\n",
      "Train Epoch: 76 [100/1000 (10%)]\tLoss: 0.000243\t score_max: 5.427702\t score_min: -51.091599; Accuracy 0.996\n",
      "Train Epoch: 76 [150/1000 (15%)]\tLoss: 0.000301\t score_max: 5.427932\t score_min: -49.614861; Accuracy 0.994\n",
      "Train Epoch: 76 [200/1000 (20%)]\tLoss: 0.000323\t score_max: 5.428093\t score_min: -53.773075; Accuracy 0.995\n",
      "Train Epoch: 76 [250/1000 (25%)]\tLoss: 0.000200\t score_max: 5.428205\t score_min: -54.831528; Accuracy 0.996\n",
      "Train Epoch: 76 [300/1000 (30%)]\tLoss: 0.000314\t score_max: 5.428322\t score_min: -53.119904; Accuracy 0.995\n",
      "Train Epoch: 76 [350/1000 (35%)]\tLoss: 0.000100\t score_max: 5.428371\t score_min: -56.716904; Accuracy 0.997\n",
      "Train Epoch: 76 [400/1000 (40%)]\tLoss: 0.000542\t score_max: 5.428425\t score_min: -52.212112; Accuracy 0.997\n",
      "Train Epoch: 76 [450/1000 (45%)]\tLoss: 0.000198\t score_max: 5.428504\t score_min: -52.982597; Accuracy 0.993\n",
      "Train Epoch: 76 [500/1000 (50%)]\tLoss: 0.000273\t score_max: 5.428627\t score_min: -48.586056; Accuracy 0.994\n",
      "Train Epoch: 76 [550/1000 (55%)]\tLoss: 0.000224\t score_max: 5.428741\t score_min: -51.276398; Accuracy 0.994\n",
      "Train Epoch: 76 [600/1000 (60%)]\tLoss: 0.000724\t score_max: 5.428844\t score_min: -49.976013; Accuracy 0.994\n",
      "Train Epoch: 76 [650/1000 (65%)]\tLoss: 0.000221\t score_max: 5.428836\t score_min: -61.276608; Accuracy 0.997\n",
      "Train Epoch: 76 [700/1000 (70%)]\tLoss: 0.000351\t score_max: 5.428931\t score_min: -42.906200; Accuracy 0.993\n",
      "Train Epoch: 76 [750/1000 (75%)]\tLoss: 0.000427\t score_max: 5.429150\t score_min: -48.184814; Accuracy 0.995\n",
      "Train Epoch: 76 [800/1000 (80%)]\tLoss: 0.000853\t score_max: 5.429400\t score_min: -46.552128; Accuracy 0.993\n",
      "Train Epoch: 76 [850/1000 (85%)]\tLoss: 0.000987\t score_max: 5.429671\t score_min: -43.900352; Accuracy 0.993\n",
      "Train Epoch: 76 [900/1000 (90%)]\tLoss: 0.000160\t score_max: 5.429883\t score_min: -59.935368; Accuracy 0.996\n",
      "Train Epoch: 76 [950/1000 (95%)]\tLoss: 0.000596\t score_max: 5.430139\t score_min: -47.550316; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00037326515739550815 ACCURACY: 0.9949449747800827\n",
      "Epoch:  77\n",
      "Train Epoch: 77 [0/1000 (0%)]\tLoss: 0.000236\t score_max: 5.430204\t score_min: -50.251503; Accuracy 0.994\n",
      "Train Epoch: 77 [50/1000 (5%)]\tLoss: 0.000564\t score_max: 5.430286\t score_min: -54.437775; Accuracy 0.995\n",
      "Train Epoch: 77 [100/1000 (10%)]\tLoss: 0.000210\t score_max: 5.430530\t score_min: -44.198490; Accuracy 0.995\n",
      "Train Epoch: 77 [150/1000 (15%)]\tLoss: 0.000502\t score_max: 5.430737\t score_min: -49.014668; Accuracy 0.994\n",
      "Train Epoch: 77 [200/1000 (20%)]\tLoss: 0.000292\t score_max: 5.430987\t score_min: -56.047192; Accuracy 0.996\n",
      "Train Epoch: 77 [250/1000 (25%)]\tLoss: 0.000344\t score_max: 5.431218\t score_min: -46.621151; Accuracy 0.994\n",
      "Train Epoch: 77 [300/1000 (30%)]\tLoss: 0.000328\t score_max: 5.431491\t score_min: -52.607983; Accuracy 0.993\n",
      "Train Epoch: 77 [350/1000 (35%)]\tLoss: 0.000291\t score_max: 5.431730\t score_min: -57.434204; Accuracy 0.997\n",
      "Train Epoch: 77 [400/1000 (40%)]\tLoss: 0.000282\t score_max: 5.431830\t score_min: -45.371128; Accuracy 0.993\n",
      "Train Epoch: 77 [450/1000 (45%)]\tLoss: 0.000261\t score_max: 5.431909\t score_min: -43.343025; Accuracy 0.994\n",
      "Train Epoch: 77 [500/1000 (50%)]\tLoss: 0.000218\t score_max: 5.432021\t score_min: -48.441933; Accuracy 0.994\n",
      "Train Epoch: 77 [550/1000 (55%)]\tLoss: 0.000424\t score_max: 5.432106\t score_min: -47.775391; Accuracy 0.994\n",
      "Train Epoch: 77 [600/1000 (60%)]\tLoss: 0.000132\t score_max: 5.432211\t score_min: -60.086266; Accuracy 0.997\n",
      "Train Epoch: 77 [650/1000 (65%)]\tLoss: 0.000804\t score_max: 5.432380\t score_min: -47.028233; Accuracy 0.991\n",
      "Train Epoch: 77 [700/1000 (70%)]\tLoss: 0.000284\t score_max: 5.432776\t score_min: -58.734917; Accuracy 0.994\n",
      "Train Epoch: 77 [750/1000 (75%)]\tLoss: 0.000430\t score_max: 5.433206\t score_min: -47.388168; Accuracy 0.993\n",
      "Train Epoch: 77 [800/1000 (80%)]\tLoss: 0.000194\t score_max: 5.433609\t score_min: -51.119850; Accuracy 0.995\n",
      "Train Epoch: 77 [850/1000 (85%)]\tLoss: 0.000289\t score_max: 5.434021\t score_min: -45.023975; Accuracy 0.993\n",
      "Train Epoch: 77 [900/1000 (90%)]\tLoss: 0.000310\t score_max: 5.434353\t score_min: -53.649879; Accuracy 0.995\n",
      "Train Epoch: 77 [950/1000 (95%)]\tLoss: 0.000146\t score_max: 5.434568\t score_min: -55.885147; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.00032698453578632324 ACCURACY: 0.9943349748849869\n",
      "Epoch:  78\n",
      "Train Epoch: 78 [0/1000 (0%)]\tLoss: 0.000370\t score_max: 5.434780\t score_min: -56.036381; Accuracy 0.997\n",
      "Train Epoch: 78 [50/1000 (5%)]\tLoss: 0.000194\t score_max: 5.435007\t score_min: -62.712402; Accuracy 0.998\n",
      "Train Epoch: 78 [100/1000 (10%)]\tLoss: 0.000456\t score_max: 5.435203\t score_min: -47.349361; Accuracy 0.994\n",
      "Train Epoch: 78 [150/1000 (15%)]\tLoss: 0.000599\t score_max: 5.435467\t score_min: -47.490540; Accuracy 0.991\n",
      "Train Epoch: 78 [200/1000 (20%)]\tLoss: 0.000432\t score_max: 5.435892\t score_min: -46.475956; Accuracy 0.993\n",
      "Train Epoch: 78 [250/1000 (25%)]\tLoss: 0.000339\t score_max: 5.436170\t score_min: -56.524662; Accuracy 0.995\n",
      "Train Epoch: 78 [300/1000 (30%)]\tLoss: 0.000430\t score_max: 5.436513\t score_min: -46.353142; Accuracy 0.995\n",
      "Train Epoch: 78 [350/1000 (35%)]\tLoss: 0.000486\t score_max: 5.436672\t score_min: -49.256069; Accuracy 0.994\n",
      "Train Epoch: 78 [400/1000 (40%)]\tLoss: 0.000642\t score_max: 5.436768\t score_min: -47.954605; Accuracy 0.995\n",
      "Train Epoch: 78 [450/1000 (45%)]\tLoss: 0.000456\t score_max: 5.436623\t score_min: -51.272923; Accuracy 0.993\n",
      "Train Epoch: 78 [500/1000 (50%)]\tLoss: 0.000556\t score_max: 5.436592\t score_min: -44.590935; Accuracy 0.993\n",
      "Train Epoch: 78 [550/1000 (55%)]\tLoss: 0.000460\t score_max: 5.436642\t score_min: -47.387047; Accuracy 0.995\n",
      "Train Epoch: 78 [600/1000 (60%)]\tLoss: 0.000178\t score_max: 5.436553\t score_min: -59.870468; Accuracy 0.997\n",
      "Train Epoch: 78 [650/1000 (65%)]\tLoss: 0.000297\t score_max: 5.436521\t score_min: -45.183441; Accuracy 0.994\n",
      "Train Epoch: 78 [700/1000 (70%)]\tLoss: 0.000412\t score_max: 5.436579\t score_min: -42.821613; Accuracy 0.994\n",
      "Train Epoch: 78 [750/1000 (75%)]\tLoss: 0.000328\t score_max: 5.436707\t score_min: -57.942093; Accuracy 0.995\n",
      "Train Epoch: 78 [800/1000 (80%)]\tLoss: 0.000725\t score_max: 5.436965\t score_min: -50.618874; Accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 78 [850/1000 (85%)]\tLoss: 0.000515\t score_max: 5.437237\t score_min: -41.465591; Accuracy 0.992\n",
      "Train Epoch: 78 [900/1000 (90%)]\tLoss: 0.000214\t score_max: 5.437572\t score_min: -45.917000; Accuracy 0.993\n",
      "Train Epoch: 78 [950/1000 (95%)]\tLoss: 0.000179\t score_max: 5.437863\t score_min: -49.826099; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.00041339690797030925 ACCURACY: 0.9944374740123749\n",
      "Epoch:  79\n",
      "Train Epoch: 79 [0/1000 (0%)]\tLoss: 0.000423\t score_max: 5.438154\t score_min: -50.060638; Accuracy 0.994\n",
      "Train Epoch: 79 [50/1000 (5%)]\tLoss: 0.000420\t score_max: 5.438342\t score_min: -47.036633; Accuracy 0.995\n",
      "Train Epoch: 79 [100/1000 (10%)]\tLoss: 0.000251\t score_max: 5.438539\t score_min: -50.735344; Accuracy 0.993\n",
      "Train Epoch: 79 [150/1000 (15%)]\tLoss: 0.000529\t score_max: 5.438820\t score_min: -52.852631; Accuracy 0.994\n",
      "Train Epoch: 79 [200/1000 (20%)]\tLoss: 0.000318\t score_max: 5.439105\t score_min: -48.798634; Accuracy 0.994\n",
      "Train Epoch: 79 [250/1000 (25%)]\tLoss: 0.000262\t score_max: 5.439391\t score_min: -53.748760; Accuracy 0.995\n",
      "Train Epoch: 79 [300/1000 (30%)]\tLoss: 0.000294\t score_max: 5.439657\t score_min: -51.416843; Accuracy 0.995\n",
      "Train Epoch: 79 [350/1000 (35%)]\tLoss: 0.000537\t score_max: 5.439818\t score_min: -52.875103; Accuracy 0.994\n",
      "Train Epoch: 79 [400/1000 (40%)]\tLoss: 0.000241\t score_max: 5.440028\t score_min: -50.180843; Accuracy 0.994\n",
      "Train Epoch: 79 [450/1000 (45%)]\tLoss: 0.000168\t score_max: 5.440197\t score_min: -57.150700; Accuracy 0.996\n",
      "Train Epoch: 79 [500/1000 (50%)]\tLoss: 0.000121\t score_max: 5.440350\t score_min: -52.933823; Accuracy 0.994\n",
      "Train Epoch: 79 [550/1000 (55%)]\tLoss: 0.000183\t score_max: 5.440494\t score_min: -56.343994; Accuracy 0.996\n",
      "Train Epoch: 79 [600/1000 (60%)]\tLoss: 0.000135\t score_max: 5.440610\t score_min: -59.104305; Accuracy 0.995\n",
      "Train Epoch: 79 [650/1000 (65%)]\tLoss: 0.000282\t score_max: 5.440718\t score_min: -47.067673; Accuracy 0.994\n",
      "Train Epoch: 79 [700/1000 (70%)]\tLoss: 0.000458\t score_max: 5.440805\t score_min: -46.946434; Accuracy 0.994\n",
      "Train Epoch: 79 [750/1000 (75%)]\tLoss: 0.000416\t score_max: 5.440951\t score_min: -49.377758; Accuracy 0.993\n",
      "Train Epoch: 79 [800/1000 (80%)]\tLoss: 0.000618\t score_max: 5.441176\t score_min: -47.623592; Accuracy 0.993\n",
      "Train Epoch: 79 [850/1000 (85%)]\tLoss: 0.001184\t score_max: 5.441386\t score_min: -47.764412; Accuracy 0.996\n",
      "Train Epoch: 79 [900/1000 (90%)]\tLoss: 0.000902\t score_max: 5.441867\t score_min: -53.329414; Accuracy 0.993\n",
      "Train Epoch: 79 [950/1000 (95%)]\tLoss: 0.000315\t score_max: 5.442600\t score_min: -47.845085; Accuracy 0.993\n",
      "---EPOCH AVG TRAIN LOSS: 0.00040274964667332826 ACCURACY: 0.9943199783563614\n",
      "Epoch:  80\n",
      "Train Epoch: 80 [0/1000 (0%)]\tLoss: 0.000574\t score_max: 5.443349\t score_min: -43.821575; Accuracy 0.993\n",
      "Train Epoch: 80 [50/1000 (5%)]\tLoss: 0.000267\t score_max: 5.443865\t score_min: -50.534492; Accuracy 0.993\n",
      "Train Epoch: 80 [100/1000 (10%)]\tLoss: 0.000315\t score_max: 5.444268\t score_min: -50.622730; Accuracy 0.994\n",
      "Train Epoch: 80 [150/1000 (15%)]\tLoss: 0.000559\t score_max: 5.444543\t score_min: -54.783829; Accuracy 0.995\n",
      "Train Epoch: 80 [200/1000 (20%)]\tLoss: 0.000229\t score_max: 5.444634\t score_min: -52.513683; Accuracy 0.994\n",
      "Train Epoch: 80 [250/1000 (25%)]\tLoss: 0.000643\t score_max: 5.444663\t score_min: -47.908234; Accuracy 0.994\n",
      "Train Epoch: 80 [300/1000 (30%)]\tLoss: 0.000182\t score_max: 5.444544\t score_min: -59.111019; Accuracy 0.996\n",
      "Train Epoch: 80 [350/1000 (35%)]\tLoss: 0.000197\t score_max: 5.444408\t score_min: -55.917065; Accuracy 0.995\n",
      "Train Epoch: 80 [400/1000 (40%)]\tLoss: 0.000308\t score_max: 5.444383\t score_min: -55.544216; Accuracy 0.996\n",
      "Train Epoch: 80 [450/1000 (45%)]\tLoss: 0.000258\t score_max: 5.444302\t score_min: -50.201473; Accuracy 0.994\n",
      "Train Epoch: 80 [500/1000 (50%)]\tLoss: 0.000120\t score_max: 5.444281\t score_min: -61.285957; Accuracy 0.998\n",
      "Train Epoch: 80 [550/1000 (55%)]\tLoss: 0.000349\t score_max: 5.444282\t score_min: -49.335827; Accuracy 0.994\n",
      "Train Epoch: 80 [600/1000 (60%)]\tLoss: 0.000554\t score_max: 5.444396\t score_min: -54.343937; Accuracy 0.996\n",
      "Train Epoch: 80 [650/1000 (65%)]\tLoss: 0.000519\t score_max: 5.444683\t score_min: -52.261799; Accuracy 0.995\n",
      "Train Epoch: 80 [700/1000 (70%)]\tLoss: 0.000347\t score_max: 5.444920\t score_min: -55.409416; Accuracy 0.995\n",
      "Train Epoch: 80 [750/1000 (75%)]\tLoss: 0.000315\t score_max: 5.445292\t score_min: -54.440937; Accuracy 0.994\n",
      "Train Epoch: 80 [800/1000 (80%)]\tLoss: 0.000320\t score_max: 5.445561\t score_min: -59.060322; Accuracy 0.996\n",
      "Train Epoch: 80 [850/1000 (85%)]\tLoss: 0.000221\t score_max: 5.445940\t score_min: -53.689331; Accuracy 0.995\n",
      "Train Epoch: 80 [900/1000 (90%)]\tLoss: 0.000273\t score_max: 5.446308\t score_min: -53.035007; Accuracy 0.994\n",
      "Train Epoch: 80 [950/1000 (95%)]\tLoss: 0.000204\t score_max: 5.446681\t score_min: -53.953491; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.000337734349159291 ACCURACY: 0.9948674738407135\n",
      "Epoch:  81\n",
      "Train Epoch: 81 [0/1000 (0%)]\tLoss: 0.000157\t score_max: 5.446979\t score_min: -60.614361; Accuracy 0.997\n",
      "Train Epoch: 81 [50/1000 (5%)]\tLoss: 0.000473\t score_max: 5.447259\t score_min: -57.652237; Accuracy 0.995\n",
      "Train Epoch: 81 [100/1000 (10%)]\tLoss: 0.000315\t score_max: 5.447553\t score_min: -45.823513; Accuracy 0.994\n",
      "Train Epoch: 81 [150/1000 (15%)]\tLoss: 0.000295\t score_max: 5.447754\t score_min: -56.596157; Accuracy 0.995\n",
      "Train Epoch: 81 [200/1000 (20%)]\tLoss: 0.000505\t score_max: 5.447886\t score_min: -48.466995; Accuracy 0.993\n",
      "Train Epoch: 81 [250/1000 (25%)]\tLoss: 0.000331\t score_max: 5.448042\t score_min: -61.719017; Accuracy 0.996\n",
      "Train Epoch: 81 [300/1000 (30%)]\tLoss: 0.000903\t score_max: 5.448083\t score_min: -51.206924; Accuracy 0.997\n",
      "Train Epoch: 81 [350/1000 (35%)]\tLoss: 0.000223\t score_max: 5.447919\t score_min: -49.220314; Accuracy 0.992\n",
      "Train Epoch: 81 [400/1000 (40%)]\tLoss: 0.000236\t score_max: 5.447839\t score_min: -50.052540; Accuracy 0.994\n",
      "Train Epoch: 81 [450/1000 (45%)]\tLoss: 0.000109\t score_max: 5.447832\t score_min: -61.550507; Accuracy 0.996\n",
      "Train Epoch: 81 [500/1000 (50%)]\tLoss: 0.000703\t score_max: 5.447814\t score_min: -55.899235; Accuracy 0.996\n",
      "Train Epoch: 81 [550/1000 (55%)]\tLoss: 0.000280\t score_max: 5.447904\t score_min: -54.824539; Accuracy 0.995\n",
      "Train Epoch: 81 [600/1000 (60%)]\tLoss: 0.000435\t score_max: 5.448069\t score_min: -45.607071; Accuracy 0.993\n",
      "Train Epoch: 81 [650/1000 (65%)]\tLoss: 0.000253\t score_max: 5.448229\t score_min: -62.505489; Accuracy 0.997\n",
      "Train Epoch: 81 [700/1000 (70%)]\tLoss: 0.000239\t score_max: 5.448411\t score_min: -64.875107; Accuracy 0.996\n",
      "Train Epoch: 81 [750/1000 (75%)]\tLoss: 0.000240\t score_max: 5.448682\t score_min: -54.087254; Accuracy 0.995\n",
      "Train Epoch: 81 [800/1000 (80%)]\tLoss: 0.001397\t score_max: 5.448942\t score_min: -56.305023; Accuracy 0.992\n",
      "Train Epoch: 81 [850/1000 (85%)]\tLoss: 0.000310\t score_max: 5.449594\t score_min: -54.530540; Accuracy 0.995\n",
      "Train Epoch: 81 [900/1000 (90%)]\tLoss: 0.000175\t score_max: 5.450265\t score_min: -55.503117; Accuracy 0.996\n",
      "Train Epoch: 81 [950/1000 (95%)]\tLoss: 0.000381\t score_max: 5.450909\t score_min: -54.756466; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003979923167207744 ACCURACY: 0.9949224770069123\n",
      "Epoch:  82\n",
      "Train Epoch: 82 [0/1000 (0%)]\tLoss: 0.000265\t score_max: 5.451412\t score_min: -57.305763; Accuracy 0.995\n",
      "Train Epoch: 82 [50/1000 (5%)]\tLoss: 0.000595\t score_max: 5.451818\t score_min: -57.072285; Accuracy 0.996\n",
      "Train Epoch: 82 [100/1000 (10%)]\tLoss: 0.000406\t score_max: 5.451976\t score_min: -62.962620; Accuracy 0.996\n",
      "Train Epoch: 82 [150/1000 (15%)]\tLoss: 0.000531\t score_max: 5.452020\t score_min: -52.008121; Accuracy 0.994\n",
      "Train Epoch: 82 [200/1000 (20%)]\tLoss: 0.000639\t score_max: 5.451937\t score_min: -47.840355; Accuracy 0.993\n",
      "Train Epoch: 82 [250/1000 (25%)]\tLoss: 0.000170\t score_max: 5.451756\t score_min: -47.949318; Accuracy 0.994\n",
      "Train Epoch: 82 [300/1000 (30%)]\tLoss: 0.000347\t score_max: 5.451581\t score_min: -55.044796; Accuracy 0.996\n",
      "Train Epoch: 82 [350/1000 (35%)]\tLoss: 0.000227\t score_max: 5.451416\t score_min: -49.260830; Accuracy 0.993\n",
      "Train Epoch: 82 [400/1000 (40%)]\tLoss: 0.000136\t score_max: 5.451310\t score_min: -62.629326; Accuracy 0.997\n",
      "Train Epoch: 82 [450/1000 (45%)]\tLoss: 0.000290\t score_max: 5.451196\t score_min: -52.070244; Accuracy 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 82 [500/1000 (50%)]\tLoss: 0.000377\t score_max: 5.451046\t score_min: -56.782993; Accuracy 0.995\n",
      "Train Epoch: 82 [550/1000 (55%)]\tLoss: 0.000239\t score_max: 5.450942\t score_min: -54.124733; Accuracy 0.995\n",
      "Train Epoch: 82 [600/1000 (60%)]\tLoss: 0.000282\t score_max: 5.450964\t score_min: -52.384727; Accuracy 0.994\n",
      "Train Epoch: 82 [650/1000 (65%)]\tLoss: 0.000621\t score_max: 5.451042\t score_min: -51.074394; Accuracy 0.994\n",
      "Train Epoch: 82 [700/1000 (70%)]\tLoss: 0.000539\t score_max: 5.451327\t score_min: -57.399055; Accuracy 0.996\n",
      "Train Epoch: 82 [750/1000 (75%)]\tLoss: 0.000291\t score_max: 5.451721\t score_min: -50.079124; Accuracy 0.995\n",
      "Train Epoch: 82 [800/1000 (80%)]\tLoss: 0.000403\t score_max: 5.452129\t score_min: -48.500954; Accuracy 0.993\n",
      "Train Epoch: 82 [850/1000 (85%)]\tLoss: 0.000394\t score_max: 5.452609\t score_min: -60.174442; Accuracy 0.996\n",
      "Train Epoch: 82 [900/1000 (90%)]\tLoss: 0.000240\t score_max: 5.453119\t score_min: -57.491291; Accuracy 0.997\n",
      "Train Epoch: 82 [950/1000 (95%)]\tLoss: 0.000272\t score_max: 5.453659\t score_min: -53.362625; Accuracy 0.994\n",
      "---EPOCH AVG TRAIN LOSS: 0.000363130235200515 ACCURACY: 0.9949474781751633\n",
      "Epoch:  83\n",
      "Train Epoch: 83 [0/1000 (0%)]\tLoss: 0.000190\t score_max: 5.454186\t score_min: -60.788681; Accuracy 0.997\n",
      "Train Epoch: 83 [50/1000 (5%)]\tLoss: 0.000121\t score_max: 5.454588\t score_min: -57.130825; Accuracy 0.996\n",
      "Train Epoch: 83 [100/1000 (10%)]\tLoss: 0.000668\t score_max: 5.454967\t score_min: -58.035652; Accuracy 0.996\n",
      "Train Epoch: 83 [150/1000 (15%)]\tLoss: 0.000242\t score_max: 5.455150\t score_min: -54.645836; Accuracy 0.995\n",
      "Train Epoch: 83 [200/1000 (20%)]\tLoss: 0.000486\t score_max: 5.455328\t score_min: -54.430470; Accuracy 0.994\n",
      "Train Epoch: 83 [250/1000 (25%)]\tLoss: 0.000357\t score_max: 5.455398\t score_min: -58.761063; Accuracy 0.996\n",
      "Train Epoch: 83 [300/1000 (30%)]\tLoss: 0.000256\t score_max: 5.455410\t score_min: -54.251720; Accuracy 0.997\n",
      "Train Epoch: 83 [350/1000 (35%)]\tLoss: 0.000396\t score_max: 5.455423\t score_min: -56.622620; Accuracy 0.996\n",
      "Train Epoch: 83 [400/1000 (40%)]\tLoss: 0.000191\t score_max: 5.455544\t score_min: -52.127258; Accuracy 0.995\n",
      "Train Epoch: 83 [450/1000 (45%)]\tLoss: 0.000316\t score_max: 5.455606\t score_min: -55.116070; Accuracy 0.994\n",
      "Train Epoch: 83 [500/1000 (50%)]\tLoss: 0.000148\t score_max: 5.455749\t score_min: -62.498680; Accuracy 0.998\n",
      "Train Epoch: 83 [550/1000 (55%)]\tLoss: 0.000471\t score_max: 5.455853\t score_min: -51.576141; Accuracy 0.992\n",
      "Train Epoch: 83 [600/1000 (60%)]\tLoss: 0.000128\t score_max: 5.456044\t score_min: -59.167919; Accuracy 0.997\n",
      "Train Epoch: 83 [650/1000 (65%)]\tLoss: 0.000410\t score_max: 5.456217\t score_min: -51.551437; Accuracy 0.995\n",
      "Train Epoch: 83 [700/1000 (70%)]\tLoss: 0.000306\t score_max: 5.456306\t score_min: -49.274284; Accuracy 0.991\n",
      "Train Epoch: 83 [750/1000 (75%)]\tLoss: 0.000440\t score_max: 5.456452\t score_min: -48.341354; Accuracy 0.992\n",
      "Train Epoch: 83 [800/1000 (80%)]\tLoss: 0.000292\t score_max: 5.456775\t score_min: -52.265152; Accuracy 0.995\n",
      "Train Epoch: 83 [850/1000 (85%)]\tLoss: 0.000288\t score_max: 5.457006\t score_min: -52.547791; Accuracy 0.994\n",
      "Train Epoch: 83 [900/1000 (90%)]\tLoss: 0.000357\t score_max: 5.457249\t score_min: -49.351082; Accuracy 0.994\n",
      "Train Epoch: 83 [950/1000 (95%)]\tLoss: 0.000409\t score_max: 5.457399\t score_min: -47.711525; Accuracy 0.993\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003234716081351507 ACCURACY: 0.9948999732732773\n",
      "Epoch:  84\n",
      "Train Epoch: 84 [0/1000 (0%)]\tLoss: 0.000344\t score_max: 5.457566\t score_min: -48.395351; Accuracy 0.995\n",
      "Train Epoch: 84 [50/1000 (5%)]\tLoss: 0.000307\t score_max: 5.457706\t score_min: -48.820610; Accuracy 0.994\n",
      "Train Epoch: 84 [100/1000 (10%)]\tLoss: 0.000144\t score_max: 5.457834\t score_min: -59.265038; Accuracy 0.996\n",
      "Train Epoch: 84 [150/1000 (15%)]\tLoss: 0.000251\t score_max: 5.457965\t score_min: -55.386456; Accuracy 0.995\n",
      "Train Epoch: 84 [200/1000 (20%)]\tLoss: 0.000599\t score_max: 5.458124\t score_min: -48.662682; Accuracy 0.992\n",
      "Train Epoch: 84 [250/1000 (25%)]\tLoss: 0.000298\t score_max: 5.458458\t score_min: -48.140736; Accuracy 0.994\n",
      "Train Epoch: 84 [300/1000 (30%)]\tLoss: 0.000401\t score_max: 5.458826\t score_min: -49.240303; Accuracy 0.994\n",
      "Train Epoch: 84 [350/1000 (35%)]\tLoss: 0.000281\t score_max: 5.459256\t score_min: -55.760471; Accuracy 0.995\n",
      "Train Epoch: 84 [400/1000 (40%)]\tLoss: 0.000275\t score_max: 5.459678\t score_min: -60.407646; Accuracy 0.997\n",
      "Train Epoch: 84 [450/1000 (45%)]\tLoss: 0.000370\t score_max: 5.460005\t score_min: -50.513634; Accuracy 0.994\n",
      "Train Epoch: 84 [500/1000 (50%)]\tLoss: 0.000432\t score_max: 5.460222\t score_min: -54.749557; Accuracy 0.994\n",
      "Train Epoch: 84 [550/1000 (55%)]\tLoss: 0.000331\t score_max: 5.460418\t score_min: -55.021355; Accuracy 0.995\n",
      "Train Epoch: 84 [600/1000 (60%)]\tLoss: 0.000399\t score_max: 5.460563\t score_min: -49.016438; Accuracy 0.996\n",
      "Train Epoch: 84 [650/1000 (65%)]\tLoss: 0.000534\t score_max: 5.460685\t score_min: -57.000187; Accuracy 0.996\n",
      "Train Epoch: 84 [700/1000 (70%)]\tLoss: 0.000323\t score_max: 5.460680\t score_min: -53.603592; Accuracy 0.995\n",
      "Train Epoch: 84 [750/1000 (75%)]\tLoss: 0.000473\t score_max: 5.460732\t score_min: -49.368038; Accuracy 0.991\n",
      "Train Epoch: 84 [800/1000 (80%)]\tLoss: 0.000492\t score_max: 5.460980\t score_min: -48.714088; Accuracy 0.993\n",
      "Train Epoch: 84 [850/1000 (85%)]\tLoss: 0.000250\t score_max: 5.461315\t score_min: -56.010803; Accuracy 0.996\n",
      "Train Epoch: 84 [900/1000 (90%)]\tLoss: 0.000324\t score_max: 5.461555\t score_min: -54.171349; Accuracy 0.995\n",
      "Train Epoch: 84 [950/1000 (95%)]\tLoss: 0.000350\t score_max: 5.461677\t score_min: -58.177525; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003588609608414117 ACCURACY: 0.994637468457222\n",
      "Epoch:  85\n",
      "Train Epoch: 85 [0/1000 (0%)]\tLoss: 0.000285\t score_max: 5.461743\t score_min: -58.143353; Accuracy 0.996\n",
      "Train Epoch: 85 [50/1000 (5%)]\tLoss: 0.000284\t score_max: 5.461789\t score_min: -52.202480; Accuracy 0.995\n",
      "Train Epoch: 85 [100/1000 (10%)]\tLoss: 0.000220\t score_max: 5.461848\t score_min: -57.292381; Accuracy 0.996\n",
      "Train Epoch: 85 [150/1000 (15%)]\tLoss: 0.000183\t score_max: 5.461948\t score_min: -55.258564; Accuracy 0.996\n",
      "Train Epoch: 85 [200/1000 (20%)]\tLoss: 0.000315\t score_max: 5.462113\t score_min: -52.213840; Accuracy 0.994\n",
      "Train Epoch: 85 [250/1000 (25%)]\tLoss: 0.000467\t score_max: 5.462305\t score_min: -49.896156; Accuracy 0.994\n",
      "Train Epoch: 85 [300/1000 (30%)]\tLoss: 0.000348\t score_max: 5.462532\t score_min: -52.264671; Accuracy 0.995\n",
      "Train Epoch: 85 [350/1000 (35%)]\tLoss: 0.000484\t score_max: 5.462758\t score_min: -55.612431; Accuracy 0.996\n",
      "Train Epoch: 85 [400/1000 (40%)]\tLoss: 0.000308\t score_max: 5.462929\t score_min: -59.256859; Accuracy 0.995\n",
      "Train Epoch: 85 [450/1000 (45%)]\tLoss: 0.000139\t score_max: 5.463199\t score_min: -57.713516; Accuracy 0.997\n",
      "Train Epoch: 85 [500/1000 (50%)]\tLoss: 0.000515\t score_max: 5.463479\t score_min: -53.665318; Accuracy 0.993\n",
      "Train Epoch: 85 [550/1000 (55%)]\tLoss: 0.000204\t score_max: 5.463853\t score_min: -48.896866; Accuracy 0.995\n",
      "Train Epoch: 85 [600/1000 (60%)]\tLoss: 0.000434\t score_max: 5.464164\t score_min: -49.256836; Accuracy 0.992\n",
      "Train Epoch: 85 [650/1000 (65%)]\tLoss: 0.000315\t score_max: 5.464586\t score_min: -51.502338; Accuracy 0.994\n",
      "Train Epoch: 85 [700/1000 (70%)]\tLoss: 0.000317\t score_max: 5.464928\t score_min: -54.739170; Accuracy 0.994\n",
      "Train Epoch: 85 [750/1000 (75%)]\tLoss: 0.000389\t score_max: 5.465256\t score_min: -53.436268; Accuracy 0.995\n",
      "Train Epoch: 85 [800/1000 (80%)]\tLoss: 0.000409\t score_max: 5.465420\t score_min: -51.458801; Accuracy 0.994\n",
      "Train Epoch: 85 [850/1000 (85%)]\tLoss: 0.000293\t score_max: 5.465545\t score_min: -51.956276; Accuracy 0.995\n",
      "Train Epoch: 85 [900/1000 (90%)]\tLoss: 0.000261\t score_max: 5.465601\t score_min: -48.845428; Accuracy 0.993\n",
      "Train Epoch: 85 [950/1000 (95%)]\tLoss: 0.000709\t score_max: 5.465707\t score_min: -51.577030; Accuracy 0.996\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003439901462115813 ACCURACY: 0.9946949779987335\n",
      "Epoch:  86\n",
      "Train Epoch: 86 [0/1000 (0%)]\tLoss: 0.000268\t score_max: 5.465815\t score_min: -56.186653; Accuracy 0.995\n",
      "Train Epoch: 86 [50/1000 (5%)]\tLoss: 0.000380\t score_max: 5.465922\t score_min: -60.012127; Accuracy 0.996\n",
      "Train Epoch: 86 [100/1000 (10%)]\tLoss: 0.000156\t score_max: 5.466046\t score_min: -50.124329; Accuracy 0.993\n",
      "Train Epoch: 86 [150/1000 (15%)]\tLoss: 0.000345\t score_max: 5.466150\t score_min: -57.637066; Accuracy 0.995\n",
      "Train Epoch: 86 [200/1000 (20%)]\tLoss: 0.000323\t score_max: 5.466355\t score_min: -48.847195; Accuracy 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86 [250/1000 (25%)]\tLoss: 0.000338\t score_max: 5.466693\t score_min: -48.952900; Accuracy 0.992\n",
      "Train Epoch: 86 [300/1000 (30%)]\tLoss: 0.000089\t score_max: 5.467077\t score_min: -59.098732; Accuracy 0.996\n",
      "Train Epoch: 86 [350/1000 (35%)]\tLoss: 0.000339\t score_max: 5.467448\t score_min: -51.641621; Accuracy 0.994\n",
      "Train Epoch: 86 [400/1000 (40%)]\tLoss: 0.000337\t score_max: 5.467763\t score_min: -56.839542; Accuracy 0.996\n",
      "Train Epoch: 86 [450/1000 (45%)]\tLoss: 0.000224\t score_max: 5.468020\t score_min: -62.429806; Accuracy 0.997\n",
      "Train Epoch: 86 [500/1000 (50%)]\tLoss: 0.000120\t score_max: 5.468286\t score_min: -58.709084; Accuracy 0.994\n",
      "Train Epoch: 86 [550/1000 (55%)]\tLoss: 0.000192\t score_max: 5.468589\t score_min: -52.137829; Accuracy 0.994\n",
      "Train Epoch: 86 [600/1000 (60%)]\tLoss: 0.000280\t score_max: 5.468832\t score_min: -61.133644; Accuracy 0.996\n",
      "Train Epoch: 86 [650/1000 (65%)]\tLoss: 0.000111\t score_max: 5.468939\t score_min: -57.048927; Accuracy 0.996\n",
      "Train Epoch: 86 [700/1000 (70%)]\tLoss: 0.000477\t score_max: 5.469025\t score_min: -55.560371; Accuracy 0.995\n",
      "Train Epoch: 86 [750/1000 (75%)]\tLoss: 0.000179\t score_max: 5.469011\t score_min: -57.634140; Accuracy 0.995\n",
      "Train Epoch: 86 [800/1000 (80%)]\tLoss: 0.000556\t score_max: 5.469066\t score_min: -53.325829; Accuracy 0.995\n",
      "Train Epoch: 86 [850/1000 (85%)]\tLoss: 0.000352\t score_max: 5.469213\t score_min: -47.650223; Accuracy 0.995\n",
      "Train Epoch: 86 [900/1000 (90%)]\tLoss: 0.000726\t score_max: 5.469484\t score_min: -47.769039; Accuracy 0.991\n",
      "Train Epoch: 86 [950/1000 (95%)]\tLoss: 0.000387\t score_max: 5.469911\t score_min: -52.327015; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003089590889430838 ACCURACY: 0.9947274714708328\n",
      "Epoch:  87\n",
      "Train Epoch: 87 [0/1000 (0%)]\tLoss: 0.000539\t score_max: 5.470289\t score_min: -48.375908; Accuracy 0.993\n",
      "Train Epoch: 87 [50/1000 (5%)]\tLoss: 0.000343\t score_max: 5.470726\t score_min: -52.994427; Accuracy 0.996\n",
      "Train Epoch: 87 [100/1000 (10%)]\tLoss: 0.000248\t score_max: 5.471153\t score_min: -56.912525; Accuracy 0.996\n",
      "Train Epoch: 87 [150/1000 (15%)]\tLoss: 0.000275\t score_max: 5.471621\t score_min: -52.311852; Accuracy 0.995\n",
      "Train Epoch: 87 [200/1000 (20%)]\tLoss: 0.000328\t score_max: 5.472001\t score_min: -52.324970; Accuracy 0.995\n",
      "Train Epoch: 87 [250/1000 (25%)]\tLoss: 0.000221\t score_max: 5.472258\t score_min: -47.142464; Accuracy 0.995\n",
      "Train Epoch: 87 [300/1000 (30%)]\tLoss: 0.000170\t score_max: 5.472463\t score_min: -55.000546; Accuracy 0.994\n",
      "Train Epoch: 87 [350/1000 (35%)]\tLoss: 0.000387\t score_max: 5.472708\t score_min: -51.603653; Accuracy 0.994\n",
      "Train Epoch: 87 [400/1000 (40%)]\tLoss: 0.000267\t score_max: 5.472909\t score_min: -50.439354; Accuracy 0.993\n",
      "Train Epoch: 87 [450/1000 (45%)]\tLoss: 0.000796\t score_max: 5.473067\t score_min: -44.089558; Accuracy 0.995\n",
      "Train Epoch: 87 [500/1000 (50%)]\tLoss: 0.000215\t score_max: 5.473311\t score_min: -49.587799; Accuracy 0.994\n",
      "Train Epoch: 87 [550/1000 (55%)]\tLoss: 0.000524\t score_max: 5.473486\t score_min: -52.714981; Accuracy 0.993\n",
      "Train Epoch: 87 [600/1000 (60%)]\tLoss: 0.000285\t score_max: 5.473724\t score_min: -60.858864; Accuracy 0.996\n",
      "Train Epoch: 87 [650/1000 (65%)]\tLoss: 0.000987\t score_max: 5.473961\t score_min: -49.510735; Accuracy 0.995\n",
      "Train Epoch: 87 [700/1000 (70%)]\tLoss: 0.000210\t score_max: 5.473883\t score_min: -58.723793; Accuracy 0.996\n",
      "Train Epoch: 87 [750/1000 (75%)]\tLoss: 0.000145\t score_max: 5.473913\t score_min: -61.055145; Accuracy 0.998\n",
      "Train Epoch: 87 [800/1000 (80%)]\tLoss: 0.000215\t score_max: 5.474006\t score_min: -57.932735; Accuracy 0.996\n",
      "Train Epoch: 87 [850/1000 (85%)]\tLoss: 0.000250\t score_max: 5.474201\t score_min: -57.104549; Accuracy 0.995\n",
      "Train Epoch: 87 [900/1000 (90%)]\tLoss: 0.000503\t score_max: 5.474420\t score_min: -49.366615; Accuracy 0.994\n",
      "Train Epoch: 87 [950/1000 (95%)]\tLoss: 0.000196\t score_max: 5.474519\t score_min: -54.146919; Accuracy 0.995\n",
      "---EPOCH AVG TRAIN LOSS: 0.000355189941910794 ACCURACY: 0.9949949711561203\n",
      "Epoch:  88\n",
      "Train Epoch: 88 [0/1000 (0%)]\tLoss: 0.000116\t score_max: 5.474672\t score_min: -62.701538; Accuracy 0.997\n",
      "Train Epoch: 88 [50/1000 (5%)]\tLoss: 0.000733\t score_max: 5.474856\t score_min: -47.296532; Accuracy 0.993\n",
      "Train Epoch: 88 [100/1000 (10%)]\tLoss: 0.000564\t score_max: 5.475071\t score_min: -51.067230; Accuracy 0.993\n",
      "Train Epoch: 88 [150/1000 (15%)]\tLoss: 0.000367\t score_max: 5.475367\t score_min: -46.821304; Accuracy 0.992\n",
      "Train Epoch: 88 [200/1000 (20%)]\tLoss: 0.000316\t score_max: 5.475816\t score_min: -54.733067; Accuracy 0.996\n",
      "Train Epoch: 88 [250/1000 (25%)]\tLoss: 0.000414\t score_max: 5.476310\t score_min: -53.158875; Accuracy 0.994\n",
      "Train Epoch: 88 [300/1000 (30%)]\tLoss: 0.000296\t score_max: 5.476801\t score_min: -59.431591; Accuracy 0.995\n",
      "Train Epoch: 88 [350/1000 (35%)]\tLoss: 0.000172\t score_max: 5.477262\t score_min: -57.041664; Accuracy 0.995\n",
      "Train Epoch: 88 [400/1000 (40%)]\tLoss: 0.000239\t score_max: 5.477619\t score_min: -55.162464; Accuracy 0.994\n",
      "Train Epoch: 88 [450/1000 (45%)]\tLoss: 0.000199\t score_max: 5.477982\t score_min: -56.054649; Accuracy 0.995\n",
      "Train Epoch: 88 [500/1000 (50%)]\tLoss: 0.000695\t score_max: 5.478250\t score_min: -40.167702; Accuracy 0.994\n",
      "Train Epoch: 88 [550/1000 (55%)]\tLoss: 0.000460\t score_max: 5.478320\t score_min: -45.115047; Accuracy 0.995\n",
      "Train Epoch: 88 [600/1000 (60%)]\tLoss: 0.000485\t score_max: 5.478217\t score_min: -51.893417; Accuracy 0.994\n",
      "Train Epoch: 88 [650/1000 (65%)]\tLoss: 0.000397\t score_max: 5.477987\t score_min: -55.469650; Accuracy 0.996\n",
      "Train Epoch: 88 [700/1000 (70%)]\tLoss: 0.000197\t score_max: 5.477691\t score_min: -54.639286; Accuracy 0.994\n",
      "Train Epoch: 88 [750/1000 (75%)]\tLoss: 0.000187\t score_max: 5.477472\t score_min: -55.210808; Accuracy 0.996\n",
      "Train Epoch: 88 [800/1000 (80%)]\tLoss: 0.000374\t score_max: 5.477291\t score_min: -51.986485; Accuracy 0.993\n",
      "Train Epoch: 88 [850/1000 (85%)]\tLoss: 0.000407\t score_max: 5.477256\t score_min: -63.297249; Accuracy 0.996\n",
      "Train Epoch: 88 [900/1000 (90%)]\tLoss: 0.000149\t score_max: 5.477293\t score_min: -56.637840; Accuracy 0.994\n",
      "Train Epoch: 88 [950/1000 (95%)]\tLoss: 0.000384\t score_max: 5.477361\t score_min: -57.522358; Accuracy 0.997\n",
      "---EPOCH AVG TRAIN LOSS: 0.0003576260736736003 ACCURACY: 0.9946324825286865\n",
      "Epoch:  89\n",
      "Train Epoch: 89 [0/1000 (0%)]\tLoss: 0.000532\t score_max: 5.477553\t score_min: -50.340351; Accuracy 0.995\n",
      "Train Epoch: 89 [50/1000 (5%)]\tLoss: 0.000127\t score_max: 5.477935\t score_min: -56.409142; Accuracy 0.994\n",
      "Train Epoch: 89 [100/1000 (10%)]\tLoss: 0.000249\t score_max: 5.478255\t score_min: -54.520157; Accuracy 0.996\n",
      "Train Epoch: 89 [150/1000 (15%)]\tLoss: 0.000420\t score_max: 5.478500\t score_min: -50.620346; Accuracy 0.994\n",
      "Train Epoch: 89 [200/1000 (20%)]\tLoss: 0.000524\t score_max: 5.478792\t score_min: -59.459633; Accuracy 0.993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28701/3943547089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/local/jerenner/emsim/training.py\u001b[0m in \u001b[0;36mtrain_unet\u001b[0;34m(model, epoch, train_loader, optimizer)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mmaxvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/torch/optim/rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    114\u001b[0m                       \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                       \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                       centered=group['centered'])\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36mrmsprop\u001b[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, lr, alpha, eps, weight_decay, momentum, centered)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the training.\n",
    "for epoch in range(epoch_start,epoch_end):\n",
    "    print(\"Epoch: \",epoch)\n",
    "    model.train()\n",
    "    tr.train_unet(model, epoch, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"{}/model_frames_20x20_noise683_2e_bcsloss_front_100kev_{}.pt\".format(modeldir,epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset for events from 0 to 198917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "dset = tr.EMDataset(\"dataframes/EM_5um_front_3M_100keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=False,add_shift=0)\n",
    "#dataset_train   = tr.EMFrameDataset(dset,frame_size=50,nelec_mean=11,nelec_sigma=0.5,noise_mean=683,noise_sigma=11.2)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done\n",
      "1% done\n",
      "2% done\n",
      "3% done\n",
      "4% done\n",
      "5% done\n",
      "6% done\n",
      "7% done\n",
      "8% done\n",
      "9% done\n",
      "10% done\n",
      "11% done\n",
      "12% done\n",
      "13% done\n",
      "14% done\n",
      "15% done\n",
      "16% done\n",
      "17% done\n",
      "18% done\n",
      "19% done\n",
      "20% done\n",
      "21% done\n",
      "22% done\n",
      "23% done\n",
      "24% done\n",
      "25% done\n",
      "26% done\n",
      "27% done\n",
      "28% done\n",
      "29% done\n",
      "30% done\n",
      "31% done\n",
      "32% done\n",
      "33% done\n",
      "34% done\n",
      "35% done\n",
      "36% done\n",
      "37% done\n",
      "38% done\n",
      "39% done\n",
      "40% done\n",
      "41% done\n",
      "42% done\n",
      "43% done\n",
      "44% done\n",
      "45% done\n",
      "46% done\n",
      "47% done\n",
      "48% done\n",
      "49% done\n",
      "50% done\n",
      "51% done\n",
      "52% done\n",
      "53% done\n",
      "54% done\n",
      "55% done\n",
      "56% done\n",
      "57% done\n",
      "58% done\n",
      "59% done\n",
      "60% done\n",
      "61% done\n",
      "62% done\n",
      "63% done\n",
      "64% done\n",
      "65% done\n",
      "66% done\n",
      "67% done\n",
      "68% done\n",
      "69% done\n",
      "70% done\n",
      "71% done\n",
      "72% done\n",
      "73% done\n",
      "74% done\n",
      "75% done\n",
      "76% done\n",
      "77% done\n",
      "78% done\n",
      "79% done\n",
      "80% done\n",
      "81% done\n",
      "82% done\n",
      "83% done\n",
      "84% done\n",
      "85% done\n",
      "86% done\n",
      "87% done\n",
      "88% done\n",
      "89% done\n",
      "90% done\n",
      "91% done\n",
      "92% done\n",
      "93% done\n",
      "94% done\n",
      "95% done\n",
      "96% done\n",
      "97% done\n",
      "98% done\n",
      "99% done\n"
     ]
    }
   ],
   "source": [
    "# Loop over many events and evaluate the true positives and false positives.\n",
    "# Store in arrays as:\n",
    "#\n",
    "#  [tp0 tp1 tp2 tp3 ... tpN], each number corresponding to a different NN threshold or classical threshold\n",
    "#\n",
    "tp_unet = []; fp_unet = []\n",
    "tp_classical = []; fp_classical = []\n",
    "#nn_thresholds = np.arange(0.05,1.0,0.1)\n",
    "nn_thresholds = np.logspace(-0.5,-0.001,1000)\n",
    "classical_thresholds = np.arange(600,7000,10)\n",
    "evts = np.arange(100000,101000)\n",
    "for evt in evts:\n",
    "    \n",
    "    # Get the event and truth.\n",
    "    evt_item = dataset_train[evt]\n",
    "    evt_arr = evt_item[0]\n",
    "    evt_lbl = evt_item[1][0]\n",
    "    \n",
    "    # Send through the model.\n",
    "    data = torch.tensor(evt_arr).float().unsqueeze(0).unsqueeze(1).cuda()\n",
    "    output_score = model(data)\n",
    "    \n",
    "    # Compute the predicted pixel values.\n",
    "    prob = np.array(sigmoid(output_score).cpu().detach().numpy()).squeeze()\n",
    "    \n",
    "    # Compute the TP and FP values for unet.\n",
    "    temp_tp = []; temp_fp = []\n",
    "    for th in nn_thresholds:\n",
    "        pred = (prob > th)\n",
    "        tp = np.sum((evt_lbl == 1) & (pred == True))\n",
    "        fn = np.sum((evt_lbl == 1) & (pred == False))\n",
    "        if( (tp + fn) > 0): tp = tp / (tp + fn)\n",
    "        else: tp = 1\n",
    "        fp = np.sum((evt_lbl == 0) & (pred == True))\n",
    "        tn = np.sum((evt_lbl == 0) & (pred == False))\n",
    "        if( (fp + tn) > 0): fp = fp / (fp + tn)\n",
    "        else: fp = 0\n",
    "        temp_tp.append(tp)\n",
    "        temp_fp.append(fp)\n",
    "    tp_unet.append(temp_tp)\n",
    "    fp_unet.append(temp_fp)\n",
    "    \n",
    "    # Compute the TP and FP values for the classical threshold.\n",
    "    temp_tp = []; temp_fp = []\n",
    "    for th in classical_thresholds:\n",
    "        pred = (evt_arr > th)\n",
    "        tp = np.sum((evt_lbl == 1) & (pred == True))\n",
    "        fn = np.sum((evt_lbl == 1) & (pred == False))\n",
    "        if( (tp + fn) > 0): tp = tp / (tp + fn)\n",
    "        else: tp = 1\n",
    "        fp = np.sum((evt_lbl == 0) & (pred == True))\n",
    "        tn = np.sum((evt_lbl == 0) & (pred == False))\n",
    "        if( (tp + tn) > 0): fp = fp / (fp + tn)\n",
    "        else: tp = 0\n",
    "        temp_tp.append(tp)\n",
    "        temp_fp.append(fp)\n",
    "    tp_classical.append(temp_tp)\n",
    "    fp_classical.append(temp_fp)\n",
    "    \n",
    "    if((evt-evts[0]) % (len(evts)/100) == 0):\n",
    "            print(\"{}% done\".format(int((evt-evts[0]) / (len(evts)/100))))\n",
    "    \n",
    "tp_unet = np.array(tp_unet)\n",
    "fp_unet = np.array(fp_unet)\n",
    "tp_classical = np.array(tp_classical)\n",
    "fp_classical = np.array(fp_classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True positive rate')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp_rate_unet = np.mean(tp_unet,axis=0)\n",
    "tp_err_unet = np.std(tp_unet,axis=0)/np.sqrt(tp_unet.shape[0])\n",
    "fp_rate_unet = np.mean(fp_unet,axis=0)\n",
    "fp_err_unet = np.std(fp_unet,axis=0)/np.sqrt(fp_unet.shape[0])\n",
    "tp_rate_classical = np.mean(tp_classical,axis=0)\n",
    "tp_err_classical = np.std(tp_classical,axis=0)/np.sqrt(tp_classical.shape[0])\n",
    "fp_rate_classical = np.mean(fp_classical,axis=0)\n",
    "fp_err_classical = np.std(fp_classical,axis=0)/np.sqrt(fp_classical.shape[0])\n",
    "\n",
    "plt.errorbar(fp_rate_unet,tp_rate_unet,xerr=fp_err_unet,yerr=tp_err_unet,label='Unet')\n",
    "plt.errorbar(fp_rate_classical,tp_rate_classical,xerr=fp_err_classical,yerr=tp_err_classical,label='Basic threshold')\n",
    "plt.xlim([0,0.02])\n",
    "plt.legend()\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN ------------------\n",
      "[Threshold 0.9772372209558107] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9772574929846057] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9772777654339282] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.977298038303787] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9773183115941908] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9773385853051483] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9773588594366681] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9773791339887592] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9773994089614301] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9774196843546896] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9774399601685464] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9774602364030093] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9774805130580869] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.977500790133788] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9775210676301214] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9775413455470957] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9775616238847197] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.977581902643002] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9776021818219515] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9776224614215768] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9776427414418868] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.97766302188289] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9776833027445953] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9777035840270112] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9777238657301467] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9777441478540104] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.977764430398611] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9777847133639574] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9778049967500582] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.977825280556922] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9778455647845576] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9778658494329739] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9778861345021795] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9779064199921832] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9779267059029936] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9779469922346194] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9779672789870696] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9779875661603527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9780078537544774] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9780281417694526] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978048430205287] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9780687190619892] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978089008339568] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9781092980380321] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9781295881573904] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9781498786976515] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978170169658824] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9781904610409169] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9782107528439387] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9782310450678983] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9782513377128043] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9782716307786654] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9782919242654906] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9783122181732884] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9783325125020675] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9783528072518368] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978373102422605] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9783933980143807] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9784136940271728] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9784339904609899] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9784542873158408] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9784745845917342] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978494882288679] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9785151804066836] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978535478945757] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9785557779059079] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978576077287145] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978596377089477] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9786166773129127] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9786369779574607] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9786572790231299] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.978677580509929] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9786978824178667] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9787181847469517] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9787384874971928] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9787587906685988] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9787790942611784] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9787993982749401] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9788197027098929] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9788400075660455] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9788603128434066] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9788806185419849] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9789009246617892] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9789212312028283] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9789415381651108] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9789618455486455] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9789821533534411] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9790024615795064] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9790227702268501] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.979043079295481] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9790633887854077] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.979083698696639] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9791040090291838] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9791243197830506] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9791446309582483] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9791649425547856] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9791852545726712] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9792055670119139] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9792258798725224] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9792461931545055] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9792665068578718] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9792868209826302] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9793071355287893] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9793274504963579] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9793477658853449] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9793680816957588] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9793883979276085] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9794087145809026] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.97942903165565] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9794493491518593] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9794696670695393] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9794899854086989] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9795103041693466] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9795306233514912] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9795509429551416] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9795712629803064] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9795915834269943] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9796119042952142] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9796322255849746] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9796525472962846] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9796728694291527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9796931919835876] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9797135149595982] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9797338383571933] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9797541621763814] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9797744864171715] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9797948110795721] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9798151361635922] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9798354616692403] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9798557875965253] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9798761139454558] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9798964407160408] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9799167679082889] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9799370955222088] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9799574235578092] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9799777520150992] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9799980808940871] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9800184101947819] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9800387399171923] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.980059070061327] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9800794006271947] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9800997316148043] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9801200630241645] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9801403948552841] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9801607271081717] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9801810597828362] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9802013928792862] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9802217263975306] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.980242060337578] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9802623946994372] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.980282729483117] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9803030646886262] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9803234003159734] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9803437363651675] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9803640728362172] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9803844097291311] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9804047470439182] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9804250847805871] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9804454229391466] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9804657615196054] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9804861005219723] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9805064399462561] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9805267797924654] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9805471200606091] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9805674607506959] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9805878018627345] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9806081433967337] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9806284853527024] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9806488277306491] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9806691705305827] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9806895137525119] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9807098573964455] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9807302014623922] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9807505459503607] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.98077089086036] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9807912361923986] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9808115819464853] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.980831928122629] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9808522747208384] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.980872621741122] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9808929691834889] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9809133170479477] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9809336653345072] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9809540140431762] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9809743631739632] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9809947127268773] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9810150627019271] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9810354130991213] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9810557639184688] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9810761151599782] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9810964668236584] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9811168189095181] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.981137171417566] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9811575243478108] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9811778777002615] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9811982314749267] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9812185856718152] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9812389402909356] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9812592953322969] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9812796507959078] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9813000066817771] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9813203629899133] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9813407197203254] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9813610768730221] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9813814344480122] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9814017924453043] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9814221508649074] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.98144250970683] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9814628689710811] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9814832286576693] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9815035887666035] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9815239492978923] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9815443102515446] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9815646716275691] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9815850334259746] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9816053956467697] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9816257582899635] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9816461213555643] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9816664848435812] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.981686848754023] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9817072130868982] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9817275778422158] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9817479430199844] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9817683086202128] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9817886746429099] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9818090410880843] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9818294079557448] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9818497752459002] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9818701429585592] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9818905110937307] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9819108796514234] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.981931248631646] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9819516180344073] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9819719878597161] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9819923581075811] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9820127287780112] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982033099871015] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9820534713866013] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9820738433247789] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9820942156855565] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9821145884689432] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9821349616749473] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9821553353035778] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9821757093548434] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982196083828753] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9822164587253152] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9822368340445389] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9822572097864327] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9822775859510056] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9822979625382662] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9823183395482232] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9823387169808856] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982359094836262] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9823794731143612] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9823998518151921] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9824202309387633] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9824406104850836] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9824609904541618] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9824813708460066] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9825017516606269] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9825221328980315] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9825425145582289] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9825628966412282] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9825832791470379] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982603662075667] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982624045427124] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9826444292014179] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9826648133985575] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9826851980185514] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9827055830614083] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9827259685271373] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982746354415747] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982766740727246] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9827871274616433] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9828075146189477] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9828279021991678] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9828482902023125] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9828686786283904] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9828890674774106] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9829094567493815] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.982929846444312] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9829502365622111] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9829706271030874] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9829910180669496] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9830114094538064] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9830318012636668] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9830521934965396] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9830725861524334] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9830929792313571] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9831133727333193] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.983133766658329] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9831541610063947] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9831745557775255] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.98319495097173] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.983215346589017] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9832357426293953] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9832561390928736] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9832765359794607] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9832969332891655] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9833173310219966] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9833377291779629] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9833581277570731] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.983378526759336] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9833989261847604] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9834193260333551] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9834397263051289] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9834601270000904] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9834805281182487] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9835009296596122] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.98352133162419] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9835417340119906] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9835621368230231] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.983582540057296] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9836029437148182] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9836233477955985] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9836437522996455] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9836641572269682] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9836845625775753] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9837049683514757] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9837253745486779] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9837457811691909] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9837661882130234] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9837865956801843] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9838070035706823] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.983827411884526] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9838478206217245] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9838682297822865] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9838886393662206] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9839090493735357] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9839294598042406] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.983949870658344] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9839702819358549] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9839906936367818] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9840111057611337] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9840315183089193] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9840519312801473] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9840723446748267] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9840927584929661] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9841131727345743] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9841335873996602] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9841540024882324] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9841744180002998] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9841948339358713] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9842152502949554] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9842356670775612] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9842560842836972] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9842765019133723] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9842969199665954] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9843173384433752] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9843377573437204] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9843581766676399] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9843785964151425] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9843990165862369] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9844194371809319] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9844398581992363] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.984460279641159] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9844807015067085] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9845011237958939] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9845215465087239] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9845419696452072] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9845623932053527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.984582817189169] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9846032415966651] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9846236664278497] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9846440916827315] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9846645173613195] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9846849434636223] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9847053699896489] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9847257969394078] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9847462243129079] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9847666521101581] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9847870803311672] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9848075089759438] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.984827938044497] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9848483675368351] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9848687974529674] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9848892277929024] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.984909658556649] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.984930089744216] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9849505213556121] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9849709533908462] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9849913858499268] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9850118187328633] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9850322520396638] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9850526857703376] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9850731199248932] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9850935545033396] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9851139895056854] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9851344249319396] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9851548607821108] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9851752970562079] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9851957337542396] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9852161708762148] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9852366084221422] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9852570463920308] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9852774847858892] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9852979236037261] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9853183628455506] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9853388025113713] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.985359242601197] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9853796831150365] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9854001240528987] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9854205654147922] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.985441007200726] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9854614494107088] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9854818920447493] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9855023351028566] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9855227785850391] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9855432224913059] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9855636668216656] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9855841115761271] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9856045567546993] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9856250023573908] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9856454483842105] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9856658948351672] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9856863417102697] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9857067890095267] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9857272367329472] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9857476848805398] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9857681334523133] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9857885824482767] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9858090318684386] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9858294817128078] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9858499319813934] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9858703826742038] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.985890833791248] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9859112853325348] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9859317372980729] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9859521896878712] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9859726425019385] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9859930957402836] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9860135494029153] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9860340034898424] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9860544580010736] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9860749129366178] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9860953682964838] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9861158240806803] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9861362802892163] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9861567369221005] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9861771939793417] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9861976514609486] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9862181093669301] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9862385676972951] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9862590264520523] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9862794856312105] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9862999452347785] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9863204052627651] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9863408657151791] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9863613265920294] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9863817878933248] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9864022496190739] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9864227117692856] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9864431743439689] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9864636373431324] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9864841007667849] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9865045646149353] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9865250288875924] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.986545493584765] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9865659587064618] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9865864242526917] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9866068902234636] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9866273566187861] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9866478234386681] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9866682906831185] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.986688758352146] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9867092264457593] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9867296949639676] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9867501639067792] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9867706332742032] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9867911030662485] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9868115732829237] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9868320439242376] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9868525149901992] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9868729864808171] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9868934583961003] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9869139307360575] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9869344035006975] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9869548766900291] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9869753503040612] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9869958243428026] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.987016298806262] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9870367736944483] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9870572490073702] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9870777247450367] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9870982009074565] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9871186774946384] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9871391545065913] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9871596319433239] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9871801098048449] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9872005880911635] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9872210668022882] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9872415459382279] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9872620254989913] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9872825054845874] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.987302985895025] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9873234667303127] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9873439479904595] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9873644296754742] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9873849117853656] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9874053943201424] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9874258772798136] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.987446360664388] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9874668444738741] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9874873287082812] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9875078133676177] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9875282984518927] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9875487839611148] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9875692698952929] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9875897562544359] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9876102430385526] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9876307302476517] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.987651217881742] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9876717059408324] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9876921944249318] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9877126833340489] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9877331726681925] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9877536624273715] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9877741526115946] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9877946432208708] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9878151342552087] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9878356257146174] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9878561175991054] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9878766099086816] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9878971026433551] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9879175958031343] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9879380893880283] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9879585833980459] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9879790778331957] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9879995726934868] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9880200679789278] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9880405636895276] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9880610598252951] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9880815563862391] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9881020533723683] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9881225507836916] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9881430486202178] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9881635468819558] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9881840455689144] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9882045446811022] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9882250442185283] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9882455441812014] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9882660445691304] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9882865453823239] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9883070466207909] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9883275482845404] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9883480503735809] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9883685528879214] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9883890558275705] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9884095591925374] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9884300629828306] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.988450567198459] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9884710718394316] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9884915769057571] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9885120823974441] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9885325883145019] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9885530946569389] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.988573601424764] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9885941086179862] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9886146162366143] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.988635124280657] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9886556327501231] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9886761416450216] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9886966509653613] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9887171607111508] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9887376708823992] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9887581814791151] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9887786925013075] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9887992039489851] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9888197158221569] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9888402281208315] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.988860740845018] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9888812539947248] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9889017675699612] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9889222815707358] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9889427959970574] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9889633108489349] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.988983826126377] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9890043418293928] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9890248579579909] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9890453745121801] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9890658914919694] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9890864088973675] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9891069267283834] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9891274449850257] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9891479636673033] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9891684827752251] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9891890023087999] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9892095222680365] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9892300426529438] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9892505634635306] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9892710846998056] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9892916063617778] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9893121284494559] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.989332650962849] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9893531739019655] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9893736972668147] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.989394221057405] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9894147452737455] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9894352699158451] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9894557949837123] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9894763204773562] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9894968463967856] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9895173727420092] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.989537899513036] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9895584267098747] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9895789543325342] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9895994823810234] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9896200108553509] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9896405397555258] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9896610690815568] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9896815988334527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9897021290112226] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9897226596148749] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9897431906444187] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.989763722099863] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9897842539812162] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9898047862884874] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9898253190216855] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9898458521808192] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9898663857658974] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9898869197769288] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9899074542139223] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.989927989076887] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9899485243658314] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9899690600807645] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.989989596221695] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9900101327886319] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9900306697815839] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.99005120720056] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9900717450455689] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9900922833166195] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9901128220137205] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.990133361136881] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9901539006861096] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9901744406614152] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9901949810628068] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.990215521890293] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9902360631438828] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.990256604823585] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9902771469294084] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9902976894613619] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9903182324194543] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9903387758036943] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9903593196140911] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9903798638506531] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9904004085133895] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9904209536023091] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9904414991174205] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9904620450587327] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9904825914262546] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9905031382199949] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9905236854399626] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9905442330861663] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9905647811586151] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9905853296573178] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9906058785822831] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.99062642793352] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9906469777110372] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9906675279148436] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.990688078544948] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9907086296013594] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9907291810840865] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9907497329931382] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9907702853285233] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9907908380902506] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9908113912783292] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9908319448927676] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9908524989335749] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9908730534007597] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9908936082943312] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9909141636142978] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9909347193606688] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9909552755334526] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9909758321326585] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.990996389158295] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9910169466103711] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9910375044888956] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9910580627938774] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9910786215253252] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9910991806832481] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9911197402676547] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9911403002785539] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9911608607159547] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9911814215798658] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991201982870296] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9912225445872543] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9912431067307496] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9912636693007905] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991284232297386] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991304795720545] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9913253595702761] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9913459238465885] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9913664885494908] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9913870536789919] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9914076192351008] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991428185217826] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9914487516271768] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9914693184631618] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9914898857257898] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9915104534150697] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9915310215310104] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9915515900736207] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9915721590429095] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9915927284388857] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991613298261558] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9916338685109353] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9916544391870264] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9916750102898405] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991695581819386] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.991716153775672] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9917367261587072] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9917572989685006] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9917778722050611] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9917984458683973] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9918190199585183] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9918395944754328] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9918601694191497] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9918807447896779] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9919013205870262] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9919218968112035] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9919424734622185] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9919630505400803] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9919836280447976] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9920042059763793] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9920247843348342] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9920453631201712] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9920659423323992] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.992086521971527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9921071020375635] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9921276825305174] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9921482634503977] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9921688447972133] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9921894265709731] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9922100087716856] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9922305913993601] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9922511744540052] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9922717579356298] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9922923418442428] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.992312926179853] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9923335109424692] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9923540961321005] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9923746817487555] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9923952677924432] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9924158542631725] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9924364411609521] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.992457028485791] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9924776162376979] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9924982044166818] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9925187930227516] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.992539382055916] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9925599715161839] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9925805614035642] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9926011517180658] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9926217424596976] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9926423336284682] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9926629252243868] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9926835172474621] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9927041096977028] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.992724702575118] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9927452958797165] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9927658896115071] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9927864837704988] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9928070783567003] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9928276733701206] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9928482688107684] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9928688646786527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9928894609737823] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.992910057696166] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9929306548458129] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9929512524227316] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9929718504269311] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9929924488584202] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9930130477172079] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9930336470033029] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.993054246716714] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9930748468574504] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9930954474255207] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9931160484209338] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9931366498436985] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9931572516938239] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9931778539713186] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9931984566761917] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9932190598084518] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.993239663368108] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.993260267355169] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9932808717696437] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9933014766115412] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9933220818808701] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9933426875776393] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9933632937018577] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9933839002535343] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9934045072326777] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.993425114639297] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9934457224734009] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9934663307349985] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9934869394240983] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9935075485407096] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9935281580848409] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9935487680565013] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9935693784556995] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9935899892824445] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9936106005367451] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9936312122186103] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9936518243280488] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9936724368650696] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9936930498296813] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9937136632218931] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9937342770417139] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9937548912891523] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9937755059642173] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9937961210669176] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9938167365972624] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9938373525552604] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9938579689409204] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9938785857542514] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9938992029952621] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9939198206639617] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9939404387603586] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9939610572844622] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9939816762362809] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9940022956158239] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9940229154230998] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9940435356581178] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9940641563208865] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9940847774114149] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9941053989297117] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.994126020875786] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9941466432496467] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9941672660513026] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9941878892807623] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.994208512938035] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9942291370231296] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9942497615360548] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9942703864768195] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9942910118454327] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9943116376419031] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9943322638662396] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9943528905184513] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9943735175985469] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9943941451065351] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9944147730424251] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9944354014062257] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9944560301979456] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9944766594175939] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9944972890651793] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9945179191407109] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9945385496441972] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9945591805756474] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9945798119350704] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9946004437224748] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9946210759378697] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9946417085812639] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9946623416526663] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9946829751520858] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9947036090795313] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9947242434350115] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9947448782185356] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9947655134301122] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9947861490697503] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9948067851374587] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9948274216332463] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.994848058557122] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9948686959090948] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9948893336891734] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9949099718973667] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9949306105336838] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9949512495981333] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9949718890907242] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9949925290114654] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9950131693603658] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9950338101374342] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9950544513426796] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9950750929761106] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9950957350377365] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9951163775275659] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9951370204456077] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9951576637918709] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9951783075663643] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9951989517690968] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9952195964000773] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9952402414593147] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9952608869468178] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9952815328625955] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9953021792066568] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9953228259790105] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9953434731796654] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9953641208086306] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9953847688659148] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.995405417351527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9954260662654759] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9954467156077706] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.99546736537842] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9954880155774327] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9955086662048179] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9955293172605844] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.995549968744741] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9955706206572965] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9955912729982601] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9956119257676405] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9956325789654464] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9956532325916871] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9956738866463711] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9956945411295076] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9957151960411054] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9957358513811732] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.99575650714972] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9957771633467547] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9957978199722863] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9958184770263235] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9958391345088754] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9958597924199507] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9958804507595583] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9959011095277072] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9959217687244062] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9959424283496643] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9959630884034902] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.995983748885893] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9960044097968814] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9960250711364645] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.996045732904651] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9960663951014499] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9960870577268701] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9961077207809204] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9961283842636097] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9961490481749471] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9961697125149411] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9961903772836009] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9962110424809354] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9962317081069534] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9962523741616637] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9962730406450754] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9962937075571972] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.996314374898038] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9963350426676069] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9963557108659126] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9963763794929641] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9963970485487702] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9964177180333399] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9964383879466819] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9964590582888054] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.996479729059719] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9965004002594319] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9965210718879527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9965417439452904] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9965624164314539] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9965830893464521] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9966037626902939] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9966244364629883] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.996645110664544] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9966657852949701] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9966864603542752] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9967071358424685] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9967278117595587] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9967484881055549] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9967691648804659] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9967898420843004] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9968105197170676] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9968311977787762] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9968518762694352] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9968725551890534] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9968932345376398] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9969139143152033] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9969345945217527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.996955275157297] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.996975956221845] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9969966377154057] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9970173196379879] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9970380019896006] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9970586847702527] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997079367979953] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9971000516187105] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997120735686534] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9971414201834324] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9971621051094148] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9971827904644899] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9972034762486667] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997224162461954] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9972448491043608] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997265536175896] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9972862236765684] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997306911606387] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9973275999653606] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9973482887534982] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9973689779708087] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9973896676173011] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997410357692984] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9974310481978665] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9974517391319576] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.997472430495266] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9974931222878007] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9975138145095707] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9975345071605847] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9975552002408518] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9975758937503807] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9975965876891805] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.99761728205726] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9976379768546281] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9976586720812938] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9976793677372658] TP = 0.355, FP = 0.0\n",
      "[Threshold 0.9977000638225533] TP = 0.355, FP = 0.0\n",
      "Classical threshold ------------------\n",
      "[Threshold 600] TP = 1.0, FP = 1.0\n",
      "[Threshold 610] TP = 1.0, FP = 1.0\n",
      "[Threshold 620] TP = 1.0, FP = 1.0\n",
      "[Threshold 630] TP = 1.0, FP = 1.0\n",
      "[Threshold 640] TP = 1.0, FP = 0.9999624247175727\n",
      "[Threshold 650] TP = 1.0, FP = 0.9986097720431718\n",
      "[Threshold 660] TP = 1.0, FP = 0.9813333438810568\n",
      "[Threshold 670] TP = 1.0, FP = 0.8843519107127115\n",
      "[Threshold 680] TP = 0.999, FP = 0.6237781239530985\n",
      "[Threshold 690] TP = 0.998, FP = 0.2943203435095273\n",
      "[Threshold 700] TP = 0.997, FP = 0.09237436782912058\n",
      "[Threshold 710] TP = 0.9945, FP = 0.03011403788995102\n",
      "[Threshold 720] TP = 0.993, FP = 0.01787779354164306\n",
      "[Threshold 730] TP = 0.9895, FP = 0.01428373071497842\n",
      "[Threshold 740] TP = 0.9855, FP = 0.012219279385650081\n",
      "[Threshold 750] TP = 0.9775, FP = 0.010568651528318294\n",
      "[Threshold 760] TP = 0.9705, FP = 0.00922914698807318\n",
      "[Threshold 770] TP = 0.956, FP = 0.008235746401178799\n",
      "[Threshold 780] TP = 0.9375, FP = 0.00740289165123862\n",
      "[Threshold 790] TP = 0.924, FP = 0.00671050742433972\n",
      "[Threshold 800] TP = 0.911, FP = 0.00611608795858992\n",
      "[Threshold 810] TP = 0.8885, FP = 0.005619362476543101\n",
      "[Threshold 820] TP = 0.8685, FP = 0.005232969358068521\n",
      "[Threshold 830] TP = 0.852, FP = 0.004796532789259568\n",
      "[Threshold 840] TP = 0.8315, FP = 0.004495409377715635\n",
      "[Threshold 850] TP = 0.807, FP = 0.004184279794964789\n",
      "[Threshold 860] TP = 0.782, FP = 0.003928376216924211\n",
      "[Threshold 870] TP = 0.7565, FP = 0.0036650357048399807\n",
      "[Threshold 880] TP = 0.723, FP = 0.0034091384239493113\n",
      "[Threshold 890] TP = 0.6945, FP = 0.0032260298988677637\n",
      "[Threshold 900] TP = 0.6745, FP = 0.0030203397942091346\n",
      "[Threshold 910] TP = 0.6505, FP = 0.0028422312061560893\n",
      "[Threshold 920] TP = 0.623, FP = 0.0026666414780670243\n",
      "[Threshold 930] TP = 0.604, FP = 0.002556283925895136\n",
      "[Threshold 940] TP = 0.579, FP = 0.002458470296343872\n",
      "[Threshold 950] TP = 0.565, FP = 0.002323018601780831\n",
      "[Threshold 960] TP = 0.5435, FP = 0.0022201357665520547\n",
      "[Threshold 970] TP = 0.5295, FP = 0.0020972468860593683\n",
      "[Threshold 980] TP = 0.518, FP = 0.002009426833415194\n",
      "[Threshold 990] TP = 0.5015, FP = 0.0018890190299870246\n",
      "[Threshold 1000] TP = 0.4955, FP = 0.0017961864460145302\n",
      "[Threshold 1010] TP = 0.487, FP = 0.0017334794272112406\n",
      "[Threshold 1020] TP = 0.475, FP = 0.0016632347199657402\n",
      "[Threshold 1030] TP = 0.471, FP = 0.0015854523242780296\n",
      "[Threshold 1040] TP = 0.4615, FP = 0.0014901449603909242\n",
      "[Threshold 1050] TP = 0.454, FP = 0.001412394050452763\n",
      "[Threshold 1060] TP = 0.4495, FP = 0.001357186937192225\n",
      "[Threshold 1070] TP = 0.4455, FP = 0.0013095364038236278\n",
      "[Threshold 1080] TP = 0.4415, FP = 0.0012518419163486585\n",
      "[Threshold 1090] TP = 0.4365, FP = 0.0011891097089457299\n",
      "[Threshold 1100] TP = 0.4315, FP = 0.0011464780040553633\n",
      "[Threshold 1110] TP = 0.4285, FP = 0.0010988211735368564\n",
      "[Threshold 1120] TP = 0.4265, FP = 0.001046151811690028\n",
      "[Threshold 1130] TP = 0.4205, FP = 0.0009909698870291298\n",
      "[Threshold 1140] TP = 0.418, FP = 0.0009734197302300969\n",
      "[Threshold 1150] TP = 0.4135, FP = 0.0009307754310399106\n",
      "[Threshold 1160] TP = 0.4115, FP = 0.0008881374289996342\n",
      "[Threshold 1170] TP = 0.4095, FP = 0.0008555307867659091\n",
      "[Threshold 1180] TP = 0.4085, FP = 0.0008329429100389158\n",
      "[Threshold 1190] TP = 0.4055, FP = 0.0007903049079986393\n",
      "[Threshold 1200] TP = 0.404, FP = 0.0007652170627573953\n",
      "[Threshold 1210] TP = 0.404, FP = 0.0007401355146660616\n",
      "[Threshold 1220] TP = 0.402, FP = 0.0007200602007531385\n",
      "[Threshold 1230] TP = 0.401, FP = 0.0006924723869976444\n",
      "[Threshold 1240] TP = 0.3995, FP = 0.0006824410271910928\n",
      "[Threshold 1250] TP = 0.3995, FP = 0.0006447966650294072\n",
      "[Threshold 1260] TP = 0.3985, FP = 0.0006272339139305545\n",
      "[Threshold 1270] TP = 0.3975, FP = 0.0006121837256457723\n",
      "[Threshold 1280] TP = 0.3935, FP = 0.0006046523343534714\n",
      "[Threshold 1290] TP = 0.3935, FP = 0.00059462097454692\n",
      "[Threshold 1300] TP = 0.3915, FP = 0.0005845833175904584\n",
      "[Threshold 1310] TP = 0.3905, FP = 0.0005695142378559463\n",
      "[Threshold 1320] TP = 0.3895, FP = 0.0005569766123852345\n",
      "[Threshold 1330] TP = 0.3895, FP = 0.0005369138927721313\n",
      "[Threshold 1340] TP = 0.389, FP = 0.0005193637359730984\n",
      "[Threshold 1350] TP = 0.3885, FP = 0.0004992884220601755\n",
      "[Threshold 1360] TP = 0.3865, FP = 0.00048675079658946354\n",
      "[Threshold 1370] TP = 0.3855, FP = 0.00046668807697636044\n",
      "[Threshold 1380] TP = 0.3835, FP = 0.0004541441543557385\n",
      "[Threshold 1390] TP = 0.3835, FP = 0.00044661906021334737\n",
      "[Threshold 1400] TP = 0.382, FP = 0.0004340751375927255\n",
      "[Threshold 1410] TP = 0.381, FP = 0.0004190186521580332\n",
      "[Threshold 1420] TP = 0.381, FP = 0.00040646843238750134\n",
      "[Threshold 1430] TP = 0.381, FP = 0.00038639311847457836\n",
      "[Threshold 1440] TP = 0.381, FP = 0.0003763617586680268\n",
      "[Threshold 1450] TP = 0.381, FP = 0.00037134293018979605\n",
      "[Threshold 1460] TP = 0.38, FP = 0.0003613052732333345\n",
      "[Threshold 1470] TP = 0.379, FP = 0.0003512739134267829\n",
      "[Threshold 1480] TP = 0.379, FP = 0.00034124255362023143\n",
      "[Threshold 1490] TP = 0.378, FP = 0.00034124255362023143\n",
      "[Threshold 1500] TP = 0.378, FP = 0.00032870492814951946\n",
      "[Threshold 1510] TP = 0.3775, FP = 0.0003236923968211987\n",
      "[Threshold 1520] TP = 0.3775, FP = 0.0003036107857583657\n",
      "[Threshold 1530] TP = 0.3775, FP = 0.0002985919572801349\n",
      "[Threshold 1540] TP = 0.3775, FP = 0.0002885480031737635\n",
      "[Threshold 1550] TP = 0.3775, FP = 0.00028352287754562284\n",
      "[Threshold 1560] TP = 0.3775, FP = 0.0002709789549250009\n",
      "[Threshold 1570] TP = 0.3775, FP = 0.00026094759511844935\n",
      "[Threshold 1580] TP = 0.3775, FP = 0.00024839107819800757\n",
      "[Threshold 1590] TP = 0.3775, FP = 0.0002458785153839372\n",
      "[Threshold 1600] TP = 0.3775, FP = 0.00024336595256986687\n",
      "[Threshold 1610] TP = 0.3765, FP = 0.00024085968690570647\n",
      "[Threshold 1620] TP = 0.3765, FP = 0.0002358345612775658\n",
      "[Threshold 1630] TP = 0.3765, FP = 0.00022329693580685383\n",
      "[Threshold 1640] TP = 0.3765, FP = 0.00021828440447853304\n",
      "[Threshold 1650] TP = 0.3755, FP = 0.00021075931033614188\n",
      "[Threshold 1660] TP = 0.3755, FP = 0.00020324051334366067\n",
      "[Threshold 1670] TP = 0.3755, FP = 0.00019572171635117946\n",
      "[Threshold 1680] TP = 0.3755, FP = 0.00018819032505887836\n",
      "[Threshold 1690] TP = 0.3755, FP = 0.000185677762244808\n",
      "[Threshold 1700] TP = 0.3755, FP = 0.00017815896525232678\n",
      "[Threshold 1710] TP = 0.3755, FP = 0.00017564640243825642\n",
      "[Threshold 1720] TP = 0.3755, FP = 0.00017313383962418605\n",
      "[Threshold 1730] TP = 0.3755, FP = 0.00017062757396002566\n",
      "[Threshold 1740] TP = 0.375, FP = 0.00016560874548179487\n",
      "[Threshold 1750] TP = 0.375, FP = 0.00016560874548179487\n",
      "[Threshold 1760] TP = 0.374, FP = 0.00016309618266772456\n",
      "[Threshold 1770] TP = 0.372, FP = 0.00015807105703958386\n",
      "[Threshold 1780] TP = 0.372, FP = 0.00015305852571126304\n",
      "[Threshold 1790] TP = 0.372, FP = 0.00015054596289719267\n",
      "[Threshold 1800] TP = 0.372, FP = 0.00014552713441896194\n",
      "[Threshold 1810] TP = 0.372, FP = 0.00014302086875480155\n",
      "[Threshold 1820] TP = 0.372, FP = 0.00014051460309064115\n",
      "[Threshold 1830] TP = 0.372, FP = 0.00014051460309064115\n",
      "[Threshold 1840] TP = 0.372, FP = 0.00014051460309064115\n",
      "[Threshold 1850] TP = 0.372, FP = 0.00013800833742648076\n",
      "[Threshold 1860] TP = 0.372, FP = 0.00013800833742648076\n",
      "[Threshold 1870] TP = 0.372, FP = 0.0001354957746124104\n",
      "[Threshold 1880] TP = 0.372, FP = 0.0001354957746124104\n",
      "[Threshold 1890] TP = 0.372, FP = 0.0001354957746124104\n",
      "[Threshold 1900] TP = 0.372, FP = 0.00013048324328408957\n",
      "[Threshold 1910] TP = 0.372, FP = 0.0001254581176559489\n",
      "[Threshold 1920] TP = 0.372, FP = 0.00012295185199178848\n",
      "[Threshold 1930] TP = 0.372, FP = 0.00012043928917771814\n",
      "[Threshold 1940] TP = 0.372, FP = 0.00011793302351355773\n",
      "[Threshold 1950] TP = 0.372, FP = 0.00011793302351355773\n",
      "[Threshold 1960] TP = 0.371, FP = 0.00011793302351355773\n",
      "[Threshold 1970] TP = 0.371, FP = 0.00011292049218523694\n",
      "[Threshold 1980] TP = 0.371, FP = 0.00011040792937116659\n",
      "[Threshold 1990] TP = 0.371, FP = 0.00011040792937116659\n",
      "[Threshold 2000] TP = 0.371, FP = 0.00010538280374302589\n",
      "[Threshold 2010] TP = 0.371, FP = 0.00010538280374302589\n",
      "[Threshold 2020] TP = 0.371, FP = 0.00010538280374302589\n",
      "[Threshold 2030] TP = 0.371, FP = 0.00010287653807886549\n",
      "[Threshold 2040] TP = 0.371, FP = 0.00010037027241470508\n",
      "[Threshold 2050] TP = 0.371, FP = 9.785770960063474e-05\n",
      "[Threshold 2060] TP = 0.371, FP = 9.785770960063474e-05\n",
      "[Threshold 2070] TP = 0.37, FP = 9.283888112240398e-05\n",
      "[Threshold 2080] TP = 0.37, FP = 9.283888112240398e-05\n",
      "[Threshold 2090] TP = 0.3695, FP = 9.283888112240398e-05\n",
      "[Threshold 2100] TP = 0.3695, FP = 9.032631830833362e-05\n",
      "[Threshold 2110] TP = 0.3685, FP = 8.782005264417322e-05\n",
      "[Threshold 2120] TP = 0.3685, FP = 8.782005264417322e-05\n",
      "[Threshold 2130] TP = 0.3675, FP = 8.782005264417322e-05\n",
      "[Threshold 2140] TP = 0.3675, FP = 8.782005264417322e-05\n",
      "[Threshold 2150] TP = 0.3665, FP = 8.530748983010286e-05\n",
      "[Threshold 2160] TP = 0.3665, FP = 8.530748983010286e-05\n",
      "[Threshold 2170] TP = 0.3665, FP = 8.028866135187211e-05\n",
      "[Threshold 2180] TP = 0.3655, FP = 7.778239568771172e-05\n",
      "[Threshold 2190] TP = 0.3655, FP = 7.778239568771172e-05\n",
      "[Threshold 2200] TP = 0.3655, FP = 7.527613002355132e-05\n",
      "[Threshold 2210] TP = 0.3655, FP = 7.527613002355132e-05\n",
      "[Threshold 2220] TP = 0.3655, FP = 7.276356720948096e-05\n",
      "[Threshold 2230] TP = 0.3655, FP = 7.276356720948096e-05\n",
      "[Threshold 2240] TP = 0.3655, FP = 7.276356720948096e-05\n",
      "[Threshold 2250] TP = 0.3655, FP = 7.276356720948096e-05\n",
      "[Threshold 2260] TP = 0.3655, FP = 6.775103588116015e-05\n",
      "[Threshold 2270] TP = 0.3645, FP = 6.272591025301948e-05\n",
      "[Threshold 2280] TP = 0.3645, FP = 5.520711326053827e-05\n",
      "[Threshold 2290] TP = 0.3645, FP = 5.520711326053827e-05\n",
      "[Threshold 2300] TP = 0.3645, FP = 5.520711326053827e-05\n",
      "[Threshold 2310] TP = 0.3645, FP = 5.520711326053827e-05\n",
      "[Threshold 2320] TP = 0.3635, FP = 5.270084759637787e-05\n",
      "[Threshold 2330] TP = 0.3635, FP = 5.270084759637787e-05\n",
      "[Threshold 2340] TP = 0.3635, FP = 4.518205060389668e-05\n",
      "[Threshold 2350] TP = 0.3635, FP = 4.518205060389668e-05\n",
      "[Threshold 2360] TP = 0.3635, FP = 4.518205060389668e-05\n",
      "[Threshold 2370] TP = 0.3625, FP = 4.267578493973628e-05\n",
      "[Threshold 2380] TP = 0.3625, FP = 4.0169519275575875e-05\n",
      "[Threshold 2390] TP = 0.3625, FP = 4.0169519275575875e-05\n",
      "[Threshold 2400] TP = 0.3625, FP = 4.0169519275575875e-05\n",
      "[Threshold 2410] TP = 0.3625, FP = 4.0169519275575875e-05\n",
      "[Threshold 2420] TP = 0.3625, FP = 3.7656956461505524e-05\n",
      "[Threshold 2430] TP = 0.3625, FP = 3.7656956461505524e-05\n",
      "[Threshold 2440] TP = 0.3625, FP = 3.7656956461505524e-05\n",
      "[Threshold 2450] TP = 0.3625, FP = 3.7656956461505524e-05\n",
      "[Threshold 2460] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2470] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2480] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2490] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2500] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2510] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2520] TP = 0.3625, FP = 3.514439364743517e-05\n",
      "[Threshold 2530] TP = 0.362, FP = 3.514439364743517e-05\n",
      "[Threshold 2540] TP = 0.362, FP = 3.514439364743517e-05\n",
      "[Threshold 2550] TP = 0.362, FP = 3.514439364743517e-05\n",
      "[Threshold 2560] TP = 0.362, FP = 3.514439364743517e-05\n",
      "[Threshold 2570] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2580] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2590] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2600] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2610] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2620] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2630] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2640] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2650] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2660] TP = 0.362, FP = 3.2631830833364814e-05\n",
      "[Threshold 2670] TP = 0.362, FP = 3.0119268019294466e-05\n",
      "[Threshold 2680] TP = 0.362, FP = 3.0119268019294466e-05\n",
      "[Threshold 2690] TP = 0.362, FP = 2.7606705205224114e-05\n",
      "[Threshold 2700] TP = 0.362, FP = 2.7606705205224114e-05\n",
      "[Threshold 2710] TP = 0.362, FP = 2.7606705205224114e-05\n",
      "[Threshold 2720] TP = 0.361, FP = 2.7606705205224114e-05\n",
      "[Threshold 2730] TP = 0.361, FP = 2.7606705205224114e-05\n",
      "[Threshold 2740] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2750] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2760] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2770] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2780] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2790] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2800] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2810] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2820] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2830] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2840] TP = 0.361, FP = 2.5094142391153763e-05\n",
      "[Threshold 2850] TP = 0.36, FP = 2.5094142391153763e-05\n",
      "[Threshold 2860] TP = 0.36, FP = 2.5094142391153763e-05\n",
      "[Threshold 2870] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2880] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2890] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2900] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2910] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2920] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2930] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2940] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2950] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2960] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2970] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2980] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 2990] TP = 0.36, FP = 2.258787672699336e-05\n",
      "[Threshold 3000] TP = 0.359, FP = 2.258787672699336e-05\n",
      "[Threshold 3010] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3020] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3030] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3040] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3050] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3060] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3070] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3080] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3090] TP = 0.359, FP = 2.007531391292301e-05\n",
      "[Threshold 3100] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3110] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3120] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3130] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3140] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3150] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3160] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3170] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3180] TP = 0.359, FP = 1.756275109885266e-05\n",
      "[Threshold 3190] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3200] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3210] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3220] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3230] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3240] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3250] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3260] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3270] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3280] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3290] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3300] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3310] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3320] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3330] TP = 0.359, FP = 1.505648543469226e-05\n",
      "[Threshold 3340] TP = 0.358, FP = 1.2550219770531858e-05\n",
      "[Threshold 3350] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3360] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3370] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3380] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3390] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3400] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3410] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3420] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3430] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3440] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3450] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3460] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3470] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3480] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3490] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3500] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3510] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3520] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3530] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3540] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3550] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3560] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3570] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3580] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3590] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3600] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3610] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3620] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3630] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3640] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3650] TP = 0.358, FP = 1.0043954106371456e-05\n",
      "[Threshold 3660] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3670] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3680] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3690] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3700] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3710] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3720] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3730] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3740] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3750] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3760] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3770] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3780] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3790] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3800] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3810] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3820] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3830] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3840] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3850] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3860] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3870] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3880] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3890] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3900] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3910] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3920] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3930] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3940] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3950] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3960] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3970] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3980] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 3990] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 4000] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 4010] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 4020] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 4030] TP = 0.3575, FP = 1.0043954106371456e-05\n",
      "[Threshold 4040] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4050] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4060] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4070] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4080] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4090] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4100] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4110] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4120] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4130] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4140] TP = 0.357, FP = 1.0043954106371456e-05\n",
      "[Threshold 4150] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4160] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4170] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4180] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4190] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4200] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4210] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4220] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4230] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4240] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4250] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4260] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4270] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4280] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4290] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4300] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4310] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4320] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4330] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4340] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4350] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4360] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4370] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4380] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4390] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4400] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4410] TP = 0.357, FP = 7.531391292301105e-06\n",
      "[Threshold 4420] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4430] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4440] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4450] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4460] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4470] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4480] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4490] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4500] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4510] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4520] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4530] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4540] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4550] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4560] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4570] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4580] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4590] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4600] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4610] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4620] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4630] TP = 0.3565, FP = 7.531391292301105e-06\n",
      "[Threshold 4640] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4650] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4660] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4670] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4680] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4690] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4700] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4710] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4720] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4730] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4740] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4750] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4760] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4770] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4780] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4790] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4800] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4810] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4820] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4830] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4840] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4850] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4860] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4870] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4880] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4890] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4900] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4910] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4920] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4930] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4940] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4950] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4960] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4970] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4980] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 4990] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5000] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5010] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5020] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5030] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5040] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5050] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5060] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5070] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5080] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5090] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5100] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5110] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5120] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5130] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5140] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5150] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5160] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5170] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5180] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5190] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5200] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5210] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5220] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5230] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5240] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5250] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5260] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5270] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5280] TP = 0.3565, FP = 5.025125628140704e-06\n",
      "[Threshold 5290] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5300] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5310] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5320] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5330] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5340] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5350] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5360] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5370] TP = 0.3565, FP = 2.512562814070352e-06\n",
      "[Threshold 5380] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5390] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5400] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5410] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5420] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5430] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5440] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5450] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5460] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5470] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5480] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5490] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5500] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5510] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5520] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5530] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5540] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5550] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5560] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5570] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5580] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5590] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5600] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5610] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5620] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5630] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5640] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5650] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5660] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5670] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5680] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5690] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5700] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5710] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5720] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5730] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5740] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5750] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5760] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5770] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5780] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5790] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5800] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5810] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5820] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5830] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5840] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5850] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5860] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5870] TP = 0.3565, FP = 0.0\n",
      "[Threshold 5880] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5890] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5900] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5910] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5920] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5930] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5940] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5950] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5960] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5970] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5980] TP = 0.3555, FP = 0.0\n",
      "[Threshold 5990] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6000] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6010] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6020] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6030] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6040] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6050] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6060] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6070] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6080] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6090] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6100] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6110] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6120] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6130] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6140] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6150] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6160] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6170] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6180] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6190] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6200] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6210] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6220] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6230] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6240] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6250] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6260] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6270] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6280] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6290] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6300] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6310] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6320] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6330] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6340] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6350] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6360] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6370] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6380] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6390] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6400] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6410] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6420] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6430] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6440] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6450] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6460] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6470] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6480] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6490] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6500] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6510] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6520] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6530] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6540] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6550] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6560] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6570] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6580] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6590] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6600] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6610] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6620] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6630] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6640] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6650] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6660] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6670] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6680] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6690] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6700] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6710] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6720] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6730] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6740] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6750] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6760] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6770] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6780] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6790] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6800] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6810] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6820] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6830] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6840] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6850] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6860] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6870] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6880] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6890] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6900] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6910] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6920] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6930] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6940] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6950] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6960] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6970] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6980] TP = 0.3555, FP = 0.0\n",
      "[Threshold 6990] TP = 0.3555, FP = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"NN ------------------\")\n",
    "for tpr,fpr,th in zip(tp_rate_unet,fp_rate_unet,nn_thresholds):\n",
    "    print(\"[Threshold {}] TP = {}, FP = {}\".format(th,tpr,fpr))\n",
    "print(\"Classical threshold ------------------\")\n",
    "for tpr,fpr,th in zip(tp_rate_classical,fp_rate_classical,classical_thresholds):\n",
    "    print(\"[Threshold {}] TP = {}, FP = {}\".format(th,tpr,fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_plt = 100001\n",
    "evt_item = dataset_train[evt_plt]\n",
    "evt_arr = evt_item[0]\n",
    "evt_lbl = evt_item[1][0]\n",
    "\n",
    "# Send through the model.\n",
    "data = torch.tensor(evt_arr).float().unsqueeze(0).unsqueeze(1).cuda()\n",
    "#target = torch.tensor(evt_lbl).float().cuda()\n",
    "output_score = model(data)\n",
    "\n",
    "# Compute the predicted pixel and (x,y) values.\n",
    "prob = np.array(sigmoid(output_score).cpu().detach().numpy()).squeeze()\n",
    "\n",
    "# Threshold\n",
    "# prob = np.zeros(evt_arr.shape)\n",
    "# prob[evt_arr > 80] = 1\n",
    "\n",
    "# Determine number of correct pixels\n",
    "th = 0.2\n",
    "pred = (prob > th)\n",
    "nelec = int(np.sum(evt_lbl == 1))\n",
    "nelec_pred = int(np.sum(pred))\n",
    "nspace = int(np.sum(evt_lbl == 0))\n",
    "nelec_coinc = np.sum((evt_lbl == 1) & (pred == True))\n",
    "nspace_coinc = np.sum((evt_lbl == 0) & (pred == False))\n",
    "print(\"{}/{} electrons predicted\".format(nelec_pred,nelec))\n",
    "print(\"{}/{} electrons coincided exactly\".format(nelec_coinc,nelec))\n",
    "print(\"{}/{} empty spaces coincided exactly\".format(nspace_coinc,nspace))\n",
    "\n",
    "# Information for drawing the line.\n",
    "nrows = evt_arr.shape[0]\n",
    "ncols = evt_arr.shape[1]\n",
    "indices = np.indices((nrows,ncols))\n",
    "irows = indices[0]\n",
    "icols = indices[1]\n",
    "m = -2*nrows/ncols\n",
    "b = 80\n",
    "print(\"Line drawn: m = {}, b = {}\".format(m,b))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4.0)\n",
    "fig.set_figwidth(18.0)\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "plt.imshow(evt_arr)\n",
    "plt.colorbar()\n",
    "plt.title(\"Event\")\n",
    "\n",
    "# xfit = np.arange(0,ncols,0.1)\n",
    "# yfit = m*xfit + b\n",
    "# plt.plot(xfit[(yfit > 0) & (yfit < nrows)],yfit[(yfit > 0) & (yfit < nrows)])\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "plt.imshow(evt_lbl)\n",
    "plt.colorbar()\n",
    "plt.title(\"Target\")\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "#plt.imshow(np.log10(prob))\n",
    "plt.imshow(prob)\n",
    "plt.colorbar()\n",
    "plt.title(\"{}/{} electrons predicted\\n{}/{} electrons coincided exactly\\n{}/{} empty spaces coincided exactly\".format(nelec_pred,nelec,nelec_coinc,nelec,nspace_coinc,nspace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct output and label arrays for 5 events.\n",
    "outputs,labels = [], []\n",
    "for iframe in range(500):\n",
    "    frame,label = frameset[iframe]\n",
    "    outputs.append(label[1])\n",
    "    labels.append(label)\n",
    "outputs = np.array(outputs)\n",
    "labels = np.array(labels)\n",
    "print(\"Outputs shape is:\",outputs.shape)\n",
    "print(\"Labels shape is:\",labels.shape)\n",
    "\n",
    "# Convert to tensors.\n",
    "outputs[outputs == 0] = 1e-10\n",
    "outputs[outputs == 1] = 0.99999999\n",
    "output = torch.tensor(np.log(outputs/(1-outputs)))\n",
    "target = torch.tensor(labels)\n",
    "\n",
    "# Compute the loss.\n",
    "sigma_dist = 2\n",
    "real_truth = target[:,0,:,:]\n",
    "th_truth = target[:,1,:,:]\n",
    "edge_truth = target[:,2,:,:]\n",
    "dist = target[:,3,:,:]\n",
    "\n",
    "final_truth = th_truth * edge_truth\n",
    "\n",
    "w_edge = 100\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss(reduce=False)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "loss0 = bce_loss(output,final_truth)\n",
    "loss1 = w_edge*sigmoid(output)*(1-edge_truth)\n",
    "loss0W = torch.exp(-(dist)**2/(2*sigma_dist**2))*(loss0)\n",
    "loss1W = torch.exp(-(dist)**2/(2*sigma_dist**2))*(loss1)\n",
    "loss = torch.mean(torch.exp(-(dist)**2/(2*sigma_dist**2))*(loss0 + loss1))\n",
    "print(\"Mean loss is \",loss)\n",
    "print(\"Mean loss0 is \",torch.mean(loss0))\n",
    "print(\"Mean loss0W is \",torch.mean(loss0W))\n",
    "print(\"Mean loss1 is \",torch.mean(loss1))\n",
    "print(\"Mean loss1W is \",torch.mean(loss1W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iframe = 5\n",
    "show_sum = True\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(6.0)\n",
    "fig.set_figwidth(16.0)\n",
    "\n",
    "ax1 = fig.add_subplot(241)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(sigmoid(output)),axis=0),interpolation=None)\n",
    "else: plt.imshow(np.array(sigmoid(output[iframe])),interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.title(\"sigmoid(Output)\")\n",
    "\n",
    "ax2 = fig.add_subplot(242)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(th_truth),axis=0),interpolation=None)\n",
    "else: plt.imshow(np.array(real_truth[iframe]),interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.title(\"Real truth\")\n",
    "\n",
    "ax3 = fig.add_subplot(243)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(edge_truth), axis=0))\n",
    "else: plt.imshow(np.array(edge_truth[iframe]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Edge truth\")\n",
    "\n",
    "ax4 = fig.add_subplot(244)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(torch.exp(-(dist)**2/(2*sigma_dist**2))),axis=0))\n",
    "else: plt.imshow(np.array(torch.exp(-(dist)**2/(2*sigma_dist**2))[iframe]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Distance\")\n",
    "\n",
    "ax5 = fig.add_subplot(245)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(loss0), axis=0))\n",
    "else: plt.imshow(np.array(loss0[iframe]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Loss0\")\n",
    "\n",
    "ax6 = fig.add_subplot(246)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(loss1),axis=0))\n",
    "else: plt.imshow(np.array(loss1[iframe]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Loss1\")\n",
    "\n",
    "ax7 = fig.add_subplot(247)\n",
    "if(show_sum): plt.imshow(np.sum(np.array(loss0W + loss1W),axis=0))\n",
    "else: plt.imshow(np.array(loss0W[iframe] + loss1W[iframe]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LossW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate real data\n",
    "img_data_cut = img_data[-1023:,-1440:]/12\n",
    "img_data_torch = torch.tensor(img_data_cut).float().unsqueeze(0).unsqueeze(1).cuda()\n",
    "output_score = model(img_data_torch)\n",
    "prob = np.array(sigmoid(output_score).cpu().detach().numpy()).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the real data evaluation\n",
    "logscale = False\n",
    "view_row_low = -350\n",
    "view_row_high = -300\n",
    "view_col_low = -350\n",
    "view_col_high = -300\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4.0)\n",
    "fig.set_figwidth(12.0)\n",
    "\n",
    "ax1 = fig.add_subplot(121);\n",
    "if(logscale):\n",
    "    plt.imshow(np.log(img_data_cut[view_row_low:view_row_high,view_col_low:view_col_high]),interpolation='none')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"log(counts)\")\n",
    "    plt.title(\"Scaled data (log counts)\")\n",
    "else:\n",
    "    plt.imshow(img_data_cut[view_row_low:view_row_high,view_col_low:view_col_high],interpolation='none') #np.log(frame))\n",
    "    cbar = plt.colorbar()\n",
    "    plt.title(\"Scaled data\")\n",
    "\n",
    "ax2 = fig.add_subplot(122);\n",
    "plt.imshow(prob[view_row_low:view_row_high,view_col_low:view_col_high],interpolation='none')\n",
    "plt.title(\"U-net output\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/1035340/reading-binary-file-and-looping-over-each-byte\n",
    "def bytes_from_file(filename, chunksize=4):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunksize)\n",
    "            if chunk:\n",
    "                yield struct.unpack('@I', chunk)[0]\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datfile = \"/home/jrenner/local/data/electronsim/stack_1.dat\"\n",
    "freader = iter(bytes_from_file(datfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "for i in range(5760*4092):\n",
    "    img.append(next(freader))\n",
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for input to a NN\n",
    "img_data = img.reshape([4092,5760])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(np.log(img.reshape([5760,4092])),vmin=9.5,vmax=10.5)\n",
    "#plt.imshow(img.reshape([5760,4092])[-100:,0:100],vmin=750,vmax=10000)\n",
    "plt.imshow(img_data,interpolation='none',vmin=750,vmax=15000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to fit the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_th = 750*12\n",
    "max_th = 751*12\n",
    "fit_img = np.copy(img_data)\n",
    "fit_img[fit_img < noise_th] = 0\n",
    "fit_img[fit_img >= noise_th] = max_th\n",
    "fit_img = fit_img/np.max(fit_img)\n",
    "fit_img = np.array(fit_img,dtype=np.uint8)\n",
    "print(\"Min value:\",np.min(fit_img),\"; max value:\",np.max(fit_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(fit_img,interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = fit_img\n",
    "th = 0.5\n",
    "nrows = A.shape[0]\n",
    "ncols = A.shape[1]\n",
    "ncts = np.sum(A >= th)\n",
    "nzeros = np.sum(A < th)\n",
    "wcts = nzeros/ncts\n",
    "indices = np.indices((nrows,ncols))\n",
    "irows = indices[0]\n",
    "icols = indices[1]\n",
    "\n",
    "def count_loss(x):\n",
    "    m,b = x\n",
    "    \n",
    "    # The loss L is:\n",
    "    #\n",
    "    # (number of 0s in the dark region) - wcts*(number of 1s in the dark region)\n",
    "    # + wcts*(number of 1s in the light region) - (number of 0s in the dark region)\n",
    "    # \n",
    "    # where wcts is the count weight, determined such that the number of counts multiplied by wcts is equal to\n",
    "    # the number of zeros.\n",
    "    L = 0\n",
    "    L1 = np.sum((irows < m*icols + b) & (A < th))\n",
    "    L2 = np.sum((irows < m*icols + b) & (A >= th))\n",
    "    L3 = np.sum((irows >= m*icols + b) & (A >= th))\n",
    "    L4 = np.sum((irows >= m*icols + b) & (A < th))\n",
    "    \n",
    "    L = L1 - wcts*L2 + wcts*L3 - L4\n",
    "    print(\"Loss is:\",-L,\"with L1 =\",L1,\"L2 =\",L2,\"L3 =\",L3,\"L4 =\",L4)\n",
    "    return -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_guess = [-nrows/ncols,nrows]\n",
    "result = optimize.minimize(count_loss,initial_guess,method='Nelder-Mead',tol=1e-6)\n",
    "m,b = result.x\n",
    "Lmin = result.fun\n",
    "print(\"m = \",m,\"b = \",b,\"Lmin=\",Lmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(fit_img,interpolation='none')\n",
    "xfit = np.arange(ncols)\n",
    "yfit = m*xfit + b\n",
    "plt.plot(xfit[(yfit > 0) & (yfit < nrows)],yfit[(yfit > 0) & (yfit < nrows)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss in a range near the parameters.\n",
    "mrng = np.arange(m-0.1*m, m+0.1*m, 0.2*m/100)\n",
    "Lrng = np.array([count_loss([mval,b])/Lmin for mval in mrng])\n",
    "print(mrng)\n",
    "plt.plot(mrng,Lrng)\n",
    "plt.xlabel(\"Parameter m\")\n",
    "plt.ylabel(\"Relative loss L/L(m$_0$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.1):\n",
    "    v = 255/2. #np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    print(\"Lower =\",lower,\", upper=\",upper)\n",
    "    return cv2.Canny(image, lower, upper)\n",
    "\n",
    "edges = auto_canny(image=fit_img) \n",
    "\n",
    "# Show images for testing\n",
    "#cv2.imshow('edges', edges)\n",
    "plt.imshow(edges)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the noise peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fscale = 12.\n",
    "\n",
    "def gauss(x, amp, mu, sigma):\n",
    "    if sigma <= 0.:\n",
    "        return np.inf\n",
    "    return amp/(2*np.pi)**(0.5)/sigma * np.exp(-0.5*(x-mu)**2./sigma**2)\n",
    "\n",
    "def gaussexpo(x, amp, mu, sigma, const, mean, x0):\n",
    "    if sigma <= 0.:\n",
    "        return np.inf\n",
    "    return amp/(2*np.pi)**(0.5)/sigma * np.exp(-0.5*(x-mu)**2./sigma**2) + const * np.exp(-(x-x0)/mean)\n",
    "\n",
    "\n",
    "yh, xh, _ = plt.hist(img[(img/fscale > 7000/fscale) & (img/fscale < 9300/fscale)]/fscale,bins=50)\n",
    "xh = (xh[1:] + xh[0:-1])/2\n",
    "\n",
    "#popt, pcov = curve_fit(gaussexpo, xh, yh, [3.0e6, 8200, 300, 1000, 10, -1])\n",
    "popt, pcov = curve_fit(gauss, xh, yh, [3.0e6, 8200/fscale, 135/fscale])\n",
    "xfit = np.linspace(xh[0],xh[-1],100)\n",
    "plt.plot(xfit,gauss(xfit,*popt))\n",
    "plt.xlabel(\"Pixel values\")\n",
    "plt.ylabel(\"Counts/bin\")\n",
    "print(\"Fit mean:\",popt[1])\n",
    "print(\"Fit sigma:\",popt[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn = np.load(\"frame_4855x4855_11occ.npz\")\n",
    "img_sim = fn['frame'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(img[(img > 0) & (img < 10000)],bins=50)\n",
    "plt.hist(img_sim,bins=50,range=[0,10000],label='MC')\n",
    "plt.hist(img/12,bins=50,range=[0,10000],label='data')\n",
    "\n",
    "plt.xlabel(\"Pixel values\")\n",
    "plt.ylabel(\"Counts/bin\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "print(\"Total pixels:\",len(img))\n",
    "print(\"Counts near peak\",np.sum(img[(img > 29) & (img < 33)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "177383690/935130034."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(np.random.normal(loc=0,scale=50,size=1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a network (single-electrons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = '/home/jrenner/local/jerenner/emsim/models'\n",
    "lrate       = 1e-4   # Learning rate to use in the training.\n",
    "load_model  = True   # Load an existing model\n",
    "tr.augment  = False  # Enable/disable data augmentation\n",
    "epoch_start = 74      # Number of initial epoch\n",
    "epoch_end   = 2000    # Number of final epoch\n",
    "model_load_checkpoint = \"{}/model_10cells_noise_100k_74.pt\".format(modeldir)\n",
    "\n",
    "# Create the datasets.\n",
    "dataset_all   = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=True,add_shift=0)\n",
    "dataset_train = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=True,nstart=0,nend=-20000,add_shift=0)\n",
    "dataset_val   = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=True,nstart=-20000,add_shift=0)\n",
    "\n",
    "# Create the loaders.\n",
    "train_loader = DataLoader(dataset_train, batch_size=1000, shuffle=True, collate_fn=tr.my_collate, num_workers=8)\n",
    "val_loader = DataLoader(dataset_val, batch_size=1000, shuffle=True, collate_fn=tr.my_collate, num_workers=8)\n",
    "#val_loader = DataLoader(dataset_val, batch_size=15, shuffle=True, collate_fn=tr.my_collate, num_workers=4)\n",
    "#test_loader = DataLoader(dataset_test, batch_size=15, shuffle=True, collate_fn=tr.my_collate, num_workers=4)\n",
    "\n",
    "# Define the model.\n",
    "#model = emnet.FCNet()\n",
    "model = emnet.basicCNN()\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lrate, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.01, amsgrad=True)\n",
    "\n",
    "# Load the model from file.\n",
    "if(load_model):\n",
    "    model.load_state_dict(torch.load(model_load_checkpoint))\n",
    "    #model.load_state_dict(torch.load(model_load_checkpoint,map_location=torch.device('cpu')))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training.\n",
    "#print(\"Training with weights\",sort_clsweights)\n",
    "for epoch in range(epoch_start,epoch_end):\n",
    "    print(\"Epoch: \",epoch)\n",
    "    model.train()\n",
    "    tr.train(model, epoch, train_loader, optimizer)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        tr.val(model, epoch, val_loader)\n",
    "#     if(epoch % 50 == 0):\n",
    "#         torch.save(model.state_dict(), \"{}/model_init_{}.pt\".format(modeldir,epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"{}/model_10cells_noise_100k_{}.pt\".format(modeldir,epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses.\n",
    "tloss = np.loadtxt(\"train.txt\")\n",
    "vloss = np.loadtxt(\"val.txt\")\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4.0)\n",
    "fig.set_figwidth(12.0)\n",
    "\n",
    "ax1 = fig.add_subplot(121);\n",
    "plt.plot(tloss[:,0],tloss[:,1],label='training')\n",
    "plt.plot(vloss[:,0],vloss[:,1],label='validation')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.yscale('log')\n",
    "\n",
    "ax2 = fig.add_subplot(122);\n",
    "plt.plot(tloss[:,0],tloss[:,2],label='training')\n",
    "plt.plot(vloss[:,0],vloss[:,2],label='validation')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate all events from a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=True,add_shift=0)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = np.arange(80000,80100)\n",
    "df, evts = emsim_utils.construct_evt_dataframe(dset,evts,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pd.plotting.scatter_matrix(df[[\"error_r_NN\",\"error_r_maxpt\",\"error_r_3x3\",\"error_r_3x3_th\",\"error_r_5x5\",\"error_r_5x5_th\"]], \n",
    "                                  figsize=[15,15], alpha=0.2, hist_kwds={'bins':100})\n",
    "for i, axs in enumerate(axes):\n",
    "    for j, ax in enumerate(axs):\n",
    "        #if i == j:  # only the histograms\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_xlim(0,0.01)\n",
    "        ax.set_ylim(0,0.01)\n",
    "            \n",
    "plt.savefig(\"errors_scatter_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cut = 0.02\n",
    "sigma_cut = 1e9\n",
    "plt.hist(df[(df.error_r_NN < err_cut) & (df.sigma_r_NN < sigma_cut)].error_r_NN,alpha=0.8,bins=50,color='blue',label='NN error')\n",
    "plt.hist(df[(df.error_r_3x3 < err_cut) & (df.sigma_r_NN < sigma_cut)].error_r_3x3,alpha=0.8,bins=50,color='green',label='3x3 centroid')\n",
    "plt.xlabel(\"error $\\sqrt{\\Delta x^2 + \\Delta y^2}$ (mm)\")\n",
    "plt.ylabel(\"counts/bin\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean 3x3 error:\",df[(df.error_r_3x3 < err_cut) & (df.sigma_r_NN < sigma_cut)].error_r_3x3.mean())\n",
    "print(\"Mean NN error: \",df[(df.error_r_NN < err_cut) & (df.sigma_r_NN < sigma_cut)].error_r_NN.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_r_diff\"] = df.error_r_NN - df.error_r_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_diff_cut = 0.005\n",
    "plt.hist(df[(df.error_r_diff < err_diff_cut) & (df.error_r_diff > -err_diff_cut) & (df.sigma_r_NN < 0.011)].error_r_diff,alpha=0.8,bins=50,color='blue',label='NN error')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"error difference (NN - 3x3-method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe and event arrays.\n",
    "df.to_pickle(\"evts_80000_to_90000.pkl\")\n",
    "np.savez(\"evt_arrays.npz\",evt_arrays=l_evt_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"evts_80000_to_90000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_sigma = 0.011\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(6.0)\n",
    "fig.set_figwidth(15.0)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "plt.hist(df[df.sigma_r_NN < cut_sigma].error_r_NN,bins=50)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"error $\\sqrt{\\Delta x^2 + \\Delta y^2}$ (mm)\")\n",
    "plt.ylabel(\"Counts/bin\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.hist(df[df.sigma_r_NN < cut_sigma].sigma_r_NN,bins=50)\n",
    "plt.xlabel(\"$\\sqrt{\\sigma_x^2 + \\sigma_y^2}$ of probability distribution (mm)\")\n",
    "plt.ylabel(\"Counts/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff, mean_err = [], []\n",
    "cut_sigmas = np.arange(0.003,0.4,0.0005)\n",
    "for cut_sigma in cut_sigmas:\n",
    "    df_cut = df[df.sigma_r_NN < cut_sigma]\n",
    "    \n",
    "    eff.append(len(df_cut)/len(df))\n",
    "    mean_err.append(df_cut.error_r_NN.mean())\n",
    "    \n",
    "    print(\"[SIGMA = {}]: EFF = {}, ERR = {}\".format(cut_sigma,len(df_cut)/len(df),df_cut.error_r_NN.mean()))\n",
    "\n",
    "eff = np.array(eff)\n",
    "mean_err = np.array(mean_err)\n",
    "plt.plot(mean_err,eff,'.-')\n",
    "plt.xlabel(\"Mean error (mm)\")\n",
    "plt.ylabel(\"Efficiency\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the net for individual events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_noise=True,add_shift=0)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_plt = 81001\n",
    "evt_item = dset[evt_plt]\n",
    "evt_arr = evt_item[0]\n",
    "evt_lbl = evt_item[1]\n",
    "evt_err_ind = evt_item[2]\n",
    "\n",
    "SHIFTED_ERR_RANGE_MIN = emnet.PIXEL_ERR_RANGE_MIN - dset.add_shift*emnet.PIXEL_SIZE\n",
    "SHIFTED_ERR_RANGE_MAX = emnet.PIXEL_ERR_RANGE_MAX + dset.add_shift*emnet.PIXEL_SIZE\n",
    "ERR_PIXEL_SIZE = emnet.PIXEL_SIZE*(2*dset.add_shift+1)/emnet.ERR_SIZE\n",
    "\n",
    "x_errgrid = np.arange(0,emnet.ERR_SIZE)*ERR_PIXEL_SIZE + SHIFTED_ERR_RANGE_MIN + ERR_PIXEL_SIZE/2\n",
    "y_errgrid = np.arange(0,emnet.ERR_SIZE)*ERR_PIXEL_SIZE + SHIFTED_ERR_RANGE_MIN + ERR_PIXEL_SIZE/2\n",
    "\n",
    "xbin = int(emnet.ERR_SIZE*(evt_lbl[0] - SHIFTED_ERR_RANGE_MIN)/(SHIFTED_ERR_RANGE_MAX - SHIFTED_ERR_RANGE_MIN))\n",
    "xbin = max(xbin,0)\n",
    "xbin = min(xbin,emnet.ERR_SIZE-1)\n",
    "\n",
    "ybin = int(emnet.ERR_SIZE*(evt_lbl[1] - SHIFTED_ERR_RANGE_MIN)/(SHIFTED_ERR_RANGE_MAX - SHIFTED_ERR_RANGE_MIN))\n",
    "ybin = max(ybin,0)\n",
    "ybin = min(ybin,emnet.ERR_SIZE-1)\n",
    "\n",
    "print(\"Computed index:\",(ybin*emnet.ERR_SIZE) + xbin,\"for max added shift:\",dset.add_shift)\n",
    "\n",
    "# Send through the model.\n",
    "data = torch.tensor(evt_arr).float().unsqueeze(0).unsqueeze(1).cuda()\n",
    "target = torch.tensor(np.array(evt_err_ind)).long().cuda()\n",
    "output_score = model(data)\n",
    "\n",
    "# Compute the predicted pixel and (x,y) values.\n",
    "prob = np.array(softmax(output_score).cpu().detach().numpy()).reshape([emnet.ERR_SIZE,emnet.ERR_SIZE])\n",
    "ipred = np.argmax(prob)\n",
    "xpred = int(ipred % emnet.ERR_SIZE)*ERR_PIXEL_SIZE + SHIFTED_ERR_RANGE_MIN + ERR_PIXEL_SIZE/2\n",
    "ypred = int(ipred / emnet.ERR_SIZE)*ERR_PIXEL_SIZE + SHIFTED_ERR_RANGE_MIN + ERR_PIXEL_SIZE/2\n",
    "#print(\"[Evt\",evt,\"]: Index is\",evt_err_ind,\"with predicted\",ipred,\"; x = {} (predicted {}), y = {} (predicted {})\".format(evt_lbl[0],xpred,evt_lbl[1],ypred))\n",
    "\n",
    "# Compute the sigmas of the distribution.\n",
    "sigma_x0, sigma_y0 = emsim_utils.compute_sigmas(prob,ERR_PIXEL_SIZE,SHIFTED_ERR_RANGE_MIN)\n",
    "popt, pcov = emsim_utils.fit_sigmas(prob,x_errgrid,y_errgrid,xpred,ypred,sigma_x0,sigma_y0,ERR_PIXEL_SIZE)\n",
    "fit_data = emsim_utils.mult_gaussFun_Fit((x_errgrid,y_errgrid),*popt).reshape([emnet.ERR_SIZE,emnet.ERR_SIZE])\n",
    "print(\"Gaussian fit parameters A*exp(-0.5*((x-x0)**2/varX + (y-y0)**2/varY)) + C:\")\n",
    "print(\"A = {}\".format(popt[0]))\n",
    "print(\"(x0, y0) = ({},{})\".format(popt[1],popt[2]))\n",
    "print(\"(sigma_x, sigma_y) = ({},{})\".format(popt[3]**0.5,popt[4]**0.5))\n",
    "print(\"C = {}\".format(popt[5]))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4.0)\n",
    "fig.set_figwidth(18.0)\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "plt.imshow(evt_arr)\n",
    "plt.colorbar()\n",
    "plt.title(\"Event {}; shift ({:.3e},{:.3e}); index {}\".format(evt_plt,evt_lbl[0],evt_lbl[1],evt_err_ind))\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot([xbin],[ybin],color='red',marker='o',markersize=10)\n",
    "plt.imshow(prob)\n",
    "plt.colorbar()\n",
    "plt.title(\"Incidence point within prediction grid\")\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "plt.imshow(fit_data)\n",
    "plt.colorbar()\n",
    "plt.title(\"2D Gaussian fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc. code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at many events:\n",
    "xpred_err, ypred_err = [], []\n",
    "for evt_plt in np.arange(8000,9999):\n",
    "    \n",
    "    evt_item = dset[evt_plt]\n",
    "    evt_arr = evt_item[0]\n",
    "    evt_lbl = evt_item[1]\n",
    "    evt_err_ind = evt_item[2]\n",
    "\n",
    "    # Send through the model.\n",
    "    data = torch.tensor(evt_arr).float().unsqueeze(0).unsqueeze(1).cuda()\n",
    "    target = torch.tensor(np.array(evt_err_ind)).long().cuda()\n",
    "\n",
    "    output_score = model(data)\n",
    "    prob = np.argmax(np.array(softmax(output_score).cpu().detach().numpy()).reshape([10,10]))\n",
    "    xpred = (prob % tr.ERR_SIZE)*0.005/tr.ERR_SIZE + tr.ERR_RANGE_MIN + 0.005/tr.ERR_SIZE/2\n",
    "    ypred = (prob / tr.ERR_SIZE)*0.005/tr.ERR_SIZE + tr.ERR_RANGE_MIN + 0.005/tr.ERR_SIZE/2\n",
    "    print(\"[Evt\",evt_plt,\"]: Index is\",evt_err_ind,\"with predicted\",prob,\"; x = {} (predicted {}), y = {} (predicted {})\".format(evt_lbl[0],xpred,evt_lbl[1],ypred))\n",
    "    \n",
    "    xpred_err.append(xpred-evt_lbl[0])\n",
    "    ypred_err.append(ypred-evt_lbl[1])\n",
    "xpred_err = np.array(xpred_err)\n",
    "ypred_err = np.array(ypred_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(6.0)\n",
    "fig.set_figwidth(15.0)\n",
    "\n",
    "ax1 = fig.add_subplot(121);\n",
    "plt.hist(xpred_err)\n",
    "plt.xlabel(\"error in x-prediction (mm)\")\n",
    "print(np.where(abs(xpred_err) > 0.001))\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.hist(ypred_err)\n",
    "plt.xlabel(\"error in y-prediction (mm)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For debugging the 3x3 sum operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.ones([6,6])\n",
    "aa[0,2] = 4\n",
    "aa[1,2] = 2\n",
    "aa[3,2] = 8\n",
    "aa[4,2] = -2\n",
    "aa[3,1] = 5\n",
    "aa[5,0] = 10\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_init   = np.unravel_index(aa.argmax(),aa.shape)\n",
    "nbsum_init = tr.sum_neighbors(aa,max_init,remove=True)\n",
    "print(\"Max at\",max_init,\"and neighbor sum\",nbsum_init)\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate a dataset for noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nevts = 1000\n",
    "noise_arr = np.arange(0.,100.,50.)\n",
    "r_mean, r_sigma = [], []\n",
    "for noise in noise_arr:\n",
    "    print(\"Running for noise\",noise)\n",
    "    dset = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",0,noise)\n",
    "    \n",
    "    shifts_x, shifts_y, shifts_r = [], [], []\n",
    "    for evt in range(Nevts):\n",
    "        evt_arr,evt_lbl = dset[evt]\n",
    "        xs,ys = evt_lbl[0],evt_lbl[1]\n",
    "        shifts_x.append(xs)\n",
    "        shifts_y.append(ys)\n",
    "        shifts_r.append((xs**2 + ys**2)**0.5)\n",
    "    \n",
    "    shifts_r = np.array(shifts_r)\n",
    "    r_mean.append(np.mean(shifts_r))\n",
    "    r_sigma.append(np.std(shifts_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(noise_arr,r_mean,yerr=np.array(r_sigma)/Nevts**0.5)\n",
    "plt.xlabel(\"$\\sigma$ noise (electrons)\")\n",
    "plt.ylabel(\"r-error (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a dataset and examine individual events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = tr.EMDataset(\"dataframes/EM_4um_back_10M_300keV.pkl\",noise_mean=0,noise_sigma=20,add_shift=10,add_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_plt = 8\n",
    "evt_item = dset[evt_plt]\n",
    "evt_arr = evt_item[0]\n",
    "evt_lbl = evt_item[1]\n",
    "evt_err_ind = evt_item[2]\n",
    "plt.imshow(evt_arr)\n",
    "plt.colorbar()\n",
    "plt.title(\"Event {}; shift {}; index {}\".format(evt_plt,evt_lbl,evt_err_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_x, shifts_y, shifts_r = [], [], []\n",
    "for evt in range(1000):\n",
    "    evt_arr,evt_lbl,evt_err_ind = dset[evt]\n",
    "    xs,ys = evt_lbl[0],evt_lbl[1]\n",
    "    shifts_x.append(xs)\n",
    "    shifts_y.append(ys)\n",
    "    shifts_r.append((xs**2 + ys**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(shifts_r,bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot events directly from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"dataframes/EM_4um_back_10M_300keV.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_plt = 97\n",
    "evt_arr = np.zeros([101,101])\n",
    "df_evt = df[df.event == evt_plt]\n",
    "for row,col,counts in zip(df_evt['row'].values,df_evt['col'].values,df_evt['counts'].values):\n",
    "    evt_arr[row,col] += counts\n",
    "plt.imshow(np.log(0.1 + evt_arr))\n",
    "plt.colorbar()\n",
    "plt.title(\"Event {}; max at {}\".format(evt_plt,np.unravel_index(evt_arr.argmax(),evt_arr.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
